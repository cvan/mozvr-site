{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/content/images/2016/02/josh.jpg","path":"content/images/2016/02/josh.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/c4d-6.png","path":"content/images/2016/02/c4d-6.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/e10s-windows.png","path":"content/images/2016/02/e10s-windows.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/fox-square-200.png","path":"content/images/2016/02/fox-square-200.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/icon-download-2-white-1.svg","path":"content/images/2016/02/icon-download-2-white-1.svg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/icon-goggles-2-white.svg","path":"content/images/2016/02/icon-goggles-2-white.svg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/icon-download-2-white.svg","path":"content/images/2016/02/icon-download-2-white.svg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/icon-mozvr-fox-128.png","path":"content/images/2016/02/icon-mozvr-fox-128.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/josh-1.jpg","path":"content/images/2016/02/josh-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/kearwoodlaptop.jpg","path":"content/images/2016/02/kearwoodlaptop.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/photo1.jpg","path":"content/images/2016/02/photo1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/uninstall.png","path":"content/images/2016/05/uninstall.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/06/w3c_home_nb-v.svg","path":"content/images/2016/06/w3c_home_nb-v.svg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/w3c.jpg","path":"content/images/2016/08/w3c.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/98d3708e-47ec-11e6-817c-4d5fdfba80a9.jpg","path":"content/images/2016/09/98d3708e-47ec-11e6-817c-4d5fdfba80a9.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/w3c-logo.png","path":"content/images/2016/09/w3c-logo.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/w3c_home_nb-v.svg","path":"content/images/2016/09/w3c_home_nb-v.svg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/Screenshot-2016-02-18-16-17-01.png","path":"content/images/2016/02/Screenshot-2016-02-18-16-17-01.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/human-visual-field.jpg","path":"content/images/2016/02/human-visual-field.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/mockup2.png","path":"content/images/2016/02/mockup2.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/PANO_20160314_123750.jpg","path":"content/images/2016/05/PANO_20160314_123750.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/rift_hero.jpg","path":"content/images/2016/05/rift_hero.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/unknown-sources.jpg","path":"content/images/2016/05/unknown-sources.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/06/W3C-_Icon-svg.png","path":"content/images/2016/06/W3C-_Icon-svg.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/06/w3c.png","path":"content/images/2016/06/w3c.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/cvan2.jpg","path":"content/images/2016/09/cvan2.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/controller_tooltips_medium.jpg","path":"content/images/2016/09/controller_tooltips_medium.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/logo_a-painter_medium.jpg","path":"content/images/2016/09/logo_a-painter_medium.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/e10s.png","path":"content/images/2016/02/e10s.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/sechelt-3.png","path":"content/images/2016/02/sechelt-3.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/visual-field-DK2.png","path":"content/images/2016/02/visual-field-DK2.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/CjFZ1n0WYAA8twp-jpg-large.jpg","path":"content/images/2016/05/CjFZ1n0WYAA8twp-jpg-large.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/IMG_20160314_123708.jpg","path":"content/images/2016/05/IMG_20160314_123708.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/IMG_20160315_111705.jpg","path":"content/images/2016/05/IMG_20160315_111705.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/IMG_20160315_112900.jpg","path":"content/images/2016/05/IMG_20160315_112900.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/mozvr.png","path":"content/images/2016/05/mozvr.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/06/IMG_20160315_112900--1-.jpg","path":"content/images/2016/06/IMG_20160315_112900--1-.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/06/w3c_icon.png","path":"content/images/2016/06/w3c_icon.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/c4d-4.png","path":"content/images/2016/02/c4d-4.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/project-splash-1.jpg","path":"content/images/2016/02/project-splash-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/project-splash.jpg","path":"content/images/2016/02/project-splash.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/IMG_20160314_135219.jpg","path":"content/images/2016/05/IMG_20160314_135219.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/06/IMG_20160314_135219--1-.jpg","path":"content/images/2016/06/IMG_20160314_135219--1-.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/webvr-1-large-1.jpg","path":"content/images/2016/08/webvr-1-large-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/webvr-1-large.jpg","path":"content/images/2016/08/webvr-1-large.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg","path":"content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/logo_a-painter_high-nobrands.jpg","path":"content/images/2016/09/logo_a-painter_high-nobrands.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/menu.jpg","path":"content/images/2016/09/menu.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/c4d-1-1.png","path":"content/images/2016/02/c4d-1-1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/c4d-1.png","path":"content/images/2016/02/c4d-1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/mockup1.png","path":"content/images/2016/02/mockup1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/post-splash-1.jpg","path":"content/images/2016/02/post-splash-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/mockup3.png","path":"content/images/2016/02/mockup3.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/post-splash-4.jpg","path":"content/images/2016/02/post-splash-4.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/post-splash-3.jpg","path":"content/images/2016/02/post-splash-3.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/vlad-1.jpg","path":"content/images/2016/02/vlad-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/foxlogo-1.png","path":"content/images/2016/09/foxlogo-1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/logo_a-painter_high-1.jpg","path":"content/images/2016/09/logo_a-painter_high-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/logo_a-painter_high.jpg","path":"content/images/2016/09/logo_a-painter_high.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/poster.png","path":"content/images/2016/09/poster.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/76upLXDc.png","path":"content/images/2016/05/76upLXDc.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/artdirection-dc.png","path":"content/images/2016/02/artdirection-dc.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/artdirection-dc-1.png","path":"content/images/2016/02/artdirection-dc-1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/foxlogo.png","path":"content/images/2016/09/foxlogo.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/artdirection-rhv.png","path":"content/images/2016/02/artdirection-rhv.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/bg.jpg","path":"content/images/2016/09/bg.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/webvr-1-2.jpg","path":"content/images/2016/08/webvr-1-2.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/webvr-1-1.jpg","path":"content/images/2016/08/webvr-1-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/webvr-1-3.jpg","path":"content/images/2016/08/webvr-1-3.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/webvr-1.jpg","path":"content/images/2016/08/webvr-1.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/post-splash.jpg","path":"content/images/2016/02/post-splash.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/home.png","path":"content/images/2016/05/home.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/post-splash-2.jpg","path":"content/images/2016/02/post-splash-2.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/puydesancy.jpg","path":"content/images/2016/02/puydesancy.jpg","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/ball-throw.gif","path":"content/images/2016/08/ball-throw.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/googleearth-2.png","path":"content/images/2016/02/googleearth-2.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/02/map1.png","path":"content/images/2016/02/map1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/apainter_painting.gif","path":"content/images/2016/09/apainter_painting.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/v0-3-0-inspector.gif","path":"content/images/2016/08/v0-3-0-inspector.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/me.png","path":"content/images/2016/05/me.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/05/settings.gif","path":"content/images/2016/05/settings.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/argon.gif","path":"content/images/2016/08/argon.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/v0-3-0-1.png","path":"content/images/2016/08/v0-3-0-1.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/v0-3-0-roomscale.gif","path":"content/images/2016/08/v0-3-0-roomscale.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/08/v0-3-0.png","path":"content/images/2016/08/v0-3-0.png","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/apainter_menuc.gif","path":"content/images/2016/09/apainter_menuc.gif","modified":0,"renderable":0},{"_id":"source/content/images/2016/09/spheres-brush.gif","path":"content/images/2016/09/spheres-brush.gif","modified":0,"renderable":0}],"Cache":[{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1475017306000},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1475017306000},{"_id":"themes/landscape/_config.yml","hash":"b00f516c4be809e31f2595ba8ea1b96fb447ad99","modified":1475022395000},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1475017306000},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1475017306000},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1475017306000},{"_id":"source/_drafts/Experimental-OSVR-Support-landed-in-Firefox-Nightly.md","hash":"06c091f3955a3f578ea2d7a1fc857934bdd4d6c1","modified":1475133467000},{"_id":"source/_drafts/Exporting-Unity-Games-to-WebVR.md","hash":"cd0ab1cb72e584adcd461d95809b4796c6b841d2","modified":1475133467000},{"_id":"source/_drafts/Making-Sechelt-With-three-js-and-Cinema-4D.md","hash":"e437a7edd3fbc5b45491d47d5daeadcbaaca4651","modified":1475133467000},{"_id":"source/_drafts/Puzzle-Rain-A-room-scale-WebVR-Experience-for-the-HTC-Vive.md","hash":"edac2078bef6e790026777b787cb28c1df3bfe83","modified":1475133467000},{"_id":"source/_drafts/Introducing-the-WebVR-1-0-API-Proposal.md","hash":"a1561be3f0e9b06d5c4819de05074be7c455fa00","modified":1475133467000},{"_id":"source/_drafts/WebVR-featured-Killscreen-Featured-on-WebVR.md","hash":"31920aab54d8413ecb6d8308fedd123ba430fbf0","modified":1475133467000},{"_id":"source/_drafts/SFHTML5-WebVR-Conference-Meetup.md","hash":"077e946b6a1fe2fa563166213b8103b71ddad71e","modified":1475133467000},{"_id":"source/_drafts/Using-Service-Workers-for-creating-fast-and-offline-first-WebVR-experiences.md","hash":"3034093756cefbbf30df0deef9a8610bd197a33b","modified":1475133467000},{"_id":"source/_posts/A-Frame-v0-3-0-Walk-in-a-Web-Page.md","hash":"17afb2ec9b58795308f131fbaa8b0775a962c795","modified":1475133467000},{"_id":"source/_posts/Everything-you-wanted-to-know-about-Oculus-CV1-Oculus-Home-1-3-runtime-and-WebVR.md","hash":"4d9128943b546389e506b41296a4863fd64a59fa","modified":1475133467000},{"_id":"source/_posts/Experimental-HTC-Vive-Support-in-Firefox-Nightly.md","hash":"163f20a363228221741f82bedb7d75cb374c694a","modified":1475133467000},{"_id":"source/_posts/A-Painter-Paint-in-VR-in-Your-Browser.md","hash":"2f4a50d844fa037f4ece51d3bea6d77c837ed936","modified":1475133467000},{"_id":"source/_posts/Fun-WebVR-Times-at-Innovation-High.md","hash":"28539f35a7973f5edf8a53e32bf5a8b3fa3448b3","modified":1475133467000},{"_id":"source/_posts/Introducing-A-Frame-Building-Blocks-for-WebVR.md","hash":"ed02dd9a458e0fceafa6f756c8d724c58b8fc85a","modified":1475133467000},{"_id":"source/_posts/Oculus-0-8-Runtime-Support-Landing-in-Firefox-Nightly.md","hash":"89eeaf2aa90c506ea125b859047da1e2f7b79c05","modified":1475133467000},{"_id":"source/_posts/Quick-VR-Prototypes.md","hash":"6e23174e0d11b31753c97f76b8c3df47d175cde5","modified":1475133467000},{"_id":"source/_posts/Upcoming-W3C-Workshop-on-Web-VR.md","hash":"efdeeb53b8ac207324a6d1cd11cc43e40fe38be2","modified":1475133467000},{"_id":"source/_posts/WebVR-1-0-available-in-Firefox-Nightly.md","hash":"2cbdb7f28e05206633f1e2b5b6f4dfbcdfedf53b","modified":1475133467000},{"_id":"source/_posts/WebVR-Enabled-by-Default-in-Firefox-Nightly.md","hash":"ead1b775eb2d3121eed025d7215887725013079c","modified":1475133467000},{"_id":"source/_posts/WebVR-Oculus-Pose-Prediction-and-HW-Latency-Testing.md","hash":"ad921b70f5f276f159abd836f2e887b142ca049d","modified":1475133467000},{"_id":"source/_posts/WebVR-Lands-in-Firefox-Nightly.md","hash":"0993a12f102124ca8ecb8166990b4b0b03dfe7a0","modified":1475133467000},{"_id":"source/_posts/hello-world.md","hash":"e1135311cb58e85cfa347bb3b618fca286f5addc","modified":1475022038000},{"_id":"source/start/index.md","hash":"bb0f5b92f71ddc5f94a0a8f1d9ab0d6275d1f4be","modified":1475022938000},{"_id":"source/_posts/WebVR-API-Transitions-to-W3C-Incubation.md","hash":"2145e087f650cb8d96b358dacbb4f61f2f67d78e","modified":1475133467000},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1475017306000},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1475017306000},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1475017306000},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1475017306000},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1475017306000},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1475017306000},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1475017306000},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1475017306000},{"_id":"themes/landscape/layout/index.ejs","hash":"e1ed9a59bcb79e23bd3bd7189f5b6579739879a2","modified":1475103228000},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1475017306000},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1475017306000},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1475017306000},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1475017306000},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1475017306000},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1475017306000},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1475017306000},{"_id":"themes/landscape/source/css/_variables.styl","hash":"5e37a6571caf87149af83ac1cc0cdef99f117350","modified":1475017306000},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1475017306000},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"82a30f81c0e8ba4a8af17acd6cc99e93834e4d5e","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"4fe8853e864d192701c03e5cd3a5390287b90612","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"c21ca56f419d01a9f49c27b6be9f4a98402b2aa3","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/getting-started.ejs","hash":"d9a560b49f0a4bfc303a96ca40c6441783e71b4c","modified":1475103221000},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1475017306000},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1475017306000},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1475017306000},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1475017306000},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1475017306000},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1475017306000},{"_id":"source/images/2016/02/josh.jpg","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1475163458000},{"_id":"source/images/2016/02/c4d-6.png","hash":"6ccf93386bc6eaa0fc7fb685a4c81da555420794","modified":1475163458000},{"_id":"source/images/2016/02/e10s-windows.png","hash":"ef6c73992b92eb279e6338223ba8ce6411860b7b","modified":1475163458000},{"_id":"source/images/2016/02/fox-square-200.png","hash":"97c85e9d083153a0d794e8c1b9139a62f48e4473","modified":1475163458000},{"_id":"source/images/2016/02/icon-download-2-white-1.svg","hash":"69996ce354bf17b74f7d74f5ef48871d5ba941a7","modified":1475163458000},{"_id":"source/images/2016/02/icon-download-2-white.svg","hash":"69996ce354bf17b74f7d74f5ef48871d5ba941a7","modified":1475163458000},{"_id":"source/images/2016/02/icon-goggles-2-white.svg","hash":"5a830f33ddfb29eddcc1e7e2beb6b4adbd806acd","modified":1475163458000},{"_id":"source/images/2016/02/josh-1.jpg","hash":"7d7f412ec5b2367e714ca0deb548318099e63963","modified":1475163458000},{"_id":"source/images/2016/02/icon-mozvr-fox-128.png","hash":"68cb7cafa555f1f24b10e069f81c18cdde2269d6","modified":1475163458000},{"_id":"source/images/2016/02/kearwoodlaptop.jpg","hash":"df3fc88335b15017cb5ae76aa6bd5d0535b69b8c","modified":1475163458000},{"_id":"source/images/2016/02/photo1.jpg","hash":"4061ffe507363383eac04e10b367e03497ed60bb","modified":1475163458000},{"_id":"source/images/2016/05/uninstall.png","hash":"d3a5bb7e55eb8dc355b0d3cd983ae60a8fb895e7","modified":1475163456000},{"_id":"source/images/2016/06/w3c_home_nb-v.svg","hash":"bc2202e2d55cca8429ec35fcd7d9cd232b7d84b4","modified":1475163458000},{"_id":"source/images/2016/08/w3c.jpg","hash":"4ebd8aa5c6073dda7e887f355e2904c94a3afd80","modified":1475163456000},{"_id":"source/images/2016/09/98d3708e-47ec-11e6-817c-4d5fdfba80a9.jpg","hash":"89b3c3aba383148ece5c57cade460c03b8a9fdbf","modified":1475163458000},{"_id":"source/images/2016/09/w3c-logo.png","hash":"53ef0b9d975b15576b5b917a80bb5004c9d7967e","modified":1475163458000},{"_id":"source/images/2016/09/w3c_home_nb-v.svg","hash":"bc2202e2d55cca8429ec35fcd7d9cd232b7d84b4","modified":1475163458000},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1475017306000},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1475017306000},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1475017306000},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1475017306000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1475017306000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1475017306000},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1475017306000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1475017306000},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1475017306000},{"_id":"source/images/2016/02/Screenshot-2016-02-18-16-17-01.png","hash":"ba0cd045ff786aa1625beb497eb90cd768fcbb10","modified":1475163458000},{"_id":"source/images/2016/02/human-visual-field.jpg","hash":"6d50dc96f9de4326ea036e9298a8d353957e50db","modified":1475163458000},{"_id":"source/images/2016/02/mockup2.png","hash":"95aa1f540ea9c178ddfda760a1a66aa0464236f1","modified":1475163458000},{"_id":"source/images/2016/05/PANO_20160314_123750.jpg","hash":"c745a0740cefe5650a85163a771c797efebaf6ea","modified":1475163456000},{"_id":"source/images/2016/05/rift_hero.jpg","hash":"6366c45e87e332d668655c65c65beebd4070cf59","modified":1475163456000},{"_id":"source/images/2016/06/W3C-_Icon-svg.png","hash":"b9a50d1a2bb069404e5109e97a4e8278daeabdcd","modified":1475163458000},{"_id":"source/images/2016/05/unknown-sources.jpg","hash":"ceea54fc197b9f71025dc352c3c715e628c633da","modified":1475163454000},{"_id":"source/images/2016/06/w3c.png","hash":"3bf8c1bb592862005a9bfa1cf34093bb396b1d17","modified":1475163458000},{"_id":"source/images/2016/09/controller_tooltips_medium.jpg","hash":"f3e7d4b7027814f3d09ee455e7705a3e1f7fccd8","modified":1475163458000},{"_id":"source/images/2016/09/cvan2.jpg","hash":"9d83f57485a2fba867958a3e037846fc09fd91e0","modified":1475163458000},{"_id":"source/images/2016/09/logo_a-painter_medium.jpg","hash":"eff41931c3ff8ad32d3e2dc30e6076081eb1efae","modified":1475163458000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1475017306000},{"_id":"source/images/2016/02/e10s.png","hash":"8f54a299e7bd5417767d709cb64c8523b00f370b","modified":1475163458000},{"_id":"source/images/2016/02/sechelt-3.png","hash":"057d10c2f913bce9d5e31a497e7b9157034cbadd","modified":1475163458000},{"_id":"source/images/2016/02/visual-field-DK2.png","hash":"813a60bd635e79adec41613749a37ec19cb6a94e","modified":1475163458000},{"_id":"source/images/2016/05/CjFZ1n0WYAA8twp-jpg-large.jpg","hash":"7ac345f522cddb9d7f34ccbe0921dbaa02375a00","modified":1475163454000},{"_id":"source/images/2016/05/IMG_20160314_123708.jpg","hash":"197d9340d7e42df1c9226e80e2aa7d8ea43a99db","modified":1475163454000},{"_id":"source/images/2016/05/IMG_20160315_111705.jpg","hash":"236fa53729a7d5d3aca4fad7884e0093ef885247","modified":1475163454000},{"_id":"source/images/2016/05/mozvr.png","hash":"4ba1931851a6f58d33d38e709369811e0a6d092b","modified":1475163456000},{"_id":"source/images/2016/05/IMG_20160315_112900.jpg","hash":"11fac8f230b1da863ea513f3d204d091b7a8ffde","modified":1475163454000},{"_id":"source/images/2016/06/IMG_20160315_112900--1-.jpg","hash":"11fac8f230b1da863ea513f3d204d091b7a8ffde","modified":1475163458000},{"_id":"source/images/2016/06/w3c_icon.png","hash":"f425cd40c88810a6eb74cc8a45ca208fc5395ec6","modified":1475163458000},{"_id":"source/images/2016/02/c4d-4.png","hash":"99b5befdd99878365aeab80b0bcec83152dbc662","modified":1475163458000},{"_id":"source/images/2016/02/project-splash-1.jpg","hash":"02a62329d8d4feb7a080fdf0375ac8bd68dbe7dc","modified":1475163458000},{"_id":"source/images/2016/02/project-splash.jpg","hash":"02a62329d8d4feb7a080fdf0375ac8bd68dbe7dc","modified":1475163458000},{"_id":"source/images/2016/05/IMG_20160314_135219.jpg","hash":"2b48b1264806885434b3118c922f2826060d1314","modified":1475163454000},{"_id":"source/images/2016/06/IMG_20160314_135219--1-.jpg","hash":"2b48b1264806885434b3118c922f2826060d1314","modified":1475163458000},{"_id":"source/images/2016/08/webvr-1-large-1.jpg","hash":"f4a9fafc2be55c8f8d474c02c48e8ac64b7052dd","modified":1475163456000},{"_id":"source/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg","hash":"ff1a2ab4c46138c33112f5c9ac9009fd8158266b","modified":1475163458000},{"_id":"source/images/2016/08/webvr-1-large.jpg","hash":"96721045dda0a5f484e90f245171e2a87e287a5f","modified":1475163456000},{"_id":"source/images/2016/09/logo_a-painter_high-nobrands.jpg","hash":"b9abec6fa570a0334ab26fd4c8f5e37f8b8fddab","modified":1475163458000},{"_id":"source/images/2016/09/menu.jpg","hash":"715162f00ebf8089c243127171e9b103a64d1f30","modified":1475163458000},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1475017306000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1475017306000},{"_id":"source/images/2016/02/c4d-1-1.png","hash":"b487acf0eee2fed4ace5d75002ab247be30103e6","modified":1475163458000},{"_id":"source/images/2016/02/c4d-1.png","hash":"b487acf0eee2fed4ace5d75002ab247be30103e6","modified":1475163458000},{"_id":"source/images/2016/02/mockup1.png","hash":"a12c3e6c0fc76d3bcd2f4c8c148c531b937c094c","modified":1475163458000},{"_id":"source/images/2016/02/mockup3.png","hash":"57f3d5b252d0f1019c2e849071fe5e2488bfcca4","modified":1475163458000},{"_id":"source/images/2016/02/post-splash-1.jpg","hash":"2f4c2f4ba64983b854dc4527747269e843919031","modified":1475163458000},{"_id":"source/images/2016/02/post-splash-3.jpg","hash":"2f4c2f4ba64983b854dc4527747269e843919031","modified":1475163458000},{"_id":"source/images/2016/02/post-splash-4.jpg","hash":"2f4c2f4ba64983b854dc4527747269e843919031","modified":1475163458000},{"_id":"source/images/2016/02/vlad-1.jpg","hash":"f574c1fc92592f3852256a84d4af80d9c1e30936","modified":1475163458000},{"_id":"source/images/2016/09/logo_a-painter_high-1.jpg","hash":"facec5c62d01ab9340c7795489676edf8eb2475a","modified":1475163458000},{"_id":"source/images/2016/09/foxlogo-1.png","hash":"5a9832386c590096d8d88b7aeeafd1eb9f934190","modified":1475163458000},{"_id":"source/images/2016/09/poster.png","hash":"71f1eeaed26d6678eb73149eb234cffd388a420c","modified":1475163458000},{"_id":"source/images/2016/09/logo_a-painter_high.jpg","hash":"facec5c62d01ab9340c7795489676edf8eb2475a","modified":1475163458000},{"_id":"source/images/2016/05/76upLXDc.png","hash":"03fa7ad685c332d87f7e9fd697601a9880e0ea88","modified":1475163456000},{"_id":"source/images/2016/02/artdirection-dc-1.png","hash":"7b03a78a7aaef0936dcba5ace592be350ab07fee","modified":1475163458000},{"_id":"source/images/2016/02/artdirection-dc.png","hash":"7b03a78a7aaef0936dcba5ace592be350ab07fee","modified":1475163458000},{"_id":"source/images/2016/09/foxlogo.png","hash":"119ad79bd8fd0aa34eb15f4a511ce0873a8e8ee9","modified":1475163458000},{"_id":"source/images/2016/02/artdirection-rhv.png","hash":"87bdde1f662f511c2cb9fb0f25ac0d51cc330496","modified":1475163458000},{"_id":"source/images/2016/09/bg.jpg","hash":"62e0b5bbed75630e3a8e20582e15d16bf51f44bd","modified":1475163458000},{"_id":"source/images/2016/08/webvr-1-1.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163458000},{"_id":"source/images/2016/08/webvr-1-3.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163458000},{"_id":"source/images/2016/08/webvr-1-2.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163456000},{"_id":"source/images/2016/08/webvr-1.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163456000},{"_id":"source/images/2016/02/post-splash.jpg","hash":"cabfd321dfc1f77a70c020d3f171bdd30cdc7f7e","modified":1475163458000},{"_id":"source/images/2016/05/home.png","hash":"33a4d7ddf574eb47d7f5f3d3576cb64136fd50ab","modified":1475163454000},{"_id":"source/images/2016/02/post-splash-2.jpg","hash":"b49a22f00baf0b91964b2d84b2de12fb63e7da01","modified":1475163458000},{"_id":"source/images/2016/02/puydesancy.jpg","hash":"eddf6e49fff1b2d49e90a973be58c0117719e17e","modified":1475163458000},{"_id":"source/images/2016/08/ball-throw.gif","hash":"1c453a808fcc621552ebcd69729f8b35dbc6cf83","modified":1475163456000},{"_id":"source/images/2016/02/googleearth-2.png","hash":"d3cdd447b938e2d9d5a67923e596e1fb52e4b7d3","modified":1475163458000},{"_id":"source/images/2016/02/map1.png","hash":"acd5f9710574b04513f234133842fafe014e469d","modified":1475163458000},{"_id":"source/images/2016/09/apainter_painting.gif","hash":"3dd9e634aca5f84e5b88a0bfe5c5114e4ea4213c","modified":1475163458000},{"_id":"source/images/2016/08/v0-3-0-inspector.gif","hash":"64c8b3dd6409b1f73b78ac4ddf0062e2a6866d0d","modified":1475163456000},{"_id":"source/images/2016/05/settings.gif","hash":"76c8341c80569f1c063c0d9594dd6d379710bbde","modified":1475163454000},{"_id":"source/images/2016/08/v0-3-0-1.png","hash":"461f2f53330beed73e052836dcb005f09135c9ec","modified":1475163456000},{"_id":"source/images/2016/08/v0-3-0.png","hash":"461f2f53330beed73e052836dcb005f09135c9ec","modified":1475163456000},{"_id":"source/images/2016/09/apainter_menuc.gif","hash":"df7aa53832f56bbfc5a024d7c0e16b8bb4867ddf","modified":1475163458000},{"_id":"source/images/2016/08/argon.gif","hash":"5d6df3de38cff9e773d813942d12d2ebd6229cc2","modified":1475163456000},{"_id":"source/images/2016/09/spheres-brush.gif","hash":"365f82bc205b00d1e55fc7597a68235f8cdcf19a","modified":1475163458000},{"_id":"source/images/2016/05/me.png","hash":"8c582df958f9291d3a419826417c7b9d3b11b8cb","modified":1475163454000},{"_id":"source/images/2016/08/v0-3-0-roomscale.gif","hash":"7219b1ea80816f42a306467c8b955e60bd9cf9ae","modified":1475163456000},{"_id":"source/content/images/2016/02/josh.jpg","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1475163458000},{"_id":"source/content/images/2016/02/c4d-6.png","hash":"6ccf93386bc6eaa0fc7fb685a4c81da555420794","modified":1475163458000},{"_id":"source/content/images/2016/02/e10s-windows.png","hash":"ef6c73992b92eb279e6338223ba8ce6411860b7b","modified":1475163458000},{"_id":"source/content/images/2016/02/fox-square-200.png","hash":"97c85e9d083153a0d794e8c1b9139a62f48e4473","modified":1475163458000},{"_id":"source/content/images/2016/02/icon-download-2-white-1.svg","hash":"69996ce354bf17b74f7d74f5ef48871d5ba941a7","modified":1475163458000},{"_id":"source/content/images/2016/02/icon-goggles-2-white.svg","hash":"5a830f33ddfb29eddcc1e7e2beb6b4adbd806acd","modified":1475163458000},{"_id":"source/content/images/2016/02/icon-download-2-white.svg","hash":"69996ce354bf17b74f7d74f5ef48871d5ba941a7","modified":1475163458000},{"_id":"source/content/images/2016/02/icon-mozvr-fox-128.png","hash":"68cb7cafa555f1f24b10e069f81c18cdde2269d6","modified":1475163458000},{"_id":"source/content/images/2016/02/josh-1.jpg","hash":"7d7f412ec5b2367e714ca0deb548318099e63963","modified":1475163458000},{"_id":"source/content/images/2016/02/kearwoodlaptop.jpg","hash":"df3fc88335b15017cb5ae76aa6bd5d0535b69b8c","modified":1475163458000},{"_id":"source/content/images/2016/02/photo1.jpg","hash":"4061ffe507363383eac04e10b367e03497ed60bb","modified":1475163458000},{"_id":"source/content/images/2016/05/uninstall.png","hash":"d3a5bb7e55eb8dc355b0d3cd983ae60a8fb895e7","modified":1475163456000},{"_id":"source/content/images/2016/06/w3c_home_nb-v.svg","hash":"bc2202e2d55cca8429ec35fcd7d9cd232b7d84b4","modified":1475163458000},{"_id":"source/content/images/2016/08/w3c.jpg","hash":"4ebd8aa5c6073dda7e887f355e2904c94a3afd80","modified":1475163456000},{"_id":"source/content/images/2016/09/98d3708e-47ec-11e6-817c-4d5fdfba80a9.jpg","hash":"89b3c3aba383148ece5c57cade460c03b8a9fdbf","modified":1475163458000},{"_id":"source/content/images/2016/09/w3c-logo.png","hash":"53ef0b9d975b15576b5b917a80bb5004c9d7967e","modified":1475163458000},{"_id":"source/content/images/2016/09/w3c_home_nb-v.svg","hash":"bc2202e2d55cca8429ec35fcd7d9cd232b7d84b4","modified":1475163458000},{"_id":"source/content/images/2016/02/Screenshot-2016-02-18-16-17-01.png","hash":"ba0cd045ff786aa1625beb497eb90cd768fcbb10","modified":1475163458000},{"_id":"source/content/images/2016/02/human-visual-field.jpg","hash":"6d50dc96f9de4326ea036e9298a8d353957e50db","modified":1475163458000},{"_id":"source/content/images/2016/02/mockup2.png","hash":"95aa1f540ea9c178ddfda760a1a66aa0464236f1","modified":1475163458000},{"_id":"source/content/images/2016/05/PANO_20160314_123750.jpg","hash":"c745a0740cefe5650a85163a771c797efebaf6ea","modified":1475163456000},{"_id":"source/content/images/2016/05/rift_hero.jpg","hash":"6366c45e87e332d668655c65c65beebd4070cf59","modified":1475163456000},{"_id":"source/content/images/2016/05/unknown-sources.jpg","hash":"ceea54fc197b9f71025dc352c3c715e628c633da","modified":1475163454000},{"_id":"source/content/images/2016/06/W3C-_Icon-svg.png","hash":"b9a50d1a2bb069404e5109e97a4e8278daeabdcd","modified":1475163458000},{"_id":"source/content/images/2016/06/w3c.png","hash":"3bf8c1bb592862005a9bfa1cf34093bb396b1d17","modified":1475163458000},{"_id":"source/content/images/2016/09/cvan2.jpg","hash":"9d83f57485a2fba867958a3e037846fc09fd91e0","modified":1475163458000},{"_id":"source/content/images/2016/09/controller_tooltips_medium.jpg","hash":"f3e7d4b7027814f3d09ee455e7705a3e1f7fccd8","modified":1475163458000},{"_id":"source/content/images/2016/09/logo_a-painter_medium.jpg","hash":"eff41931c3ff8ad32d3e2dc30e6076081eb1efae","modified":1475163458000},{"_id":"source/content/images/2016/02/e10s.png","hash":"8f54a299e7bd5417767d709cb64c8523b00f370b","modified":1475163458000},{"_id":"source/content/images/2016/02/sechelt-3.png","hash":"057d10c2f913bce9d5e31a497e7b9157034cbadd","modified":1475163458000},{"_id":"source/content/images/2016/02/visual-field-DK2.png","hash":"813a60bd635e79adec41613749a37ec19cb6a94e","modified":1475163458000},{"_id":"source/content/images/2016/05/CjFZ1n0WYAA8twp-jpg-large.jpg","hash":"7ac345f522cddb9d7f34ccbe0921dbaa02375a00","modified":1475163454000},{"_id":"source/content/images/2016/05/IMG_20160314_123708.jpg","hash":"197d9340d7e42df1c9226e80e2aa7d8ea43a99db","modified":1475163454000},{"_id":"source/content/images/2016/05/IMG_20160315_111705.jpg","hash":"236fa53729a7d5d3aca4fad7884e0093ef885247","modified":1475163454000},{"_id":"source/content/images/2016/05/IMG_20160315_112900.jpg","hash":"11fac8f230b1da863ea513f3d204d091b7a8ffde","modified":1475163454000},{"_id":"source/content/images/2016/05/mozvr.png","hash":"4ba1931851a6f58d33d38e709369811e0a6d092b","modified":1475163456000},{"_id":"source/content/images/2016/06/IMG_20160315_112900--1-.jpg","hash":"11fac8f230b1da863ea513f3d204d091b7a8ffde","modified":1475163458000},{"_id":"source/content/images/2016/06/w3c_icon.png","hash":"f425cd40c88810a6eb74cc8a45ca208fc5395ec6","modified":1475163458000},{"_id":"source/content/images/2016/02/c4d-4.png","hash":"99b5befdd99878365aeab80b0bcec83152dbc662","modified":1475163458000},{"_id":"source/content/images/2016/02/project-splash-1.jpg","hash":"02a62329d8d4feb7a080fdf0375ac8bd68dbe7dc","modified":1475163458000},{"_id":"source/content/images/2016/02/project-splash.jpg","hash":"02a62329d8d4feb7a080fdf0375ac8bd68dbe7dc","modified":1475163458000},{"_id":"source/content/images/2016/05/IMG_20160314_135219.jpg","hash":"2b48b1264806885434b3118c922f2826060d1314","modified":1475163454000},{"_id":"source/content/images/2016/06/IMG_20160314_135219--1-.jpg","hash":"2b48b1264806885434b3118c922f2826060d1314","modified":1475163458000},{"_id":"source/content/images/2016/08/webvr-1-large-1.jpg","hash":"f4a9fafc2be55c8f8d474c02c48e8ac64b7052dd","modified":1475163456000},{"_id":"source/content/images/2016/08/webvr-1-large.jpg","hash":"96721045dda0a5f484e90f245171e2a87e287a5f","modified":1475163456000},{"_id":"source/content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg","hash":"ff1a2ab4c46138c33112f5c9ac9009fd8158266b","modified":1475163458000},{"_id":"source/content/images/2016/09/logo_a-painter_high-nobrands.jpg","hash":"b9abec6fa570a0334ab26fd4c8f5e37f8b8fddab","modified":1475163458000},{"_id":"source/content/images/2016/09/menu.jpg","hash":"715162f00ebf8089c243127171e9b103a64d1f30","modified":1475163458000},{"_id":"source/content/images/2016/02/c4d-1-1.png","hash":"b487acf0eee2fed4ace5d75002ab247be30103e6","modified":1475163458000},{"_id":"source/content/images/2016/02/c4d-1.png","hash":"b487acf0eee2fed4ace5d75002ab247be30103e6","modified":1475163458000},{"_id":"source/content/images/2016/02/mockup1.png","hash":"a12c3e6c0fc76d3bcd2f4c8c148c531b937c094c","modified":1475163458000},{"_id":"source/content/images/2016/02/post-splash-1.jpg","hash":"2f4c2f4ba64983b854dc4527747269e843919031","modified":1475163458000},{"_id":"source/content/images/2016/02/mockup3.png","hash":"57f3d5b252d0f1019c2e849071fe5e2488bfcca4","modified":1475163458000},{"_id":"source/content/images/2016/02/post-splash-4.jpg","hash":"2f4c2f4ba64983b854dc4527747269e843919031","modified":1475163458000},{"_id":"source/content/images/2016/02/post-splash-3.jpg","hash":"2f4c2f4ba64983b854dc4527747269e843919031","modified":1475163458000},{"_id":"source/content/images/2016/02/vlad-1.jpg","hash":"f574c1fc92592f3852256a84d4af80d9c1e30936","modified":1475163458000},{"_id":"source/content/images/2016/09/foxlogo-1.png","hash":"5a9832386c590096d8d88b7aeeafd1eb9f934190","modified":1475163458000},{"_id":"source/content/images/2016/09/logo_a-painter_high-1.jpg","hash":"facec5c62d01ab9340c7795489676edf8eb2475a","modified":1475163458000},{"_id":"source/content/images/2016/09/logo_a-painter_high.jpg","hash":"facec5c62d01ab9340c7795489676edf8eb2475a","modified":1475163458000},{"_id":"source/content/images/2016/09/poster.png","hash":"71f1eeaed26d6678eb73149eb234cffd388a420c","modified":1475163458000},{"_id":"source/content/images/2016/05/76upLXDc.png","hash":"03fa7ad685c332d87f7e9fd697601a9880e0ea88","modified":1475163456000},{"_id":"source/content/images/2016/02/artdirection-dc.png","hash":"7b03a78a7aaef0936dcba5ace592be350ab07fee","modified":1475163458000},{"_id":"source/content/images/2016/02/artdirection-dc-1.png","hash":"7b03a78a7aaef0936dcba5ace592be350ab07fee","modified":1475163458000},{"_id":"source/content/images/2016/09/foxlogo.png","hash":"119ad79bd8fd0aa34eb15f4a511ce0873a8e8ee9","modified":1475163458000},{"_id":"source/content/images/2016/02/artdirection-rhv.png","hash":"87bdde1f662f511c2cb9fb0f25ac0d51cc330496","modified":1475163458000},{"_id":"source/content/images/2016/09/bg.jpg","hash":"62e0b5bbed75630e3a8e20582e15d16bf51f44bd","modified":1475163458000},{"_id":"source/content/images/2016/08/webvr-1-2.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163456000},{"_id":"source/content/images/2016/08/webvr-1-1.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163458000},{"_id":"source/content/images/2016/08/webvr-1-3.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163458000},{"_id":"source/content/images/2016/08/webvr-1.jpg","hash":"18994c6e57c9b21a61d6f0a1f4b09e1b7225e3a1","modified":1475163456000},{"_id":"source/content/images/2016/02/post-splash.jpg","hash":"cabfd321dfc1f77a70c020d3f171bdd30cdc7f7e","modified":1475163458000},{"_id":"source/content/images/2016/05/home.png","hash":"33a4d7ddf574eb47d7f5f3d3576cb64136fd50ab","modified":1475163454000},{"_id":"source/content/images/2016/02/post-splash-2.jpg","hash":"b49a22f00baf0b91964b2d84b2de12fb63e7da01","modified":1475163458000},{"_id":"source/content/images/2016/02/puydesancy.jpg","hash":"eddf6e49fff1b2d49e90a973be58c0117719e17e","modified":1475163458000},{"_id":"source/content/images/2016/08/ball-throw.gif","hash":"1c453a808fcc621552ebcd69729f8b35dbc6cf83","modified":1475163456000},{"_id":"source/content/images/2016/02/googleearth-2.png","hash":"d3cdd447b938e2d9d5a67923e596e1fb52e4b7d3","modified":1475163458000},{"_id":"source/content/images/2016/02/map1.png","hash":"acd5f9710574b04513f234133842fafe014e469d","modified":1475163458000},{"_id":"source/content/images/2016/09/apainter_painting.gif","hash":"3dd9e634aca5f84e5b88a0bfe5c5114e4ea4213c","modified":1475163458000},{"_id":"source/content/images/2016/08/v0-3-0-inspector.gif","hash":"64c8b3dd6409b1f73b78ac4ddf0062e2a6866d0d","modified":1475163456000},{"_id":"source/content/images/2016/05/settings.gif","hash":"76c8341c80569f1c063c0d9594dd6d379710bbde","modified":1475163454000},{"_id":"source/content/images/2016/08/v0-3-0-1.png","hash":"461f2f53330beed73e052836dcb005f09135c9ec","modified":1475163456000},{"_id":"source/content/images/2016/08/v0-3-0.png","hash":"461f2f53330beed73e052836dcb005f09135c9ec","modified":1475163456000},{"_id":"source/content/images/2016/09/apainter_menuc.gif","hash":"df7aa53832f56bbfc5a024d7c0e16b8bb4867ddf","modified":1475163458000},{"_id":"source/content/images/2016/08/argon.gif","hash":"5d6df3de38cff9e773d813942d12d2ebd6229cc2","modified":1475163456000},{"_id":"source/content/images/2016/09/spheres-brush.gif","hash":"365f82bc205b00d1e55fc7597a68235f8cdcf19a","modified":1475163458000},{"_id":"source/content/images/2016/05/me.png","hash":"8c582df958f9291d3a419826417c7b9d3b11b8cb","modified":1475163454000},{"_id":"source/content/images/2016/08/v0-3-0-roomscale.gif","hash":"7219b1ea80816f42a306467c8b955e60bd9cf9ae","modified":1475163456000},{"_id":"source/.DS_Store","hash":"5395d7c570e9247e1168a04be8a39a272e0ab051","modified":1475181995000}],"Category":[],"Data":[],"Page":[{"title":"Getting Started","date":"2016-09-28T00:32:55.000Z","_content":"\nImport from github","source":"start/index.md","raw":"---\ntitle: Getting Started\ndate: 2016-09-27 17:32:55\n---\n\nImport from github","updated":"2016-09-28T00:35:38.000Z","path":"start/index.html","comments":1,"layout":"page","_id":"citot8hyd0002ik1jffn90ncq","content":"<p>Import from github</p>\n","excerpt":"","more":"<p>Import from github</p>\n"}],"Post":[{"title":"Experimental OSVR Support landed in Firefox Nightly","id":"23","updated":"2016-09-24T02:08:13.000Z","_content":"\nSee these links:\n\n* http://sensics.com/osvr-comes-webvr/\n* http://sensics.com/why-webvr/\n* http://sensics.com/tag/webvr/ (tell Sensics to tag \"OSVR Comes to WebVR\" blog post too)\n\nMention the potential and promise of OSVR. Mention its headset too.\n\nAnd acknowledge thanks to everyone involved in reviewing the patch at Mozilla, writing the patch at OSVR, and collaboration between us two.\n","source":"_drafts/Experimental-OSVR-Support-landed-in-Firefox-Nightly.md","raw":"---\ntitle: Experimental OSVR Support landed in Firefox Nightly\npermalink: experimental-osvr-support-landed-in-firefox-nightly\nid: 23\nupdated: '2016-09-23 19:08:13'\ntags:\n---\n\nSee these links:\n\n* http://sensics.com/osvr-comes-webvr/\n* http://sensics.com/why-webvr/\n* http://sensics.com/tag/webvr/ (tell Sensics to tag \"OSVR Comes to WebVR\" blog post too)\n\nMention the potential and promise of OSVR. Mention its headset too.\n\nAnd acknowledge thanks to everyone involved in reviewing the patch at Mozilla, writing the patch at OSVR, and collaboration between us two.\n","slug":"experimental-osvr-support-landed-in-firefox-nightly","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hxk0000ik1j2ea4d15x","content":"<p>See these links:</p>\n<ul>\n<li><a href=\"http://sensics.com/osvr-comes-webvr/\" target=\"_blank\" rel=\"external\">http://sensics.com/osvr-comes-webvr/</a></li>\n<li><a href=\"http://sensics.com/why-webvr/\" target=\"_blank\" rel=\"external\">http://sensics.com/why-webvr/</a></li>\n<li><a href=\"http://sensics.com/tag/webvr/\" target=\"_blank\" rel=\"external\">http://sensics.com/tag/webvr/</a> (tell Sensics to tag OSVR Comes to WebVR blog post too)</li>\n</ul>\n<p>Mention the potential and promise of OSVR. Mention its headset too.</p>\n<p>And acknowledge thanks to everyone involved in reviewing the patch at Mozilla, writing the patch at OSVR, and collaboration between us two.</p>\n","excerpt":"","more":"<p>See these links:</p>\n<ul>\n<li><a href=\"http://sensics.com/osvr-comes-webvr/\">http://sensics.com/osvr-comes-webvr/</a></li>\n<li><a href=\"http://sensics.com/why-webvr/\">http://sensics.com/why-webvr/</a></li>\n<li><a href=\"http://sensics.com/tag/webvr/\">http://sensics.com/tag/webvr/</a> (tell Sensics to tag OSVR Comes to WebVR blog post too)</li>\n</ul>\n<p>Mention the potential and promise of OSVR. Mention its headset too.</p>\n<p>And acknowledge thanks to everyone involved in reviewing the patch at Mozilla, writing the patch at OSVR, and collaboration between us two.</p>\n"},{"title":"Exporting Unity Games to WebVR","id":"20","updated":"2016-09-29T04:52:02.000Z","_content":"\n(Copy contents/link to of https://hacks.mozilla.org/2016/05/exporting-an-indie-unity-game-to-webvr/.)\n\n(Also, reference https://github.com/if1live/unity-scene-web-exporter and any other Unity WebVR projects.)\n\n(Get an update from Unity. Contact Jukka.)\n","source":"_drafts/Exporting-Unity-Games-to-WebVR.md","raw":"---\ntitle: Exporting Unity Games to WebVR\npermalink: exporting-unity-games-to-webvr\nid: 20\nupdated: '2016-09-28 21:52:02'\ntags:\n---\n\n(Copy contents/link to of https://hacks.mozilla.org/2016/05/exporting-an-indie-unity-game-to-webvr/.)\n\n(Also, reference https://github.com/if1live/unity-scene-web-exporter and any other Unity WebVR projects.)\n\n(Get an update from Unity. Contact Jukka.)\n","slug":"exporting-unity-games-to-webvr","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hyc0001ik1jvaw5b2y6","content":"<p>(Copy contents/link to of <a href=\"https://hacks.mozilla.org/2016/05/exporting-an-indie-unity-game-to-webvr/\" target=\"_blank\" rel=\"external\">https://hacks.mozilla.org/2016/05/exporting-an-indie-unity-game-to-webvr/</a>.)</p>\n<p>(Also, reference <a href=\"https://github.com/if1live/unity-scene-web-exporter\" target=\"_blank\" rel=\"external\">https://github.com/if1live/unity-scene-web-exporter</a> and any other Unity WebVR projects.)</p>\n<p>(Get an update from Unity. Contact Jukka.)</p>\n","excerpt":"","more":"<p>(Copy contents/link to of <a href=\"https://hacks.mozilla.org/2016/05/exporting-an-indie-unity-game-to-webvr/\">https://hacks.mozilla.org/2016/05/exporting-an-indie-unity-game-to-webvr/</a>.)</p>\n<p>(Also, reference <a href=\"https://github.com/if1live/unity-scene-web-exporter\">https://github.com/if1live/unity-scene-web-exporter</a> and any other Unity WebVR projects.)</p>\n<p>(Get an update from Unity. Contact Jukka.)</p>\n"},{"title":"Making Sechelt With three.js and Cinema 4D","id":"2","updated":"2016-09-29T04:52:58.000Z","_content":"\nA collaboration with [Ricardo Cabello](https://twitter.com/mrdoob) of [three.js](https://github.com/mrdoob/three.js/). Inspired by the coastline of British Columbia and the work of [Roy Henry Vickers](http://www.royhenryvickers.com/). Created with [Cinema 4D](http://www.maxon.net/products/cinema-4d-studio/), [three.js](https://github.com/mrdoob/three.js/).\n\n![The Cinema 4D setup](/content/images/2016/02/c4d-1.png)\n\n## Basic workflow\n\nThe high-level process that brought Sechelt to life:\n\n*   Scene modeled in Cinema 4D.\n*   Scene optimized by combing geometries and eliminating unnecessary materials.\n*   Scene models exported from Cinema 4D to Collada `.DAE`.\n*   DAE file opened in [three.js Editor](http://threejs.org/editor/).\n*   Scene setup, animation, interactivity, and sound created in three.js.\n*   VR support implemented with `VRControls` and `VREffect` three.js extras.\n\n## Pre Production\n\n### Inspiration and art direction\n\n<!--\nSechelt as location using Google Earth\nRoy Henry Vickers\nDoug Coupland's take on the coast of BC\nJourney, Shape of the World\nSketches\n-->\n\n[Roy Henry Vickers](http://www.royhenryvickers.com/):\n\n![Roy Henry Vickers](/content/images/2016/02/artdirection-rhv.png)\n\n[Douglas Coupland](http://coupland.com/):\n\n![Douglas Coupland](/content/images/2016/02/artdirection-dc-1.png)\n\nGoogle Earth:\n\n![](/content/images/2016/02/photo1.jpg)\n\n### Scouting a location\n\nIt was important to us to capture the reality of BC's coastal landscape, with its steep glacier-carved valleys and it's uncountable forested islands, stretching north from Vancouver to Alaska. To find a location, we used Google Earth to identify promising flight paths and vistas, eventually settling on a path stretching south from a mountain peak to the town of Sechelt.\n\n![The Sechelt scene](/content/images/2016/02/googleearth-2.png)\n![The Motion Camera settings]( \"The Motion Camera settings\")\n\n## Cinema 4D\n\n### Modeling and lighting\n\nThis landscape was then modeled in Cinema 4D using the sculpt tool. Getting the lighting right was critical to achieving the desired look, and performance was a concern, so we opted to use a shader-based system. There are no lights in the scene. The landscape, water, trees etc are all colored with shaders. The fade of the landscape, from purple to light blue as it stretches into the distance, was achieved with a Gradient shader in the landscape material's Luminance channel. The shader is a set to 2000cm, and mapped to the position of the camera, making objects close to the camera dark, and objects further away progressively lighter.\n\n![The Cinema 4D setup](/content/images/2016/02/c4d-1-1.png)\n\n### Camera animation\n\nThe camera animation was defined with Cinema 4D's Motion Camera tool. A spline was carefully modeled, sweeping through the scene. The Motion Camera's path was set to the spline, and the Camera Position then animated from 0 to 100%. At the end I wanted the camera to come to rest in a very precise position, which proved difficult to achieve by tweaking the spline points. So we instead created a second camera, framed it just right, then set the Motion Camera to switch between aligning itself to the spline, and aligning itself to this second camera, at the very end of the sequence. The final effect was seamless.\n\n![The Motion Camera settings](/content/images/2016/02/c4d-6.png)\n\n### Exporting the Cinema 4D assets\n\nTo exporting the assets from Cinema 4D to three.js it was important to get several things right, or we found the results were unwieldy, mismatched, slow, etc. The steps we took were to:\n\n#### 1. Adjust the scale\n\nThe original scene was modeled to match the actual landscape, in meters. This made the units too massive to easily handle, however, so we scaled the scene down to centimeters before exporting.\n\n#### 2. Reduce the number of individual objects by merging\n\nIn Cinema 4D the trees were dozens of individual objects each with their own instance of the tree material. It is important to reduce the number of unique geometries and materials when working with three.js, however, for both performance and logistics reasons. So before we exported the scene, we deleted any unused objects and merged the trees into one single object with one material instance.\n\n#### 3. Clean up the geometry\n\nIf the camera was not going to see something, we deleted it. The meant carving out sections of the landscape, such as the backside of the mountains flanking the valleys.\n\n![The final Sechelt model landscape model. The white line is the camera](/content/images/2016/02/c4d-4.png)\n\n## three.js Implementation\n\n### Importing scene models\n\nWe recreated the Cinema 4D scene in three.js by importing the objects inside the .DAE file with the following:\n\n    var loader = new THREE.ObjectLoader();\n    loader.load( 'c4d-scene.json', function ( object ) {\n\n      var landscape = object.getObjectByName( 'landscape' );\n\n      var reflection = new THREE.Mesh( landscape.geometry, landscape.material.clone() );\n      reflection.material.side = THREE.BackSide;\n      reflection.position.y = 7.7;\n      reflection.scale.y = -1;\n      landscape.parent.add( reflection );\n\n      scene.add( object );\n\n    } );\n\nTo create the effect of the landscape reflecting on the \"water,\" Ricardo actually duplicated the landscape, inverted it on the Y-axis, and moved it down. This seems more convoluted than simply created a water surface with a reflection shader (as we did in the original Cinema 4D scene), but within WebGL this approach is faster and enables finer control over the look of the reflection by modifying the reflection object's materials and other scene objects.\n\n### Ambient sounds\n\nAs the user moves through the scene they hear waves, wildlife, and wind. These sounds are mapped to the environment itself, helping to create a sense of immersion within the 3D world. This effect was achieved by Ricardo, who created null objects in the 3D world, mapped sounds to them, and mapped the playback volume of the sounds to the distance of the user. Sound clips were sourced from [Freesound.org](http://www.freesound.org).\n\n    var listener = new THREE.AudioListener();\n    camera.add( listener );\n\n    var sound = new THREE.Audio( listener );\n    sound.load( 'sounds/78389__inchadney__seagulls.ogg' );\n    sound.position.set( 475, 50, 850 );\n    sound.setLoop( true );\n    sound.setRefDistance( 100 );\n    scene.add( sound );\n\n### Camera system\n\nWe were inspired by the app Eden River to implement a control scheme that was completely hands free and intuitive. As users fly through the Sechelt scene, their position travels along the path that was defined in Cinema 4D. By tilting their head, however, they can \"bank\" the camera, like a plane, to steer left and right, deviating slightly in the direction they wish to go. This feels a bit like flying a plane. We love this control scheme because 1) it takes advantage of the head set's innate head tracking capabilities, 2) it is entirely optional, with new users able to enjoy their experience even if they never discover the head-tilt mechanic, 3) it does not require an external input device, and 4) it is so satisfying.\n\nRicardo implemented this control scheme in three.js by creating a dolly system that tracks both the user's headset data and the position of the camera on the pre-defined path, and then averages them.\n\n    if ( cameraPath !== undefined ) {\n\n      var time = ( performance.now() / 40000 ) % 1;\n\n      var pointA = cameraPath.getPointAt( time );\n      var pointB = cameraPath.getPointAt( Math.min( time + 0.015, 1 ) );\n\n      pointA.z = -pointA.z;\n      pointB.z = -pointB.z;\n\n      dolly.position.copy( pointA );\n      dolly.lookAt( pointB );\n\n      dolly.rotateY( Math.PI ); // look forward\n\n    }\n\n    controls.update();\n\n    sky.position.copy( dolly.position );\n\n    water.position.x = dolly.position.x;\n    water.position.z = dolly.position.z;\n\n    effect.render( scene, camera );\n\nTo bring camera data from Cinema 4D into three.js, we exported the individual points that define the camera path in C4D as ASCII text, and then imported them into three.js using an importer that Ricardo wrote:\n\n    var loader = new THREE.C4DLineLoader();\n    loader.load( 'flightpath-ascii.txt', function ( line ) {\n\n      cameraPath = line;\n\n    } );\n\n## Testing & Optimization\n\n### Adding VR headset support\n\nSupport for VR headsets was implemented with two three.js components: `VRControls` and `VREffect`. These take the scene and enable VR headset support.\n\n### Testing\n\nWe tested the results with DK1 and DK2 headsets and random coworkers, trying to find people who were particularly sensitive to the nausea and disorientation that VR can produce if not properly calibrated.\n\n### Deployment\n\nFor the start of the development process we simple worked out of a Dropbox folder, with Ricardo saving this progress as he went. Our standard process is to use Git, NPM and Gulp track changes, manage dependencies and automate various development tasks, but early in the process we were more concerned with quick results, and with just Ricardo doing the code a simple setup was good enough. Before deploying, however, we organized the code and pushed to GitHub, hosting everything with [GitHub Pages](https://pages.github.com), using [gulp-gh-pages](https://www.npmjs.org/package/gulp-gh-pages) to automate the process.\n","source":"_drafts/Making-Sechelt-With-three-js-and-Cinema-4D.md","raw":"---\ntitle: Making Sechelt With three.js and Cinema 4D\npermalink: making-sechelt-with-three-js-and-cinema-4d\nid: 2\nupdated: '2016-09-28 21:52:58'\ntags:\n---\n\nA collaboration with [Ricardo Cabello](https://twitter.com/mrdoob) of [three.js](https://github.com/mrdoob/three.js/). Inspired by the coastline of British Columbia and the work of [Roy Henry Vickers](http://www.royhenryvickers.com/). Created with [Cinema 4D](http://www.maxon.net/products/cinema-4d-studio/), [three.js](https://github.com/mrdoob/three.js/).\n\n![The Cinema 4D setup](/content/images/2016/02/c4d-1.png)\n\n## Basic workflow\n\nThe high-level process that brought Sechelt to life:\n\n*   Scene modeled in Cinema 4D.\n*   Scene optimized by combing geometries and eliminating unnecessary materials.\n*   Scene models exported from Cinema 4D to Collada `.DAE`.\n*   DAE file opened in [three.js Editor](http://threejs.org/editor/).\n*   Scene setup, animation, interactivity, and sound created in three.js.\n*   VR support implemented with `VRControls` and `VREffect` three.js extras.\n\n## Pre Production\n\n### Inspiration and art direction\n\n<!--\nSechelt as location using Google Earth\nRoy Henry Vickers\nDoug Coupland's take on the coast of BC\nJourney, Shape of the World\nSketches\n-->\n\n[Roy Henry Vickers](http://www.royhenryvickers.com/):\n\n![Roy Henry Vickers](/content/images/2016/02/artdirection-rhv.png)\n\n[Douglas Coupland](http://coupland.com/):\n\n![Douglas Coupland](/content/images/2016/02/artdirection-dc-1.png)\n\nGoogle Earth:\n\n![](/content/images/2016/02/photo1.jpg)\n\n### Scouting a location\n\nIt was important to us to capture the reality of BC's coastal landscape, with its steep glacier-carved valleys and it's uncountable forested islands, stretching north from Vancouver to Alaska. To find a location, we used Google Earth to identify promising flight paths and vistas, eventually settling on a path stretching south from a mountain peak to the town of Sechelt.\n\n![The Sechelt scene](/content/images/2016/02/googleearth-2.png)\n![The Motion Camera settings]( \"The Motion Camera settings\")\n\n## Cinema 4D\n\n### Modeling and lighting\n\nThis landscape was then modeled in Cinema 4D using the sculpt tool. Getting the lighting right was critical to achieving the desired look, and performance was a concern, so we opted to use a shader-based system. There are no lights in the scene. The landscape, water, trees etc are all colored with shaders. The fade of the landscape, from purple to light blue as it stretches into the distance, was achieved with a Gradient shader in the landscape material's Luminance channel. The shader is a set to 2000cm, and mapped to the position of the camera, making objects close to the camera dark, and objects further away progressively lighter.\n\n![The Cinema 4D setup](/content/images/2016/02/c4d-1-1.png)\n\n### Camera animation\n\nThe camera animation was defined with Cinema 4D's Motion Camera tool. A spline was carefully modeled, sweeping through the scene. The Motion Camera's path was set to the spline, and the Camera Position then animated from 0 to 100%. At the end I wanted the camera to come to rest in a very precise position, which proved difficult to achieve by tweaking the spline points. So we instead created a second camera, framed it just right, then set the Motion Camera to switch between aligning itself to the spline, and aligning itself to this second camera, at the very end of the sequence. The final effect was seamless.\n\n![The Motion Camera settings](/content/images/2016/02/c4d-6.png)\n\n### Exporting the Cinema 4D assets\n\nTo exporting the assets from Cinema 4D to three.js it was important to get several things right, or we found the results were unwieldy, mismatched, slow, etc. The steps we took were to:\n\n#### 1. Adjust the scale\n\nThe original scene was modeled to match the actual landscape, in meters. This made the units too massive to easily handle, however, so we scaled the scene down to centimeters before exporting.\n\n#### 2. Reduce the number of individual objects by merging\n\nIn Cinema 4D the trees were dozens of individual objects each with their own instance of the tree material. It is important to reduce the number of unique geometries and materials when working with three.js, however, for both performance and logistics reasons. So before we exported the scene, we deleted any unused objects and merged the trees into one single object with one material instance.\n\n#### 3. Clean up the geometry\n\nIf the camera was not going to see something, we deleted it. The meant carving out sections of the landscape, such as the backside of the mountains flanking the valleys.\n\n![The final Sechelt model landscape model. The white line is the camera](/content/images/2016/02/c4d-4.png)\n\n## three.js Implementation\n\n### Importing scene models\n\nWe recreated the Cinema 4D scene in three.js by importing the objects inside the .DAE file with the following:\n\n    var loader = new THREE.ObjectLoader();\n    loader.load( 'c4d-scene.json', function ( object ) {\n\n      var landscape = object.getObjectByName( 'landscape' );\n\n      var reflection = new THREE.Mesh( landscape.geometry, landscape.material.clone() );\n      reflection.material.side = THREE.BackSide;\n      reflection.position.y = 7.7;\n      reflection.scale.y = -1;\n      landscape.parent.add( reflection );\n\n      scene.add( object );\n\n    } );\n\nTo create the effect of the landscape reflecting on the \"water,\" Ricardo actually duplicated the landscape, inverted it on the Y-axis, and moved it down. This seems more convoluted than simply created a water surface with a reflection shader (as we did in the original Cinema 4D scene), but within WebGL this approach is faster and enables finer control over the look of the reflection by modifying the reflection object's materials and other scene objects.\n\n### Ambient sounds\n\nAs the user moves through the scene they hear waves, wildlife, and wind. These sounds are mapped to the environment itself, helping to create a sense of immersion within the 3D world. This effect was achieved by Ricardo, who created null objects in the 3D world, mapped sounds to them, and mapped the playback volume of the sounds to the distance of the user. Sound clips were sourced from [Freesound.org](http://www.freesound.org).\n\n    var listener = new THREE.AudioListener();\n    camera.add( listener );\n\n    var sound = new THREE.Audio( listener );\n    sound.load( 'sounds/78389__inchadney__seagulls.ogg' );\n    sound.position.set( 475, 50, 850 );\n    sound.setLoop( true );\n    sound.setRefDistance( 100 );\n    scene.add( sound );\n\n### Camera system\n\nWe were inspired by the app Eden River to implement a control scheme that was completely hands free and intuitive. As users fly through the Sechelt scene, their position travels along the path that was defined in Cinema 4D. By tilting their head, however, they can \"bank\" the camera, like a plane, to steer left and right, deviating slightly in the direction they wish to go. This feels a bit like flying a plane. We love this control scheme because 1) it takes advantage of the head set's innate head tracking capabilities, 2) it is entirely optional, with new users able to enjoy their experience even if they never discover the head-tilt mechanic, 3) it does not require an external input device, and 4) it is so satisfying.\n\nRicardo implemented this control scheme in three.js by creating a dolly system that tracks both the user's headset data and the position of the camera on the pre-defined path, and then averages them.\n\n    if ( cameraPath !== undefined ) {\n\n      var time = ( performance.now() / 40000 ) % 1;\n\n      var pointA = cameraPath.getPointAt( time );\n      var pointB = cameraPath.getPointAt( Math.min( time + 0.015, 1 ) );\n\n      pointA.z = -pointA.z;\n      pointB.z = -pointB.z;\n\n      dolly.position.copy( pointA );\n      dolly.lookAt( pointB );\n\n      dolly.rotateY( Math.PI ); // look forward\n\n    }\n\n    controls.update();\n\n    sky.position.copy( dolly.position );\n\n    water.position.x = dolly.position.x;\n    water.position.z = dolly.position.z;\n\n    effect.render( scene, camera );\n\nTo bring camera data from Cinema 4D into three.js, we exported the individual points that define the camera path in C4D as ASCII text, and then imported them into three.js using an importer that Ricardo wrote:\n\n    var loader = new THREE.C4DLineLoader();\n    loader.load( 'flightpath-ascii.txt', function ( line ) {\n\n      cameraPath = line;\n\n    } );\n\n## Testing & Optimization\n\n### Adding VR headset support\n\nSupport for VR headsets was implemented with two three.js components: `VRControls` and `VREffect`. These take the scene and enable VR headset support.\n\n### Testing\n\nWe tested the results with DK1 and DK2 headsets and random coworkers, trying to find people who were particularly sensitive to the nausea and disorientation that VR can produce if not properly calibrated.\n\n### Deployment\n\nFor the start of the development process we simple worked out of a Dropbox folder, with Ricardo saving this progress as he went. Our standard process is to use Git, NPM and Gulp track changes, manage dependencies and automate various development tasks, but early in the process we were more concerned with quick results, and with just Ricardo doing the code a simple setup was good enough. Before deploying, however, we organized the code and pushed to GitHub, hosting everything with [GitHub Pages](https://pages.github.com), using [gulp-gh-pages](https://www.npmjs.org/package/gulp-gh-pages) to automate the process.\n","slug":"making-sechelt-with-three-js-and-cinema-4d","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hye0003ik1jr67mw37t","content":"<p>A collaboration with <a href=\"https://twitter.com/mrdoob\" target=\"_blank\" rel=\"external\">Ricardo Cabello</a> of <a href=\"https://github.com/mrdoob/three.js/\" target=\"_blank\" rel=\"external\">three.js</a>. Inspired by the coastline of British Columbia and the work of <a href=\"http://www.royhenryvickers.com/\" target=\"_blank\" rel=\"external\">Roy Henry Vickers</a>. Created with <a href=\"http://www.maxon.net/products/cinema-4d-studio/\" target=\"_blank\" rel=\"external\">Cinema 4D</a>, <a href=\"https://github.com/mrdoob/three.js/\" target=\"_blank\" rel=\"external\">three.js</a>.</p>\n<p><img src=\"/content/images/2016/02/c4d-1.png\" alt=\"The Cinema 4D setup\"></p>\n<h2 id=\"Basic-workflow\"><a href=\"#Basic-workflow\" class=\"headerlink\" title=\"Basic workflow\"></a>Basic workflow</h2><p>The high-level process that brought Sechelt to life:</p>\n<ul>\n<li>Scene modeled in Cinema 4D.</li>\n<li>Scene optimized by combing geometries and eliminating unnecessary materials.</li>\n<li>Scene models exported from Cinema 4D to Collada <code>.DAE</code>.</li>\n<li>DAE file opened in <a href=\"http://threejs.org/editor/\" target=\"_blank\" rel=\"external\">three.js Editor</a>.</li>\n<li>Scene setup, animation, interactivity, and sound created in three.js.</li>\n<li>VR support implemented with <code>VRControls</code> and <code>VREffect</code> three.js extras.</li>\n</ul>\n<h2 id=\"Pre-Production\"><a href=\"#Pre-Production\" class=\"headerlink\" title=\"Pre Production\"></a>Pre Production</h2><h3 id=\"Inspiration-and-art-direction\"><a href=\"#Inspiration-and-art-direction\" class=\"headerlink\" title=\"Inspiration and art direction\"></a>Inspiration and art direction</h3><!--\nSechelt as location using Google Earth\nRoy Henry Vickers\nDoug Coupland's take on the coast of BC\nJourney, Shape of the World\nSketches\n-->\n<p><a href=\"http://www.royhenryvickers.com/\" target=\"_blank\" rel=\"external\">Roy Henry Vickers</a>:</p>\n<p><img src=\"/content/images/2016/02/artdirection-rhv.png\" alt=\"Roy Henry Vickers\"></p>\n<p><a href=\"http://coupland.com/\" target=\"_blank\" rel=\"external\">Douglas Coupland</a>:</p>\n<p><img src=\"/content/images/2016/02/artdirection-dc-1.png\" alt=\"Douglas Coupland\"></p>\n<p>Google Earth:</p>\n<p><img src=\"/content/images/2016/02/photo1.jpg\" alt=\"\"></p>\n<h3 id=\"Scouting-a-location\"><a href=\"#Scouting-a-location\" class=\"headerlink\" title=\"Scouting a location\"></a>Scouting a location</h3><p>It was important to us to capture the reality of BCs coastal landscape, with its steep glacier-carved valleys and its uncountable forested islands, stretching north from Vancouver to Alaska. To find a location, we used Google Earth to identify promising flight paths and vistas, eventually settling on a path stretching south from a mountain peak to the town of Sechelt.</p>\n<p><img src=\"/content/images/2016/02/googleearth-2.png\" alt=\"The Sechelt scene\"><br><img src=\"&quot;The Motion Camera settings&quot;\" alt=\"The Motion Camera settings\"></p>\n<h2 id=\"Cinema-4D\"><a href=\"#Cinema-4D\" class=\"headerlink\" title=\"Cinema 4D\"></a>Cinema 4D</h2><h3 id=\"Modeling-and-lighting\"><a href=\"#Modeling-and-lighting\" class=\"headerlink\" title=\"Modeling and lighting\"></a>Modeling and lighting</h3><p>This landscape was then modeled in Cinema 4D using the sculpt tool. Getting the lighting right was critical to achieving the desired look, and performance was a concern, so we opted to use a shader-based system. There are no lights in the scene. The landscape, water, trees etc are all colored with shaders. The fade of the landscape, from purple to light blue as it stretches into the distance, was achieved with a Gradient shader in the landscape materials Luminance channel. The shader is a set to 2000cm, and mapped to the position of the camera, making objects close to the camera dark, and objects further away progressively lighter.</p>\n<p><img src=\"/content/images/2016/02/c4d-1-1.png\" alt=\"The Cinema 4D setup\"></p>\n<h3 id=\"Camera-animation\"><a href=\"#Camera-animation\" class=\"headerlink\" title=\"Camera animation\"></a>Camera animation</h3><p>The camera animation was defined with Cinema 4Ds Motion Camera tool. A spline was carefully modeled, sweeping through the scene. The Motion Cameras path was set to the spline, and the Camera Position then animated from 0 to 100%. At the end I wanted the camera to come to rest in a very precise position, which proved difficult to achieve by tweaking the spline points. So we instead created a second camera, framed it just right, then set the Motion Camera to switch between aligning itself to the spline, and aligning itself to this second camera, at the very end of the sequence. The final effect was seamless.</p>\n<p><img src=\"/content/images/2016/02/c4d-6.png\" alt=\"The Motion Camera settings\"></p>\n<h3 id=\"Exporting-the-Cinema-4D-assets\"><a href=\"#Exporting-the-Cinema-4D-assets\" class=\"headerlink\" title=\"Exporting the Cinema 4D assets\"></a>Exporting the Cinema 4D assets</h3><p>To exporting the assets from Cinema 4D to three.js it was important to get several things right, or we found the results were unwieldy, mismatched, slow, etc. The steps we took were to:</p>\n<h4 id=\"1-Adjust-the-scale\"><a href=\"#1-Adjust-the-scale\" class=\"headerlink\" title=\"1. Adjust the scale\"></a>1. Adjust the scale</h4><p>The original scene was modeled to match the actual landscape, in meters. This made the units too massive to easily handle, however, so we scaled the scene down to centimeters before exporting.</p>\n<h4 id=\"2-Reduce-the-number-of-individual-objects-by-merging\"><a href=\"#2-Reduce-the-number-of-individual-objects-by-merging\" class=\"headerlink\" title=\"2. Reduce the number of individual objects by merging\"></a>2. Reduce the number of individual objects by merging</h4><p>In Cinema 4D the trees were dozens of individual objects each with their own instance of the tree material. It is important to reduce the number of unique geometries and materials when working with three.js, however, for both performance and logistics reasons. So before we exported the scene, we deleted any unused objects and merged the trees into one single object with one material instance.</p>\n<h4 id=\"3-Clean-up-the-geometry\"><a href=\"#3-Clean-up-the-geometry\" class=\"headerlink\" title=\"3. Clean up the geometry\"></a>3. Clean up the geometry</h4><p>If the camera was not going to see something, we deleted it. The meant carving out sections of the landscape, such as the backside of the mountains flanking the valleys.</p>\n<p><img src=\"/content/images/2016/02/c4d-4.png\" alt=\"The final Sechelt model landscape model. The white line is the camera\"></p>\n<h2 id=\"three-js-Implementation\"><a href=\"#three-js-Implementation\" class=\"headerlink\" title=\"three.js Implementation\"></a>three.js Implementation</h2><h3 id=\"Importing-scene-models\"><a href=\"#Importing-scene-models\" class=\"headerlink\" title=\"Importing scene models\"></a>Importing scene models</h3><p>We recreated the Cinema 4D scene in three.js by importing the objects inside the .DAE file with the following:</p>\n<pre><code>var loader = new THREE.ObjectLoader();\nloader.load( &apos;c4d-scene.json&apos;, function ( object ) {\n\n  var landscape = object.getObjectByName( &apos;landscape&apos; );\n\n  var reflection = new THREE.Mesh( landscape.geometry, landscape.material.clone() );\n  reflection.material.side = THREE.BackSide;\n  reflection.position.y = 7.7;\n  reflection.scale.y = -1;\n  landscape.parent.add( reflection );\n\n  scene.add( object );\n\n} );\n</code></pre><p>To create the effect of the landscape reflecting on the water, Ricardo actually duplicated the landscape, inverted it on the Y-axis, and moved it down. This seems more convoluted than simply created a water surface with a reflection shader (as we did in the original Cinema 4D scene), but within WebGL this approach is faster and enables finer control over the look of the reflection by modifying the reflection objects materials and other scene objects.</p>\n<h3 id=\"Ambient-sounds\"><a href=\"#Ambient-sounds\" class=\"headerlink\" title=\"Ambient sounds\"></a>Ambient sounds</h3><p>As the user moves through the scene they hear waves, wildlife, and wind. These sounds are mapped to the environment itself, helping to create a sense of immersion within the 3D world. This effect was achieved by Ricardo, who created null objects in the 3D world, mapped sounds to them, and mapped the playback volume of the sounds to the distance of the user. Sound clips were sourced from <a href=\"http://www.freesound.org\" target=\"_blank\" rel=\"external\">Freesound.org</a>.</p>\n<pre><code>var listener = new THREE.AudioListener();\ncamera.add( listener );\n\nvar sound = new THREE.Audio( listener );\nsound.load( &apos;sounds/78389__inchadney__seagulls.ogg&apos; );\nsound.position.set( 475, 50, 850 );\nsound.setLoop( true );\nsound.setRefDistance( 100 );\nscene.add( sound );\n</code></pre><h3 id=\"Camera-system\"><a href=\"#Camera-system\" class=\"headerlink\" title=\"Camera system\"></a>Camera system</h3><p>We were inspired by the app Eden River to implement a control scheme that was completely hands free and intuitive. As users fly through the Sechelt scene, their position travels along the path that was defined in Cinema 4D. By tilting their head, however, they can bank the camera, like a plane, to steer left and right, deviating slightly in the direction they wish to go. This feels a bit like flying a plane. We love this control scheme because 1) it takes advantage of the head sets innate head tracking capabilities, 2) it is entirely optional, with new users able to enjoy their experience even if they never discover the head-tilt mechanic, 3) it does not require an external input device, and 4) it is so satisfying.</p>\n<p>Ricardo implemented this control scheme in three.js by creating a dolly system that tracks both the users headset data and the position of the camera on the pre-defined path, and then averages them.</p>\n<pre><code>if ( cameraPath !== undefined ) {\n\n  var time = ( performance.now() / 40000 ) % 1;\n\n  var pointA = cameraPath.getPointAt( time );\n  var pointB = cameraPath.getPointAt( Math.min( time + 0.015, 1 ) );\n\n  pointA.z = -pointA.z;\n  pointB.z = -pointB.z;\n\n  dolly.position.copy( pointA );\n  dolly.lookAt( pointB );\n\n  dolly.rotateY( Math.PI ); // look forward\n\n}\n\ncontrols.update();\n\nsky.position.copy( dolly.position );\n\nwater.position.x = dolly.position.x;\nwater.position.z = dolly.position.z;\n\neffect.render( scene, camera );\n</code></pre><p>To bring camera data from Cinema 4D into three.js, we exported the individual points that define the camera path in C4D as ASCII text, and then imported them into three.js using an importer that Ricardo wrote:</p>\n<pre><code>var loader = new THREE.C4DLineLoader();\nloader.load( &apos;flightpath-ascii.txt&apos;, function ( line ) {\n\n  cameraPath = line;\n\n} );\n</code></pre><h2 id=\"Testing-amp-Optimization\"><a href=\"#Testing-amp-Optimization\" class=\"headerlink\" title=\"Testing &amp; Optimization\"></a>Testing &amp; Optimization</h2><h3 id=\"Adding-VR-headset-support\"><a href=\"#Adding-VR-headset-support\" class=\"headerlink\" title=\"Adding VR headset support\"></a>Adding VR headset support</h3><p>Support for VR headsets was implemented with two three.js components: <code>VRControls</code> and <code>VREffect</code>. These take the scene and enable VR headset support.</p>\n<h3 id=\"Testing\"><a href=\"#Testing\" class=\"headerlink\" title=\"Testing\"></a>Testing</h3><p>We tested the results with DK1 and DK2 headsets and random coworkers, trying to find people who were particularly sensitive to the nausea and disorientation that VR can produce if not properly calibrated.</p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>For the start of the development process we simple worked out of a Dropbox folder, with Ricardo saving this progress as he went. Our standard process is to use Git, NPM and Gulp track changes, manage dependencies and automate various development tasks, but early in the process we were more concerned with quick results, and with just Ricardo doing the code a simple setup was good enough. Before deploying, however, we organized the code and pushed to GitHub, hosting everything with <a href=\"https://pages.github.com\" target=\"_blank\" rel=\"external\">GitHub Pages</a>, using <a href=\"https://www.npmjs.org/package/gulp-gh-pages\" target=\"_blank\" rel=\"external\">gulp-gh-pages</a> to automate the process.</p>\n","excerpt":"","more":"<p>A collaboration with <a href=\"https://twitter.com/mrdoob\">Ricardo Cabello</a> of <a href=\"https://github.com/mrdoob/three.js/\">three.js</a>. Inspired by the coastline of British Columbia and the work of <a href=\"http://www.royhenryvickers.com/\">Roy Henry Vickers</a>. Created with <a href=\"http://www.maxon.net/products/cinema-4d-studio/\">Cinema 4D</a>, <a href=\"https://github.com/mrdoob/three.js/\">three.js</a>.</p>\n<p><img src=\"/content/images/2016/02/c4d-1.png\" alt=\"The Cinema 4D setup\"></p>\n<h2 id=\"Basic-workflow\"><a href=\"#Basic-workflow\" class=\"headerlink\" title=\"Basic workflow\"></a>Basic workflow</h2><p>The high-level process that brought Sechelt to life:</p>\n<ul>\n<li>Scene modeled in Cinema 4D.</li>\n<li>Scene optimized by combing geometries and eliminating unnecessary materials.</li>\n<li>Scene models exported from Cinema 4D to Collada <code>.DAE</code>.</li>\n<li>DAE file opened in <a href=\"http://threejs.org/editor/\">three.js Editor</a>.</li>\n<li>Scene setup, animation, interactivity, and sound created in three.js.</li>\n<li>VR support implemented with <code>VRControls</code> and <code>VREffect</code> three.js extras.</li>\n</ul>\n<h2 id=\"Pre-Production\"><a href=\"#Pre-Production\" class=\"headerlink\" title=\"Pre Production\"></a>Pre Production</h2><h3 id=\"Inspiration-and-art-direction\"><a href=\"#Inspiration-and-art-direction\" class=\"headerlink\" title=\"Inspiration and art direction\"></a>Inspiration and art direction</h3><!--\nSechelt as location using Google Earth\nRoy Henry Vickers\nDoug Coupland's take on the coast of BC\nJourney, Shape of the World\nSketches\n-->\n<p><a href=\"http://www.royhenryvickers.com/\">Roy Henry Vickers</a>:</p>\n<p><img src=\"/content/images/2016/02/artdirection-rhv.png\" alt=\"Roy Henry Vickers\"></p>\n<p><a href=\"http://coupland.com/\">Douglas Coupland</a>:</p>\n<p><img src=\"/content/images/2016/02/artdirection-dc-1.png\" alt=\"Douglas Coupland\"></p>\n<p>Google Earth:</p>\n<p><img src=\"/content/images/2016/02/photo1.jpg\" alt=\"\"></p>\n<h3 id=\"Scouting-a-location\"><a href=\"#Scouting-a-location\" class=\"headerlink\" title=\"Scouting a location\"></a>Scouting a location</h3><p>It was important to us to capture the reality of BCs coastal landscape, with its steep glacier-carved valleys and its uncountable forested islands, stretching north from Vancouver to Alaska. To find a location, we used Google Earth to identify promising flight paths and vistas, eventually settling on a path stretching south from a mountain peak to the town of Sechelt.</p>\n<p><img src=\"/content/images/2016/02/googleearth-2.png\" alt=\"The Sechelt scene\"><br><img src=\"&quot;The Motion Camera settings&quot;\" alt=\"The Motion Camera settings\"></p>\n<h2 id=\"Cinema-4D\"><a href=\"#Cinema-4D\" class=\"headerlink\" title=\"Cinema 4D\"></a>Cinema 4D</h2><h3 id=\"Modeling-and-lighting\"><a href=\"#Modeling-and-lighting\" class=\"headerlink\" title=\"Modeling and lighting\"></a>Modeling and lighting</h3><p>This landscape was then modeled in Cinema 4D using the sculpt tool. Getting the lighting right was critical to achieving the desired look, and performance was a concern, so we opted to use a shader-based system. There are no lights in the scene. The landscape, water, trees etc are all colored with shaders. The fade of the landscape, from purple to light blue as it stretches into the distance, was achieved with a Gradient shader in the landscape materials Luminance channel. The shader is a set to 2000cm, and mapped to the position of the camera, making objects close to the camera dark, and objects further away progressively lighter.</p>\n<p><img src=\"/content/images/2016/02/c4d-1-1.png\" alt=\"The Cinema 4D setup\"></p>\n<h3 id=\"Camera-animation\"><a href=\"#Camera-animation\" class=\"headerlink\" title=\"Camera animation\"></a>Camera animation</h3><p>The camera animation was defined with Cinema 4Ds Motion Camera tool. A spline was carefully modeled, sweeping through the scene. The Motion Cameras path was set to the spline, and the Camera Position then animated from 0 to 100%. At the end I wanted the camera to come to rest in a very precise position, which proved difficult to achieve by tweaking the spline points. So we instead created a second camera, framed it just right, then set the Motion Camera to switch between aligning itself to the spline, and aligning itself to this second camera, at the very end of the sequence. The final effect was seamless.</p>\n<p><img src=\"/content/images/2016/02/c4d-6.png\" alt=\"The Motion Camera settings\"></p>\n<h3 id=\"Exporting-the-Cinema-4D-assets\"><a href=\"#Exporting-the-Cinema-4D-assets\" class=\"headerlink\" title=\"Exporting the Cinema 4D assets\"></a>Exporting the Cinema 4D assets</h3><p>To exporting the assets from Cinema 4D to three.js it was important to get several things right, or we found the results were unwieldy, mismatched, slow, etc. The steps we took were to:</p>\n<h4 id=\"1-Adjust-the-scale\"><a href=\"#1-Adjust-the-scale\" class=\"headerlink\" title=\"1. Adjust the scale\"></a>1. Adjust the scale</h4><p>The original scene was modeled to match the actual landscape, in meters. This made the units too massive to easily handle, however, so we scaled the scene down to centimeters before exporting.</p>\n<h4 id=\"2-Reduce-the-number-of-individual-objects-by-merging\"><a href=\"#2-Reduce-the-number-of-individual-objects-by-merging\" class=\"headerlink\" title=\"2. Reduce the number of individual objects by merging\"></a>2. Reduce the number of individual objects by merging</h4><p>In Cinema 4D the trees were dozens of individual objects each with their own instance of the tree material. It is important to reduce the number of unique geometries and materials when working with three.js, however, for both performance and logistics reasons. So before we exported the scene, we deleted any unused objects and merged the trees into one single object with one material instance.</p>\n<h4 id=\"3-Clean-up-the-geometry\"><a href=\"#3-Clean-up-the-geometry\" class=\"headerlink\" title=\"3. Clean up the geometry\"></a>3. Clean up the geometry</h4><p>If the camera was not going to see something, we deleted it. The meant carving out sections of the landscape, such as the backside of the mountains flanking the valleys.</p>\n<p><img src=\"/content/images/2016/02/c4d-4.png\" alt=\"The final Sechelt model landscape model. The white line is the camera\"></p>\n<h2 id=\"three-js-Implementation\"><a href=\"#three-js-Implementation\" class=\"headerlink\" title=\"three.js Implementation\"></a>three.js Implementation</h2><h3 id=\"Importing-scene-models\"><a href=\"#Importing-scene-models\" class=\"headerlink\" title=\"Importing scene models\"></a>Importing scene models</h3><p>We recreated the Cinema 4D scene in three.js by importing the objects inside the .DAE file with the following:</p>\n<pre><code>var loader = new THREE.ObjectLoader();\nloader.load( &apos;c4d-scene.json&apos;, function ( object ) {\n\n  var landscape = object.getObjectByName( &apos;landscape&apos; );\n\n  var reflection = new THREE.Mesh( landscape.geometry, landscape.material.clone() );\n  reflection.material.side = THREE.BackSide;\n  reflection.position.y = 7.7;\n  reflection.scale.y = -1;\n  landscape.parent.add( reflection );\n\n  scene.add( object );\n\n} );\n</code></pre><p>To create the effect of the landscape reflecting on the water, Ricardo actually duplicated the landscape, inverted it on the Y-axis, and moved it down. This seems more convoluted than simply created a water surface with a reflection shader (as we did in the original Cinema 4D scene), but within WebGL this approach is faster and enables finer control over the look of the reflection by modifying the reflection objects materials and other scene objects.</p>\n<h3 id=\"Ambient-sounds\"><a href=\"#Ambient-sounds\" class=\"headerlink\" title=\"Ambient sounds\"></a>Ambient sounds</h3><p>As the user moves through the scene they hear waves, wildlife, and wind. These sounds are mapped to the environment itself, helping to create a sense of immersion within the 3D world. This effect was achieved by Ricardo, who created null objects in the 3D world, mapped sounds to them, and mapped the playback volume of the sounds to the distance of the user. Sound clips were sourced from <a href=\"http://www.freesound.org\">Freesound.org</a>.</p>\n<pre><code>var listener = new THREE.AudioListener();\ncamera.add( listener );\n\nvar sound = new THREE.Audio( listener );\nsound.load( &apos;sounds/78389__inchadney__seagulls.ogg&apos; );\nsound.position.set( 475, 50, 850 );\nsound.setLoop( true );\nsound.setRefDistance( 100 );\nscene.add( sound );\n</code></pre><h3 id=\"Camera-system\"><a href=\"#Camera-system\" class=\"headerlink\" title=\"Camera system\"></a>Camera system</h3><p>We were inspired by the app Eden River to implement a control scheme that was completely hands free and intuitive. As users fly through the Sechelt scene, their position travels along the path that was defined in Cinema 4D. By tilting their head, however, they can bank the camera, like a plane, to steer left and right, deviating slightly in the direction they wish to go. This feels a bit like flying a plane. We love this control scheme because 1) it takes advantage of the head sets innate head tracking capabilities, 2) it is entirely optional, with new users able to enjoy their experience even if they never discover the head-tilt mechanic, 3) it does not require an external input device, and 4) it is so satisfying.</p>\n<p>Ricardo implemented this control scheme in three.js by creating a dolly system that tracks both the users headset data and the position of the camera on the pre-defined path, and then averages them.</p>\n<pre><code>if ( cameraPath !== undefined ) {\n\n  var time = ( performance.now() / 40000 ) % 1;\n\n  var pointA = cameraPath.getPointAt( time );\n  var pointB = cameraPath.getPointAt( Math.min( time + 0.015, 1 ) );\n\n  pointA.z = -pointA.z;\n  pointB.z = -pointB.z;\n\n  dolly.position.copy( pointA );\n  dolly.lookAt( pointB );\n\n  dolly.rotateY( Math.PI ); // look forward\n\n}\n\ncontrols.update();\n\nsky.position.copy( dolly.position );\n\nwater.position.x = dolly.position.x;\nwater.position.z = dolly.position.z;\n\neffect.render( scene, camera );\n</code></pre><p>To bring camera data from Cinema 4D into three.js, we exported the individual points that define the camera path in C4D as ASCII text, and then imported them into three.js using an importer that Ricardo wrote:</p>\n<pre><code>var loader = new THREE.C4DLineLoader();\nloader.load( &apos;flightpath-ascii.txt&apos;, function ( line ) {\n\n  cameraPath = line;\n\n} );\n</code></pre><h2 id=\"Testing-amp-Optimization\"><a href=\"#Testing-amp-Optimization\" class=\"headerlink\" title=\"Testing &amp; Optimization\"></a>Testing &amp; Optimization</h2><h3 id=\"Adding-VR-headset-support\"><a href=\"#Adding-VR-headset-support\" class=\"headerlink\" title=\"Adding VR headset support\"></a>Adding VR headset support</h3><p>Support for VR headsets was implemented with two three.js components: <code>VRControls</code> and <code>VREffect</code>. These take the scene and enable VR headset support.</p>\n<h3 id=\"Testing\"><a href=\"#Testing\" class=\"headerlink\" title=\"Testing\"></a>Testing</h3><p>We tested the results with DK1 and DK2 headsets and random coworkers, trying to find people who were particularly sensitive to the nausea and disorientation that VR can produce if not properly calibrated.</p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>For the start of the development process we simple worked out of a Dropbox folder, with Ricardo saving this progress as he went. Our standard process is to use Git, NPM and Gulp track changes, manage dependencies and automate various development tasks, but early in the process we were more concerned with quick results, and with just Ricardo doing the code a simple setup was good enough. Before deploying, however, we organized the code and pushed to GitHub, hosting everything with <a href=\"https://pages.github.com\">GitHub Pages</a>, using <a href=\"https://www.npmjs.org/package/gulp-gh-pages\">gulp-gh-pages</a> to automate the process.</p>\n"},{"title":"Introducing the WebVR 1.0 API Proposal","id":"19","updated":"2016-09-24T02:02:05.000Z","_content":"\n(Copy contents from https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/.)\n","source":"_drafts/Introducing-the-WebVR-1-0-API-Proposal.md","raw":"---\ntitle: Introducing the WebVR 1.0 API Proposal\npermalink: introducing-the-webvr-1-0-api-proposal\nid: 19\nupdated: '2016-09-23 19:02:05'\ntags:\n---\n\n(Copy contents from https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/.)\n","slug":"introducing-the-webvr-1-0-api-proposal","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hyf0004ik1jdr0xy4rd","content":"<p>(Copy contents from <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\" target=\"_blank\" rel=\"external\">https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/</a>.)</p>\n","excerpt":"","more":"<p>(Copy contents from <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\">https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/</a>.)</p>\n"},{"title":"WebVR featured Killscreen Featured on WebVR","id":"21","updated":"2016-09-24T02:04:42.000Z","_content":"\nThe future of the internet is coming, and it's in VR.\n\n(Link to Casey's post on https://versions.killscreen.com/future-internet-coming-vr/.)\n","source":"_drafts/WebVR-featured-Killscreen-Featured-on-WebVR.md","raw":"---\ntitle: WebVR featured Killscreen Featured on WebVR\npermalink: killscreen-2\nid: 21\nupdated: '2016-09-23 19:04:42'\ntags:\n---\n\nThe future of the internet is coming, and it's in VR.\n\n(Link to Casey's post on https://versions.killscreen.com/future-internet-coming-vr/.)\n","slug":"killscreen-2","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hyh0005ik1jfomnde0p","content":"<p>The future of the internet is coming, and its in VR.</p>\n<p>(Link to Caseys post on <a href=\"https://versions.killscreen.com/future-internet-coming-vr/\" target=\"_blank\" rel=\"external\">https://versions.killscreen.com/future-internet-coming-vr/</a>.)</p>\n","excerpt":"","more":"<p>The future of the internet is coming, and its in VR.</p>\n<p>(Link to Caseys post on <a href=\"https://versions.killscreen.com/future-internet-coming-vr/\">https://versions.killscreen.com/future-internet-coming-vr/</a>.)</p>\n"},{"title":"SFHTML5 WebVR Conference Meetup","id":"12","updated":"2016-06-03T09:43:17.000Z","_content":"","source":"_drafts/SFHTML5-WebVR-Conference-Meetup.md","raw":"---\ntitle: SFHTML5 WebVR Conference Meetup\ntags: |-\n\n  - Community\npermalink: sfhtml5-webvr-conference-meetup\nid: 12\nupdated: '2016-06-03 02:43:17'\n---\n","slug":"sfhtml5-webvr-conference-meetup","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hyk0006ik1jso6rs350","content":"","excerpt":"","more":""},{"title":"Puzzle Rain: A room-scale WebVR Experience for the HTC Vive","id":"14","updated":"2016-09-29T06:20:06.000Z","_content":"\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XOIDXXynmq8\" allowfullscreen></iframe>\n\nThis project was created to demonstrate what is possible to create with WebVR today.\n\nWe compressed the creative and development processes in a seven-week project, in which we used the following techniques:\n\n* [Narrative/visual techniques](#Narrative/visual techniques)\n* [Game mechanics](#Game mechanics)\n* [UX techniques](#UX techniques)\n* [Technical WebVR challenges](#Technical WebVR challenges)\n\n# Narrative/visual techniques\n\nBased on [Pixar](http://www.pixar.com/)'s animated films, we began the concept of informing to the user, which in our case was to make it feel like a conductor of a magical orchestra that comes alive with user interactions. We used colors, music, and various characters for each family of instruments. Here is a color script of the final experience on the [spectator mode](https://mozvr.com/puzzle-rain/?mode=spectator):\n\n<img src=\"https://cloud.githubusercontent.com/assets/203725/18942091/284169ee-85cb-11e6-81be-025ed750a7e6.jpg\" alt=\"Puzzle Rain  Color script\" title=\"Puzzle Rain  Color script\">\n\n# Game mechanics\n\nBecause VR is an interactive medium, we have made an experience with the following features:\n\n* Movement with user interaction\n* Variable duration depending on how fast the user moves\n* Different endings depending on what the user does\n\nAnd, this was a huge challenge to coordinate the storytelling stages with the musical soundtrack (composed by [Guillermo Laporta](http://guillermolaporta.com/)) for each stage.\n\n<img src=\"https://cloud.githubusercontent.com/assets/203725/18942652/4eefc636-85cf-11e6-8890-2208783e2979.jpg\" alt=\"Puzzle Rain  Interactive Script\" title=\"Puzzle Rain  Interactive Script\">\n\n# UX techniques\n\nWe focused on the following UX challenges to create a uniquely VR experience:\n\n* Interactivity (user agency)\n* Perspective (first-person point of view)\n* Room-scale (optimized for the HTC Vive)\n\nBelow are the initial sketches of the room-scaled game area, which was proportionally subdivided into quadrants:\n\n<img src=\"https://cloud.githubusercontent.com/assets/203725/18942928/30153e42-85d1-11e6-9b50-245fc4448fab.jpg\" alt=\"Puzzle Rain  Gameplay area\" title=\"Puzzle Rain  Gameplay area\">\n\n# Technical WebVR challenges\n\nWe achieved a stable 90 frames-per-second stable frame rate with the minimum PC specifications for the Vive (NVIDIA GTX 970, Intel i5-4590, and 8GB RAM) with:","source":"_drafts/Puzzle-Rain-A-room-scale-WebVR-Experience-for-the-HTC-Vive.md","raw":"---\ntitle: 'Puzzle Rain: A room-scale WebVR Experience for the HTC Vive'\npermalink: puzzle-rain\nid: 14\nupdated: '2016-09-28 23:20:06'\ntags:\n---\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XOIDXXynmq8\" allowfullscreen></iframe>\n\nThis project was created to demonstrate what is possible to create with WebVR today.\n\nWe compressed the creative and development processes in a seven-week project, in which we used the following techniques:\n\n* [Narrative/visual techniques](#Narrative/visual techniques)\n* [Game mechanics](#Game mechanics)\n* [UX techniques](#UX techniques)\n* [Technical WebVR challenges](#Technical WebVR challenges)\n\n# Narrative/visual techniques\n\nBased on [Pixar](http://www.pixar.com/)'s animated films, we began the concept of informing to the user, which in our case was to make it feel like a conductor of a magical orchestra that comes alive with user interactions. We used colors, music, and various characters for each family of instruments. Here is a color script of the final experience on the [spectator mode](https://mozvr.com/puzzle-rain/?mode=spectator):\n\n<img src=\"https://cloud.githubusercontent.com/assets/203725/18942091/284169ee-85cb-11e6-81be-025ed750a7e6.jpg\" alt=\"Puzzle Rain  Color script\" title=\"Puzzle Rain  Color script\">\n\n# Game mechanics\n\nBecause VR is an interactive medium, we have made an experience with the following features:\n\n* Movement with user interaction\n* Variable duration depending on how fast the user moves\n* Different endings depending on what the user does\n\nAnd, this was a huge challenge to coordinate the storytelling stages with the musical soundtrack (composed by [Guillermo Laporta](http://guillermolaporta.com/)) for each stage.\n\n<img src=\"https://cloud.githubusercontent.com/assets/203725/18942652/4eefc636-85cf-11e6-8890-2208783e2979.jpg\" alt=\"Puzzle Rain  Interactive Script\" title=\"Puzzle Rain  Interactive Script\">\n\n# UX techniques\n\nWe focused on the following UX challenges to create a uniquely VR experience:\n\n* Interactivity (user agency)\n* Perspective (first-person point of view)\n* Room-scale (optimized for the HTC Vive)\n\nBelow are the initial sketches of the room-scaled game area, which was proportionally subdivided into quadrants:\n\n<img src=\"https://cloud.githubusercontent.com/assets/203725/18942928/30153e42-85d1-11e6-9b50-245fc4448fab.jpg\" alt=\"Puzzle Rain  Gameplay area\" title=\"Puzzle Rain  Gameplay area\">\n\n# Technical WebVR challenges\n\nWe achieved a stable 90 frames-per-second stable frame rate with the minimum PC specifications for the Vive (NVIDIA GTX 970, Intel i5-4590, and 8GB RAM) with:","slug":"puzzle-rain","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hyl0007ik1j68zq7iv6","content":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XOIDXXynmq8\" allowfullscreen></iframe>\n\n<p>This project was created to demonstrate what is possible to create with WebVR today.</p>\n<p>We compressed the creative and development processes in a seven-week project, in which we used the following techniques:</p>\n<ul>\n<li><a href=\"#Narrative/visual techniques\">Narrative/visual techniques</a></li>\n<li><a href=\"#Game mechanics\">Game mechanics</a></li>\n<li><a href=\"#UX techniques\">UX techniques</a></li>\n<li><a href=\"#Technical WebVR challenges\">Technical WebVR challenges</a></li>\n</ul>\n<h1 id=\"Narrative-visual-techniques\"><a href=\"#Narrative-visual-techniques\" class=\"headerlink\" title=\"Narrative/visual techniques\"></a>Narrative/visual techniques</h1><p>Based on <a href=\"http://www.pixar.com/\" target=\"_blank\" rel=\"external\">Pixar</a>s animated films, we began the concept of informing to the user, which in our case was to make it feel like a conductor of a magical orchestra that comes alive with user interactions. We used colors, music, and various characters for each family of instruments. Here is a color script of the final experience on the <a href=\"https://mozvr.com/puzzle-rain/?mode=spectator\" target=\"_blank\" rel=\"external\">spectator mode</a>:</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/203725/18942091/284169ee-85cb-11e6-81be-025ed750a7e6.jpg\" alt=\"Puzzle Rain  Color script\" title=\"Puzzle Rain  Color script\"></p>\n<h1 id=\"Game-mechanics\"><a href=\"#Game-mechanics\" class=\"headerlink\" title=\"Game mechanics\"></a>Game mechanics</h1><p>Because VR is an interactive medium, we have made an experience with the following features:</p>\n<ul>\n<li>Movement with user interaction</li>\n<li>Variable duration depending on how fast the user moves</li>\n<li>Different endings depending on what the user does</li>\n</ul>\n<p>And, this was a huge challenge to coordinate the storytelling stages with the musical soundtrack (composed by <a href=\"http://guillermolaporta.com/\" target=\"_blank\" rel=\"external\">Guillermo Laporta</a>) for each stage.</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/203725/18942652/4eefc636-85cf-11e6-8890-2208783e2979.jpg\" alt=\"Puzzle Rain  Interactive Script\" title=\"Puzzle Rain  Interactive Script\"></p>\n<h1 id=\"UX-techniques\"><a href=\"#UX-techniques\" class=\"headerlink\" title=\"UX techniques\"></a>UX techniques</h1><p>We focused on the following UX challenges to create a uniquely VR experience:</p>\n<ul>\n<li>Interactivity (user agency)</li>\n<li>Perspective (first-person point of view)</li>\n<li>Room-scale (optimized for the HTC Vive)</li>\n</ul>\n<p>Below are the initial sketches of the room-scaled game area, which was proportionally subdivided into quadrants:</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/203725/18942928/30153e42-85d1-11e6-9b50-245fc4448fab.jpg\" alt=\"Puzzle Rain  Gameplay area\" title=\"Puzzle Rain  Gameplay area\"></p>\n<h1 id=\"Technical-WebVR-challenges\"><a href=\"#Technical-WebVR-challenges\" class=\"headerlink\" title=\"Technical WebVR challenges\"></a>Technical WebVR challenges</h1><p>We achieved a stable 90 frames-per-second stable frame rate with the minimum PC specifications for the Vive (NVIDIA GTX 970, Intel i5-4590, and 8GB RAM) with:</p>\n","excerpt":"","more":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XOIDXXynmq8\" allowfullscreen></iframe>\n\n<p>This project was created to demonstrate what is possible to create with WebVR today.</p>\n<p>We compressed the creative and development processes in a seven-week project, in which we used the following techniques:</p>\n<ul>\n<li><a href=\"#Narrative/visual techniques\">Narrative/visual techniques</a></li>\n<li><a href=\"#Game mechanics\">Game mechanics</a></li>\n<li><a href=\"#UX techniques\">UX techniques</a></li>\n<li><a href=\"#Technical WebVR challenges\">Technical WebVR challenges</a></li>\n</ul>\n<h1 id=\"Narrative-visual-techniques\"><a href=\"#Narrative-visual-techniques\" class=\"headerlink\" title=\"Narrative/visual techniques\"></a>Narrative/visual techniques</h1><p>Based on <a href=\"http://www.pixar.com/\">Pixar</a>s animated films, we began the concept of informing to the user, which in our case was to make it feel like a conductor of a magical orchestra that comes alive with user interactions. We used colors, music, and various characters for each family of instruments. Here is a color script of the final experience on the <a href=\"https://mozvr.com/puzzle-rain/?mode=spectator\">spectator mode</a>:</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/203725/18942091/284169ee-85cb-11e6-81be-025ed750a7e6.jpg\" alt=\"Puzzle Rain  Color script\" title=\"Puzzle Rain  Color script\"></p>\n<h1 id=\"Game-mechanics\"><a href=\"#Game-mechanics\" class=\"headerlink\" title=\"Game mechanics\"></a>Game mechanics</h1><p>Because VR is an interactive medium, we have made an experience with the following features:</p>\n<ul>\n<li>Movement with user interaction</li>\n<li>Variable duration depending on how fast the user moves</li>\n<li>Different endings depending on what the user does</li>\n</ul>\n<p>And, this was a huge challenge to coordinate the storytelling stages with the musical soundtrack (composed by <a href=\"http://guillermolaporta.com/\">Guillermo Laporta</a>) for each stage.</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/203725/18942652/4eefc636-85cf-11e6-8890-2208783e2979.jpg\" alt=\"Puzzle Rain  Interactive Script\" title=\"Puzzle Rain  Interactive Script\"></p>\n<h1 id=\"UX-techniques\"><a href=\"#UX-techniques\" class=\"headerlink\" title=\"UX techniques\"></a>UX techniques</h1><p>We focused on the following UX challenges to create a uniquely VR experience:</p>\n<ul>\n<li>Interactivity (user agency)</li>\n<li>Perspective (first-person point of view)</li>\n<li>Room-scale (optimized for the HTC Vive)</li>\n</ul>\n<p>Below are the initial sketches of the room-scaled game area, which was proportionally subdivided into quadrants:</p>\n<p><img src=\"https://cloud.githubusercontent.com/assets/203725/18942928/30153e42-85d1-11e6-9b50-245fc4448fab.jpg\" alt=\"Puzzle Rain  Gameplay area\" title=\"Puzzle Rain  Gameplay area\"></p>\n<h1 id=\"Technical-WebVR-challenges\"><a href=\"#Technical-WebVR-challenges\" class=\"headerlink\" title=\"Technical WebVR challenges\"></a>Technical WebVR challenges</h1><p>We achieved a stable 90 frames-per-second stable frame rate with the minimum PC specifications for the Vive (NVIDIA GTX 970, Intel i5-4590, and 8GB RAM) with:</p>\n"},{"title":"Using Service Workers for creating fast and offline-first WebVR experiences","id":"22","updated":"2016-09-24T02:05:28.000Z","_content":"","source":"_drafts/Using-Service-Workers-for-creating-fast-and-offline-first-WebVR-experiences.md","raw":"---\ntitle: Using Service Workers for creating fast and offline-first WebVR experiences\npermalink: using-service-workers-for-creating-fast-and-offline-first-webvr-experiences\nid: 22\nupdated: '2016-09-23 19:05:28'\ntags:\n---\n","slug":"using-service-workers-for-creating-fast-and-offline-first-webvr-experiences","published":0,"date":"2016-09-29T07:17:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hyp0009ik1jz3m9f5vm","content":"","excerpt":"","more":""},{"title":"A-Frame v0.3.0 - Walk in a Web Page","id":"16","updated":"2016-08-23T20:06:11.000Z","date":"2016-08-23T19:34:26.000Z","_content":"\n[webvr1.0]: https://w3c.github.io/webvr/\n\nA-Frame **v0.3.0** has dropped! With support for the **[new WebVR 1.0 API][webvr1.0]**, we aim higher towards state-of-the-art VR. With room-scale tracking, we can walk in a web page, and with tracked controller support, we can reach out into the world.\n\n![](/content/images/2016/08/v0-3-0-roomscale.gif)\n\n[latestbuild]: https://aframe.io/releases/0.3.0/aframe.min.js\n\nGrab the latest build at [`https://aframe.io/releases/0.3.0/aframe.min.js`][latestbuild] or `npm install aframe`.\n\n## What's New?\n\n**WebVR 1.0** support is the highlight of this release. This includes:\n\n- Better **room-scale** support to be able to walk/dash/duck/jump in a web\n  page with the HTC Vive.\n- Hitting **90 frames per second** due to being able to push content directly to the headset\n  display rather than mirroring a desktop display. This also allows us to have different\n  content on the desktop display than the headset, opening the door for asynchronous gameplay\n  and spectator modes.\n\nAs a corollary, A-Frame now supports **tracked controllers** with the HTC Vive. Tracked controllers go hand-in-hand with room-scale. Grab an HTC Vive and the [experimental WebVR-enabled Chromium build](https://webvr.info/get-chrome/) (which currently supports the Vive) and try out the [basic hand controls demo](https://aframe.io/aframe/examples/showcase/tracked-controls/) or [ball throw](https://bryik.github.io/aframe-ball-throw/).\n\n![](/content/images/2016/08/ball-throw.gif)\n\n[inspectordemo]: https://aframe.io/aframe-inspector/example/\n\nWe are also releasing the much-anticipated **A-Frame Inspector** ([view demo][inspectordemo]). The current primary purpose of the Inspector is to serve as a complementary tool for inspecting and tweaking scenes alongside code; it is more akin to your favorite browser's DOM Inspector rather than an end-to-end tool such as Unity. The easiest way to try out the A-Frame Inspector is to press `<ctrl> + <shift> + i` on any A-Frame scene using v0.3.0.\n\n![A-Frame Inspector Demo](/content/images/2016/08/v0-3-0-inspector.gif)\n\nOther noteworthy changes include significant performance improvements, improved support for multiple scenes embedded within a single webpage, and support for multiple instances of components of the same type.\n\n[releasenotes]: https://github.com/aframevr/aframe/releases/tag/v0.3.0\n\nCheck out the [release notes][releasenotes] for the complete changelog, which includes a list of possible breaking changes.\n\n## What Have People Built?\n\n[github]: https://github.com/aframevr/aframe\n[slack]: https://aframevr-slack.herokuapp.com\n[webvr-slack]: https://webvr-slack.herokuapp.com\n\nA-Frame's popularity has grown immensely, leading it to be the WebVR framework of choice. In less than a year, the [GitHub repository][github] has over **2800 stargazers and 60 contributors**. There are over **1200 members** on the [A-Frame Slack channel][slack].\n\n[blog]: https://aframe.io\n\nWe started producing weekly roundups with the *[A Week of A-Frame][blog]* series to showcase community content, components, and contributions. In the last four months, we have featured over **150 high quality scenes**:\n\n- [MagicaVoxel Island](https://sandbox.donmccurdy.com/vr/island/)\n- [Audio Visualizer](https://ngokevin.github.io/aframe-audio-visualizer-components/spectrum/)\n- [TumbVR](http://tbaloo.com/tumbvr/madeinhexels)\n- [Virtual Symphony](https://musicpua.firebaseapp.com/)\n- [Sad Island](http://www.skyislandsvr.com/pages/SadIsland.html)\n- [Shopify VR](https://shopifyvr.myshopify.com/pages/virtual-reality)\n\n[don]: https://github.com/donmccurdy/aframe-extras\n[altspace]: https://github.com/AltspaceVR/aframe-altspace-component\n[bmfont]: https://github.com/bryik/aframe-bmfont-text-component\n[cubemap]: https://github.com/bryik/aframe-cubemap-component\n[extras]: https://github.com/donmccurdy/aframe-extras\n[gif]: https://github.com/mayognaise/aframe-gif-shader\n[gltf]: https://github.com/xirvr/aframe-gltf\n[grid]: https://github.com/dbradleyfl/aframe-gridhelper\n[html]: https://github.com/mayognaise/aframe-html-shader\n[k-frame]: https://github.com/ngokevin/k-frame\n[leap]: https://github.com/openleap/aframe-leap-hands\n[lsystem]: https://github.com/nylki/aframe-lsystem-component\n[particle]: https://github.com/IdeaSpaceVR/aframe-particle-system-component\n[stereocube]: https://github.com/wallabyway/aframe-stereocube\n[vidcontrols]: https://github.com/oscarmarinmiro/aframe-video-controls\n[terrain]: https://github.com/andreasplesch/aframe-heightgrid-component\n[webvrcontroller]: https://github.com/richardanaya/aframe-webvr-controller\n\n...and nearly **50 community components**:\n\n- **Component Packs:** [aframe-extras][extras] by [Don McCurdy][don] enables\n  additional **controls**, **physics**, and loaders. [k-frame][k-frame]\n  enables **audio visualizations**, **multiuser**, **templating**, layout, text,\n  and improved animations.\n- **Geometries:** [Procedural geometries][lsystem], [Bitmap font text][bmfont],\n  [terrains][terrain], [oceans][extras], and [grids][grid].\n- **Materials:** [GIF][gif], [HTML][html], [cubemaps][cubemap],\n  [stereo cubemaps][stereocube], and [video controls][vidcontrols].\n- **Miscellaneous:** [Leap Motion controls][leap], [Vive controls][webvrcontroller],\n  [AltSpaceVR integration][altspace], [glTF][gltf], and [particle systems][particle].\n\nThere have even been a couple of **augmented reality** prototypes:\n\n![A-Frame Augmented Reality with Argon Browser](/content/images/2016/08/argon.gif)\n\n## What's Next?\n\n[blender]: https://www.blender.org/\n[magicavoxel]: https://ephtracy.github.io/\n\nWe want to make it **easier to get started** with A-Frame. This includes a refreshed homepage with new example scenes that act as starter kits. These examples will be accompanied with free assets, guides, and workflows tutorials on how to use A-Frame alongside tools such as [MagicaVoxel][magicavoxel] and [Blender][blender].\n\nWe are also excited to improve the component discovery and consumption process to have an easy place to find great community components. We'll also be thinking about asset curation and discovery which should sound great if you've ever had trouble finding free 3D models.\n\n[roadmap]: https://github.com/aframevr/aframe/blob/master/ROADMAP.md\n\nCheck out the [official roadmap][roadmap] for what we currently have planned over the next several months.","source":"_posts/A-Frame-v0-3-0-Walk-in-a-Web-Page.md","raw":"---\ntitle: A-Frame v0.3.0 - Walk in a Web Page\ntags: A-Frame\npermalink: aframe-v0-3-0\nid: 16\nupdated: '2016-08-23 13:06:11'\ndate: 2016-08-23 12:34:26\n---\n\n[webvr1.0]: https://w3c.github.io/webvr/\n\nA-Frame **v0.3.0** has dropped! With support for the **[new WebVR 1.0 API][webvr1.0]**, we aim higher towards state-of-the-art VR. With room-scale tracking, we can walk in a web page, and with tracked controller support, we can reach out into the world.\n\n![](/content/images/2016/08/v0-3-0-roomscale.gif)\n\n[latestbuild]: https://aframe.io/releases/0.3.0/aframe.min.js\n\nGrab the latest build at [`https://aframe.io/releases/0.3.0/aframe.min.js`][latestbuild] or `npm install aframe`.\n\n## What's New?\n\n**WebVR 1.0** support is the highlight of this release. This includes:\n\n- Better **room-scale** support to be able to walk/dash/duck/jump in a web\n  page with the HTC Vive.\n- Hitting **90 frames per second** due to being able to push content directly to the headset\n  display rather than mirroring a desktop display. This also allows us to have different\n  content on the desktop display than the headset, opening the door for asynchronous gameplay\n  and spectator modes.\n\nAs a corollary, A-Frame now supports **tracked controllers** with the HTC Vive. Tracked controllers go hand-in-hand with room-scale. Grab an HTC Vive and the [experimental WebVR-enabled Chromium build](https://webvr.info/get-chrome/) (which currently supports the Vive) and try out the [basic hand controls demo](https://aframe.io/aframe/examples/showcase/tracked-controls/) or [ball throw](https://bryik.github.io/aframe-ball-throw/).\n\n![](/content/images/2016/08/ball-throw.gif)\n\n[inspectordemo]: https://aframe.io/aframe-inspector/example/\n\nWe are also releasing the much-anticipated **A-Frame Inspector** ([view demo][inspectordemo]). The current primary purpose of the Inspector is to serve as a complementary tool for inspecting and tweaking scenes alongside code; it is more akin to your favorite browser's DOM Inspector rather than an end-to-end tool such as Unity. The easiest way to try out the A-Frame Inspector is to press `<ctrl> + <shift> + i` on any A-Frame scene using v0.3.0.\n\n![A-Frame Inspector Demo](/content/images/2016/08/v0-3-0-inspector.gif)\n\nOther noteworthy changes include significant performance improvements, improved support for multiple scenes embedded within a single webpage, and support for multiple instances of components of the same type.\n\n[releasenotes]: https://github.com/aframevr/aframe/releases/tag/v0.3.0\n\nCheck out the [release notes][releasenotes] for the complete changelog, which includes a list of possible breaking changes.\n\n## What Have People Built?\n\n[github]: https://github.com/aframevr/aframe\n[slack]: https://aframevr-slack.herokuapp.com\n[webvr-slack]: https://webvr-slack.herokuapp.com\n\nA-Frame's popularity has grown immensely, leading it to be the WebVR framework of choice. In less than a year, the [GitHub repository][github] has over **2800 stargazers and 60 contributors**. There are over **1200 members** on the [A-Frame Slack channel][slack].\n\n[blog]: https://aframe.io\n\nWe started producing weekly roundups with the *[A Week of A-Frame][blog]* series to showcase community content, components, and contributions. In the last four months, we have featured over **150 high quality scenes**:\n\n- [MagicaVoxel Island](https://sandbox.donmccurdy.com/vr/island/)\n- [Audio Visualizer](https://ngokevin.github.io/aframe-audio-visualizer-components/spectrum/)\n- [TumbVR](http://tbaloo.com/tumbvr/madeinhexels)\n- [Virtual Symphony](https://musicpua.firebaseapp.com/)\n- [Sad Island](http://www.skyislandsvr.com/pages/SadIsland.html)\n- [Shopify VR](https://shopifyvr.myshopify.com/pages/virtual-reality)\n\n[don]: https://github.com/donmccurdy/aframe-extras\n[altspace]: https://github.com/AltspaceVR/aframe-altspace-component\n[bmfont]: https://github.com/bryik/aframe-bmfont-text-component\n[cubemap]: https://github.com/bryik/aframe-cubemap-component\n[extras]: https://github.com/donmccurdy/aframe-extras\n[gif]: https://github.com/mayognaise/aframe-gif-shader\n[gltf]: https://github.com/xirvr/aframe-gltf\n[grid]: https://github.com/dbradleyfl/aframe-gridhelper\n[html]: https://github.com/mayognaise/aframe-html-shader\n[k-frame]: https://github.com/ngokevin/k-frame\n[leap]: https://github.com/openleap/aframe-leap-hands\n[lsystem]: https://github.com/nylki/aframe-lsystem-component\n[particle]: https://github.com/IdeaSpaceVR/aframe-particle-system-component\n[stereocube]: https://github.com/wallabyway/aframe-stereocube\n[vidcontrols]: https://github.com/oscarmarinmiro/aframe-video-controls\n[terrain]: https://github.com/andreasplesch/aframe-heightgrid-component\n[webvrcontroller]: https://github.com/richardanaya/aframe-webvr-controller\n\n...and nearly **50 community components**:\n\n- **Component Packs:** [aframe-extras][extras] by [Don McCurdy][don] enables\n  additional **controls**, **physics**, and loaders. [k-frame][k-frame]\n  enables **audio visualizations**, **multiuser**, **templating**, layout, text,\n  and improved animations.\n- **Geometries:** [Procedural geometries][lsystem], [Bitmap font text][bmfont],\n  [terrains][terrain], [oceans][extras], and [grids][grid].\n- **Materials:** [GIF][gif], [HTML][html], [cubemaps][cubemap],\n  [stereo cubemaps][stereocube], and [video controls][vidcontrols].\n- **Miscellaneous:** [Leap Motion controls][leap], [Vive controls][webvrcontroller],\n  [AltSpaceVR integration][altspace], [glTF][gltf], and [particle systems][particle].\n\nThere have even been a couple of **augmented reality** prototypes:\n\n![A-Frame Augmented Reality with Argon Browser](/content/images/2016/08/argon.gif)\n\n## What's Next?\n\n[blender]: https://www.blender.org/\n[magicavoxel]: https://ephtracy.github.io/\n\nWe want to make it **easier to get started** with A-Frame. This includes a refreshed homepage with new example scenes that act as starter kits. These examples will be accompanied with free assets, guides, and workflows tutorials on how to use A-Frame alongside tools such as [MagicaVoxel][magicavoxel] and [Blender][blender].\n\nWe are also excited to improve the component discovery and consumption process to have an easy place to find great community components. We'll also be thinking about asset curation and discovery which should sound great if you've ever had trouble finding free 3D models.\n\n[roadmap]: https://github.com/aframevr/aframe/blob/master/ROADMAP.md\n\nCheck out the [official roadmap][roadmap] for what we currently have planned over the next several months.","slug":"aframe-v0-3-0","published":1,"_id":"citot8hyq000aik1jaldlq6l5","comments":1,"layout":"post","photos":[],"link":"","content":"<p>A-Frame <strong>v0.3.0</strong> has dropped! With support for the <strong><a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">new WebVR 1.0 API</a></strong>, we aim higher towards state-of-the-art VR. With room-scale tracking, we can walk in a web page, and with tracked controller support, we can reach out into the world.</p>\n<p><img src=\"/content/images/2016/08/v0-3-0-roomscale.gif\" alt=\"\"></p>\n<p>Grab the latest build at <a href=\"https://aframe.io/releases/0.3.0/aframe.min.js\" target=\"_blank\" rel=\"external\"><code>https://aframe.io/releases/0.3.0/aframe.min.js</code></a> or <code>npm install aframe</code>.</p>\n<h2 id=\"Whats-New\"><a href=\"#Whats-New\" class=\"headerlink\" title=\"Whats New?\"></a>Whats New?</h2><p><strong>WebVR 1.0</strong> support is the highlight of this release. This includes:</p>\n<ul>\n<li>Better <strong>room-scale</strong> support to be able to walk/dash/duck/jump in a web<br>page with the HTC Vive.</li>\n<li>Hitting <strong>90 frames per second</strong> due to being able to push content directly to the headset<br>display rather than mirroring a desktop display. This also allows us to have different<br>content on the desktop display than the headset, opening the door for asynchronous gameplay<br>and spectator modes.</li>\n</ul>\n<p>As a corollary, A-Frame now supports <strong>tracked controllers</strong> with the HTC Vive. Tracked controllers go hand-in-hand with room-scale. Grab an HTC Vive and the <a href=\"https://webvr.info/get-chrome/\" target=\"_blank\" rel=\"external\">experimental WebVR-enabled Chromium build</a> (which currently supports the Vive) and try out the <a href=\"https://aframe.io/aframe/examples/showcase/tracked-controls/\" target=\"_blank\" rel=\"external\">basic hand controls demo</a> or <a href=\"https://bryik.github.io/aframe-ball-throw/\" target=\"_blank\" rel=\"external\">ball throw</a>.</p>\n<p><img src=\"/content/images/2016/08/ball-throw.gif\" alt=\"\"></p>\n<p>We are also releasing the much-anticipated <strong>A-Frame Inspector</strong> (<a href=\"https://aframe.io/aframe-inspector/example/\" target=\"_blank\" rel=\"external\">view demo</a>). The current primary purpose of the Inspector is to serve as a complementary tool for inspecting and tweaking scenes alongside code; it is more akin to your favorite browsers DOM Inspector rather than an end-to-end tool such as Unity. The easiest way to try out the A-Frame Inspector is to press <code>&lt;ctrl&gt; + &lt;shift&gt; + i</code> on any A-Frame scene using v0.3.0.</p>\n<p><img src=\"/content/images/2016/08/v0-3-0-inspector.gif\" alt=\"A-Frame Inspector Demo\"></p>\n<p>Other noteworthy changes include significant performance improvements, improved support for multiple scenes embedded within a single webpage, and support for multiple instances of components of the same type.</p>\n<p>Check out the <a href=\"https://github.com/aframevr/aframe/releases/tag/v0.3.0\" target=\"_blank\" rel=\"external\">release notes</a> for the complete changelog, which includes a list of possible breaking changes.</p>\n<h2 id=\"What-Have-People-Built\"><a href=\"#What-Have-People-Built\" class=\"headerlink\" title=\"What Have People Built?\"></a>What Have People Built?</h2><p>A-Frames popularity has grown immensely, leading it to be the WebVR framework of choice. In less than a year, the <a href=\"https://github.com/aframevr/aframe\" target=\"_blank\" rel=\"external\">GitHub repository</a> has over <strong>2800 stargazers and 60 contributors</strong>. There are over <strong>1200 members</strong> on the <a href=\"https://aframevr-slack.herokuapp.com\" target=\"_blank\" rel=\"external\">A-Frame Slack channel</a>.</p>\n<p>We started producing weekly roundups with the <em><a href=\"https://aframe.io\" target=\"_blank\" rel=\"external\">A Week of A-Frame</a></em> series to showcase community content, components, and contributions. In the last four months, we have featured over <strong>150 high quality scenes</strong>:</p>\n<ul>\n<li><a href=\"https://sandbox.donmccurdy.com/vr/island/\" target=\"_blank\" rel=\"external\">MagicaVoxel Island</a></li>\n<li><a href=\"https://ngokevin.github.io/aframe-audio-visualizer-components/spectrum/\" target=\"_blank\" rel=\"external\">Audio Visualizer</a></li>\n<li><a href=\"http://tbaloo.com/tumbvr/madeinhexels\" target=\"_blank\" rel=\"external\">TumbVR</a></li>\n<li><a href=\"https://musicpua.firebaseapp.com/\" target=\"_blank\" rel=\"external\">Virtual Symphony</a></li>\n<li><a href=\"http://www.skyislandsvr.com/pages/SadIsland.html\" target=\"_blank\" rel=\"external\">Sad Island</a></li>\n<li><a href=\"https://shopifyvr.myshopify.com/pages/virtual-reality\" target=\"_blank\" rel=\"external\">Shopify VR</a></li>\n</ul>\n<p>and nearly <strong>50 community components</strong>:</p>\n<ul>\n<li><strong>Component Packs:</strong> <a href=\"https://github.com/donmccurdy/aframe-extras\" target=\"_blank\" rel=\"external\">aframe-extras</a> by <a href=\"https://github.com/donmccurdy/aframe-extras\" target=\"_blank\" rel=\"external\">Don McCurdy</a> enables<br>additional <strong>controls</strong>, <strong>physics</strong>, and loaders. <a href=\"https://github.com/ngokevin/k-frame\" target=\"_blank\" rel=\"external\">k-frame</a><br>enables <strong>audio visualizations</strong>, <strong>multiuser</strong>, <strong>templating</strong>, layout, text,<br>and improved animations.</li>\n<li><strong>Geometries:</strong> <a href=\"https://github.com/nylki/aframe-lsystem-component\" target=\"_blank\" rel=\"external\">Procedural geometries</a>, <a href=\"https://github.com/bryik/aframe-bmfont-text-component\" target=\"_blank\" rel=\"external\">Bitmap font text</a>,<br><a href=\"https://github.com/andreasplesch/aframe-heightgrid-component\" target=\"_blank\" rel=\"external\">terrains</a>, <a href=\"https://github.com/donmccurdy/aframe-extras\" target=\"_blank\" rel=\"external\">oceans</a>, and <a href=\"https://github.com/dbradleyfl/aframe-gridhelper\" target=\"_blank\" rel=\"external\">grids</a>.</li>\n<li><strong>Materials:</strong> <a href=\"https://github.com/mayognaise/aframe-gif-shader\" target=\"_blank\" rel=\"external\">GIF</a>, <a href=\"https://github.com/mayognaise/aframe-html-shader\" target=\"_blank\" rel=\"external\">HTML</a>, <a href=\"https://github.com/bryik/aframe-cubemap-component\" target=\"_blank\" rel=\"external\">cubemaps</a>,<br><a href=\"https://github.com/wallabyway/aframe-stereocube\" target=\"_blank\" rel=\"external\">stereo cubemaps</a>, and <a href=\"https://github.com/oscarmarinmiro/aframe-video-controls\" target=\"_blank\" rel=\"external\">video controls</a>.</li>\n<li><strong>Miscellaneous:</strong> <a href=\"https://github.com/openleap/aframe-leap-hands\" target=\"_blank\" rel=\"external\">Leap Motion controls</a>, <a href=\"https://github.com/richardanaya/aframe-webvr-controller\" target=\"_blank\" rel=\"external\">Vive controls</a>,<br><a href=\"https://github.com/AltspaceVR/aframe-altspace-component\" target=\"_blank\" rel=\"external\">AltSpaceVR integration</a>, <a href=\"https://github.com/xirvr/aframe-gltf\" target=\"_blank\" rel=\"external\">glTF</a>, and <a href=\"https://github.com/IdeaSpaceVR/aframe-particle-system-component\" target=\"_blank\" rel=\"external\">particle systems</a>.</li>\n</ul>\n<p>There have even been a couple of <strong>augmented reality</strong> prototypes:</p>\n<p><img src=\"/content/images/2016/08/argon.gif\" alt=\"A-Frame Augmented Reality with Argon Browser\"></p>\n<h2 id=\"Whats-Next\"><a href=\"#Whats-Next\" class=\"headerlink\" title=\"Whats Next?\"></a>Whats Next?</h2><p>We want to make it <strong>easier to get started</strong> with A-Frame. This includes a refreshed homepage with new example scenes that act as starter kits. These examples will be accompanied with free assets, guides, and workflows tutorials on how to use A-Frame alongside tools such as <a href=\"https://ephtracy.github.io/\" target=\"_blank\" rel=\"external\">MagicaVoxel</a> and <a href=\"https://www.blender.org/\" target=\"_blank\" rel=\"external\">Blender</a>.</p>\n<p>We are also excited to improve the component discovery and consumption process to have an easy place to find great community components. Well also be thinking about asset curation and discovery which should sound great if youve ever had trouble finding free 3D models.</p>\n<p>Check out the <a href=\"https://github.com/aframevr/aframe/blob/master/ROADMAP.md\" target=\"_blank\" rel=\"external\">official roadmap</a> for what we currently have planned over the next several months.</p>\n","excerpt":"","more":"<p>A-Frame <strong>v0.3.0</strong> has dropped! With support for the <strong><a href=\"https://w3c.github.io/webvr/\">new WebVR 1.0 API</a></strong>, we aim higher towards state-of-the-art VR. With room-scale tracking, we can walk in a web page, and with tracked controller support, we can reach out into the world.</p>\n<p><img src=\"/content/images/2016/08/v0-3-0-roomscale.gif\" alt=\"\"></p>\n<p>Grab the latest build at <a href=\"https://aframe.io/releases/0.3.0/aframe.min.js\"><code>https://aframe.io/releases/0.3.0/aframe.min.js</code></a> or <code>npm install aframe</code>.</p>\n<h2 id=\"Whats-New\"><a href=\"#Whats-New\" class=\"headerlink\" title=\"Whats New?\"></a>Whats New?</h2><p><strong>WebVR 1.0</strong> support is the highlight of this release. This includes:</p>\n<ul>\n<li>Better <strong>room-scale</strong> support to be able to walk/dash/duck/jump in a web<br>page with the HTC Vive.</li>\n<li>Hitting <strong>90 frames per second</strong> due to being able to push content directly to the headset<br>display rather than mirroring a desktop display. This also allows us to have different<br>content on the desktop display than the headset, opening the door for asynchronous gameplay<br>and spectator modes.</li>\n</ul>\n<p>As a corollary, A-Frame now supports <strong>tracked controllers</strong> with the HTC Vive. Tracked controllers go hand-in-hand with room-scale. Grab an HTC Vive and the <a href=\"https://webvr.info/get-chrome/\">experimental WebVR-enabled Chromium build</a> (which currently supports the Vive) and try out the <a href=\"https://aframe.io/aframe/examples/showcase/tracked-controls/\">basic hand controls demo</a> or <a href=\"https://bryik.github.io/aframe-ball-throw/\">ball throw</a>.</p>\n<p><img src=\"/content/images/2016/08/ball-throw.gif\" alt=\"\"></p>\n<p>We are also releasing the much-anticipated <strong>A-Frame Inspector</strong> (<a href=\"https://aframe.io/aframe-inspector/example/\">view demo</a>). The current primary purpose of the Inspector is to serve as a complementary tool for inspecting and tweaking scenes alongside code; it is more akin to your favorite browsers DOM Inspector rather than an end-to-end tool such as Unity. The easiest way to try out the A-Frame Inspector is to press <code>&lt;ctrl&gt; + &lt;shift&gt; + i</code> on any A-Frame scene using v0.3.0.</p>\n<p><img src=\"/content/images/2016/08/v0-3-0-inspector.gif\" alt=\"A-Frame Inspector Demo\"></p>\n<p>Other noteworthy changes include significant performance improvements, improved support for multiple scenes embedded within a single webpage, and support for multiple instances of components of the same type.</p>\n<p>Check out the <a href=\"https://github.com/aframevr/aframe/releases/tag/v0.3.0\">release notes</a> for the complete changelog, which includes a list of possible breaking changes.</p>\n<h2 id=\"What-Have-People-Built\"><a href=\"#What-Have-People-Built\" class=\"headerlink\" title=\"What Have People Built?\"></a>What Have People Built?</h2><p>A-Frames popularity has grown immensely, leading it to be the WebVR framework of choice. In less than a year, the <a href=\"https://github.com/aframevr/aframe\">GitHub repository</a> has over <strong>2800 stargazers and 60 contributors</strong>. There are over <strong>1200 members</strong> on the <a href=\"https://aframevr-slack.herokuapp.com\">A-Frame Slack channel</a>.</p>\n<p>We started producing weekly roundups with the <em><a href=\"https://aframe.io\">A Week of A-Frame</a></em> series to showcase community content, components, and contributions. In the last four months, we have featured over <strong>150 high quality scenes</strong>:</p>\n<ul>\n<li><a href=\"https://sandbox.donmccurdy.com/vr/island/\">MagicaVoxel Island</a></li>\n<li><a href=\"https://ngokevin.github.io/aframe-audio-visualizer-components/spectrum/\">Audio Visualizer</a></li>\n<li><a href=\"http://tbaloo.com/tumbvr/madeinhexels\">TumbVR</a></li>\n<li><a href=\"https://musicpua.firebaseapp.com/\">Virtual Symphony</a></li>\n<li><a href=\"http://www.skyislandsvr.com/pages/SadIsland.html\">Sad Island</a></li>\n<li><a href=\"https://shopifyvr.myshopify.com/pages/virtual-reality\">Shopify VR</a></li>\n</ul>\n<p>and nearly <strong>50 community components</strong>:</p>\n<ul>\n<li><strong>Component Packs:</strong> <a href=\"https://github.com/donmccurdy/aframe-extras\">aframe-extras</a> by <a href=\"https://github.com/donmccurdy/aframe-extras\">Don McCurdy</a> enables<br>additional <strong>controls</strong>, <strong>physics</strong>, and loaders. <a href=\"https://github.com/ngokevin/k-frame\">k-frame</a><br>enables <strong>audio visualizations</strong>, <strong>multiuser</strong>, <strong>templating</strong>, layout, text,<br>and improved animations.</li>\n<li><strong>Geometries:</strong> <a href=\"https://github.com/nylki/aframe-lsystem-component\">Procedural geometries</a>, <a href=\"https://github.com/bryik/aframe-bmfont-text-component\">Bitmap font text</a>,<br><a href=\"https://github.com/andreasplesch/aframe-heightgrid-component\">terrains</a>, <a href=\"https://github.com/donmccurdy/aframe-extras\">oceans</a>, and <a href=\"https://github.com/dbradleyfl/aframe-gridhelper\">grids</a>.</li>\n<li><strong>Materials:</strong> <a href=\"https://github.com/mayognaise/aframe-gif-shader\">GIF</a>, <a href=\"https://github.com/mayognaise/aframe-html-shader\">HTML</a>, <a href=\"https://github.com/bryik/aframe-cubemap-component\">cubemaps</a>,<br><a href=\"https://github.com/wallabyway/aframe-stereocube\">stereo cubemaps</a>, and <a href=\"https://github.com/oscarmarinmiro/aframe-video-controls\">video controls</a>.</li>\n<li><strong>Miscellaneous:</strong> <a href=\"https://github.com/openleap/aframe-leap-hands\">Leap Motion controls</a>, <a href=\"https://github.com/richardanaya/aframe-webvr-controller\">Vive controls</a>,<br><a href=\"https://github.com/AltspaceVR/aframe-altspace-component\">AltSpaceVR integration</a>, <a href=\"https://github.com/xirvr/aframe-gltf\">glTF</a>, and <a href=\"https://github.com/IdeaSpaceVR/aframe-particle-system-component\">particle systems</a>.</li>\n</ul>\n<p>There have even been a couple of <strong>augmented reality</strong> prototypes:</p>\n<p><img src=\"/content/images/2016/08/argon.gif\" alt=\"A-Frame Augmented Reality with Argon Browser\"></p>\n<h2 id=\"Whats-Next\"><a href=\"#Whats-Next\" class=\"headerlink\" title=\"Whats Next?\"></a>Whats Next?</h2><p>We want to make it <strong>easier to get started</strong> with A-Frame. This includes a refreshed homepage with new example scenes that act as starter kits. These examples will be accompanied with free assets, guides, and workflows tutorials on how to use A-Frame alongside tools such as <a href=\"https://ephtracy.github.io/\">MagicaVoxel</a> and <a href=\"https://www.blender.org/\">Blender</a>.</p>\n<p>We are also excited to improve the component discovery and consumption process to have an easy place to find great community components. Well also be thinking about asset curation and discovery which should sound great if youve ever had trouble finding free 3D models.</p>\n<p>Check out the <a href=\"https://github.com/aframevr/aframe/blob/master/ROADMAP.md\">official roadmap</a> for what we currently have planned over the next several months.</p>\n"},{"title":"Everything you wanted to know about Oculus CV1, Oculus Home, 1.3 runtime and WebVR","id":"9","updated":"2016-05-24T20:08:08.000Z","date":"2016-05-19T03:49:26.000Z","_content":"\nThere have been questions how [WebVR](https://webvr.info/) will work with the recently released [Oculus Rift consumer headset](https://www.oculus.com/rift/), Oculus Home, and the new [1.3 version of the Oculus SDK/runtime](https://developer.oculus.com/downloads/pc/1.3.0/Oculus_SDK_for_Windows/). This post covers what we learned in the past week since its release and how to best work with WebVR using the latest updates.\n\n## Oculus 1.3 runtime support in Firefox Nightly and experimental Chromium builds\n\nUpdates to [Firefox Nightly](https://nightly.mozilla.org/) and [experimental VR-enabled Chromium builds](webvr.info/get-chrome/) are now available and working with the new Oculus 1.3 SDK/runtime, after enabling Unknown Sources from the Oculus Settings. Fortunately, you will need need to do this only once.\n\n## Enabling Unknown Sources\n\n![](/content/images/2016/05/settings.gif)\n\nIn an effort to protect users from applications that have not been reviewed by Oculus (for comfort, content, or health/safety), Oculus by default will not display content from apps obtained outside of the Oculus Store. There are plenty of interesting experiences to try from trustworthy developers including content from the Web!\n\nWhen launching WebVR from within the browser, you will be presented with an Unknown Source screen that initially blocks WebVR content from being displayed.\n\n![](/content/images/2016/05/unknown-sources.jpg)\n\nTo resolve this, you will need to check the Enable Unknown Sources option. You can access this from the Oculus settings.\n\n1. Oculus Application Settings.\n2. General settings.\n3. Toggle the Unknown Sources icon.\n\nOnce done, you will now be able to from Firefox or Chromium and launch WebVR content directly into the headset. There are no changes to how this works, and WebVR experiences continue to be launched from the desktop browser application.\n\n## Compatibility with Consumer Oculus Rift (CV1)\n\nWith 1.3 compatibility comes support for the consumer shipping versions of the Oculus Rift headset. This of course means that your content can now fully utilize the enhanced resolution, refresh rates, and tracking offered by the new headset.\n\n## Setting up Firefox and Chromium for WebVR\n\nOnce your computer is setup and running with the [latest Oculus Runtime](https://developer.oculus.com/downloads/).\n\n### Using Firefox Nightly with WebVR\n\n1. [Download VR-enabled version of Firefox Nightly](https://nightly.mozilla.org/)\n2. [Download and Install WebVR enabler](https://addons.mozilla.org/en-US/firefox/addon/mozilla-webvr-enabler/)\n3. You are now ready to use WebVR.\n\n### Using experimental Chromium builds\n\n1. [Download VR-enabled Oculus build of Chromium](https://webvr.info/get-chrome/) (you will need [7-Zip](http://www.7-zip.org/download.html) installed to extract).\n2. [Enable WebVR](https://docs.google.com/document/d/1g02qHfX85vSRSOkWm9k33I0b7VuyN79md9U9t6MIa4E/edit) flag in `chrome://flags`.\n3. You are now ready to use WebVR content.\nOnly WebVR 1.0 API is supported with the Oculus 1.3 runtime.\n\n## Viewing WebVR content\n\nTo view WebVR content, start up your WebVR-enabled browser from your desktop and navigate to a [WebVR enabled page](https://mozvr.com/). Launch content into the headset by pressing the Enter VR button on the page.\n\n![](/content/images/2016/05/mozvr.png)\n\nIt should also be noted that your headset will display a black loading screen until content is launched using the Enter VR button. You will also be presented with a health and safety warning that will need to be dismissed before content is displayed.\n\nIf Oculus Home is being displayed into the headset, the launched WebVR content will replace Home. With Oculus Home off, WebVR content is launched directly into the headset by-passing Oculus Home. Closing the browser will return the user back to Oculus Home.\n\n## Not yet integrated with Oculus Home\n\nThe most significant change with the latest runtime updates for the Rift is the addition of Oculus Home, which is a central hub for launching Oculus-compatible VR applications. The main benefit is that the Oculus Home interface is accessible from both the desktop and within VR: a nice convenience that allows users to not have to take off the headset to navigate and launch into another application.\n\n![](/content/images/2016/05/home.png)\n\nOculus Home is unfortunately not yet integrated with the current desktop-browser based WebVR implementations since neither Firefox or Chromium currently implements a UI that can be rendered in VR. All navigation is done using the traditional desktop interface, and without VR UI, it wont be possible for users to navigate the browser in VR.\n\nThis is something that we are actively investigating solutions for.\n\n## Not much changes for WebVR\n\nAlthough Oculus Home changes how most users will access VR content, existing WebVR content continues to run without any modifications and the experience for both users and developers are mostly unchanged.\n\nThere certainly needs to be some consideration how this will change down the road, but for now, having WebVR compatible with the latest Oculus headset is a major win!\n\n## Wait, I still have questions! \n\n**Will Oculus runtime 1.3 continues to work with the Oculus DK2 developer kit?**\n\nYes, the Oculus DK2 developer kit continues to work with WebVR using the 1.3 runtime.\n\n**Why do I see an hourglass loading indicator in the headset?**\n\nAs soon as content requests access to a VR device, the Rift will display a hourglass loading indicator. Content is not presented into the headset until the user clicks an Enter VR button.\n\n**Im having trouble upgrading to the 1.3 runtime version.**\n\nIf you are upgrading from a pre-1.3 runtime, you will need to manually uninstall the sensor application, followed by the runtime, before installing the 1.3 runtime.\n\n![](/content/images/2016/05/uninstall.png)\n","source":"_posts/Everything-you-wanted-to-know-about-Oculus-CV1-Oculus-Home-1-3-runtime-and-WebVR.md","raw":"---\ntitle: >-\n  Everything you wanted to know about Oculus CV1, Oculus Home, 1.3 runtime and\n  WebVR\npermalink: oculus-home-rift-cv1-webvr\nid: 9\nupdated: '2016-05-24 13:08:08'\ndate: 2016-05-18 20:49:26\ntags: Oculus\n---\n\nThere have been questions how [WebVR](https://webvr.info/) will work with the recently released [Oculus Rift consumer headset](https://www.oculus.com/rift/), Oculus Home, and the new [1.3 version of the Oculus SDK/runtime](https://developer.oculus.com/downloads/pc/1.3.0/Oculus_SDK_for_Windows/). This post covers what we learned in the past week since its release and how to best work with WebVR using the latest updates.\n\n## Oculus 1.3 runtime support in Firefox Nightly and experimental Chromium builds\n\nUpdates to [Firefox Nightly](https://nightly.mozilla.org/) and [experimental VR-enabled Chromium builds](webvr.info/get-chrome/) are now available and working with the new Oculus 1.3 SDK/runtime, after enabling Unknown Sources from the Oculus Settings. Fortunately, you will need need to do this only once.\n\n## Enabling Unknown Sources\n\n![](/content/images/2016/05/settings.gif)\n\nIn an effort to protect users from applications that have not been reviewed by Oculus (for comfort, content, or health/safety), Oculus by default will not display content from apps obtained outside of the Oculus Store. There are plenty of interesting experiences to try from trustworthy developers including content from the Web!\n\nWhen launching WebVR from within the browser, you will be presented with an Unknown Source screen that initially blocks WebVR content from being displayed.\n\n![](/content/images/2016/05/unknown-sources.jpg)\n\nTo resolve this, you will need to check the Enable Unknown Sources option. You can access this from the Oculus settings.\n\n1. Oculus Application Settings.\n2. General settings.\n3. Toggle the Unknown Sources icon.\n\nOnce done, you will now be able to from Firefox or Chromium and launch WebVR content directly into the headset. There are no changes to how this works, and WebVR experiences continue to be launched from the desktop browser application.\n\n## Compatibility with Consumer Oculus Rift (CV1)\n\nWith 1.3 compatibility comes support for the consumer shipping versions of the Oculus Rift headset. This of course means that your content can now fully utilize the enhanced resolution, refresh rates, and tracking offered by the new headset.\n\n## Setting up Firefox and Chromium for WebVR\n\nOnce your computer is setup and running with the [latest Oculus Runtime](https://developer.oculus.com/downloads/).\n\n### Using Firefox Nightly with WebVR\n\n1. [Download VR-enabled version of Firefox Nightly](https://nightly.mozilla.org/)\n2. [Download and Install WebVR enabler](https://addons.mozilla.org/en-US/firefox/addon/mozilla-webvr-enabler/)\n3. You are now ready to use WebVR.\n\n### Using experimental Chromium builds\n\n1. [Download VR-enabled Oculus build of Chromium](https://webvr.info/get-chrome/) (you will need [7-Zip](http://www.7-zip.org/download.html) installed to extract).\n2. [Enable WebVR](https://docs.google.com/document/d/1g02qHfX85vSRSOkWm9k33I0b7VuyN79md9U9t6MIa4E/edit) flag in `chrome://flags`.\n3. You are now ready to use WebVR content.\nOnly WebVR 1.0 API is supported with the Oculus 1.3 runtime.\n\n## Viewing WebVR content\n\nTo view WebVR content, start up your WebVR-enabled browser from your desktop and navigate to a [WebVR enabled page](https://mozvr.com/). Launch content into the headset by pressing the Enter VR button on the page.\n\n![](/content/images/2016/05/mozvr.png)\n\nIt should also be noted that your headset will display a black loading screen until content is launched using the Enter VR button. You will also be presented with a health and safety warning that will need to be dismissed before content is displayed.\n\nIf Oculus Home is being displayed into the headset, the launched WebVR content will replace Home. With Oculus Home off, WebVR content is launched directly into the headset by-passing Oculus Home. Closing the browser will return the user back to Oculus Home.\n\n## Not yet integrated with Oculus Home\n\nThe most significant change with the latest runtime updates for the Rift is the addition of Oculus Home, which is a central hub for launching Oculus-compatible VR applications. The main benefit is that the Oculus Home interface is accessible from both the desktop and within VR: a nice convenience that allows users to not have to take off the headset to navigate and launch into another application.\n\n![](/content/images/2016/05/home.png)\n\nOculus Home is unfortunately not yet integrated with the current desktop-browser based WebVR implementations since neither Firefox or Chromium currently implements a UI that can be rendered in VR. All navigation is done using the traditional desktop interface, and without VR UI, it wont be possible for users to navigate the browser in VR.\n\nThis is something that we are actively investigating solutions for.\n\n## Not much changes for WebVR\n\nAlthough Oculus Home changes how most users will access VR content, existing WebVR content continues to run without any modifications and the experience for both users and developers are mostly unchanged.\n\nThere certainly needs to be some consideration how this will change down the road, but for now, having WebVR compatible with the latest Oculus headset is a major win!\n\n## Wait, I still have questions! \n\n**Will Oculus runtime 1.3 continues to work with the Oculus DK2 developer kit?**\n\nYes, the Oculus DK2 developer kit continues to work with WebVR using the 1.3 runtime.\n\n**Why do I see an hourglass loading indicator in the headset?**\n\nAs soon as content requests access to a VR device, the Rift will display a hourglass loading indicator. Content is not presented into the headset until the user clicks an Enter VR button.\n\n**Im having trouble upgrading to the 1.3 runtime version.**\n\nIf you are upgrading from a pre-1.3 runtime, you will need to manually uninstall the sensor application, followed by the runtime, before installing the 1.3 runtime.\n\n![](/content/images/2016/05/uninstall.png)\n","slug":"oculus-home-rift-cv1-webvr","published":1,"_id":"citot8hyr000bik1j7i34gioj","comments":1,"layout":"post","photos":[],"link":"","content":"<p>There have been questions how <a href=\"https://webvr.info/\" target=\"_blank\" rel=\"external\">WebVR</a> will work with the recently released <a href=\"https://www.oculus.com/rift/\" target=\"_blank\" rel=\"external\">Oculus Rift consumer headset</a>, Oculus Home, and the new <a href=\"https://developer.oculus.com/downloads/pc/1.3.0/Oculus_SDK_for_Windows/\" target=\"_blank\" rel=\"external\">1.3 version of the Oculus SDK/runtime</a>. This post covers what we learned in the past week since its release and how to best work with WebVR using the latest updates.</p>\n<h2 id=\"Oculus-1-3-runtime-support-in-Firefox-Nightly-and-experimental-Chromium-builds\"><a href=\"#Oculus-1-3-runtime-support-in-Firefox-Nightly-and-experimental-Chromium-builds\" class=\"headerlink\" title=\"Oculus 1.3 runtime support in Firefox Nightly and experimental Chromium builds\"></a>Oculus 1.3 runtime support in Firefox Nightly and experimental Chromium builds</h2><p>Updates to <a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a> and <a href=\"webvr.info/get-chrome/\">experimental VR-enabled Chromium builds</a> are now available and working with the new Oculus 1.3 SDK/runtime, after enabling Unknown Sources from the Oculus Settings. Fortunately, you will need need to do this only once.</p>\n<h2 id=\"Enabling-Unknown-Sources\"><a href=\"#Enabling-Unknown-Sources\" class=\"headerlink\" title=\"Enabling Unknown Sources\"></a>Enabling Unknown Sources</h2><p><img src=\"/content/images/2016/05/settings.gif\" alt=\"\"></p>\n<p>In an effort to protect users from applications that have not been reviewed by Oculus (for comfort, content, or health/safety), Oculus by default will not display content from apps obtained outside of the Oculus Store. There are plenty of interesting experiences to try from trustworthy developers including content from the Web!</p>\n<p>When launching WebVR from within the browser, you will be presented with an Unknown Source screen that initially blocks WebVR content from being displayed.</p>\n<p><img src=\"/content/images/2016/05/unknown-sources.jpg\" alt=\"\"></p>\n<p>To resolve this, you will need to check the Enable Unknown Sources option. You can access this from the Oculus settings.</p>\n<ol>\n<li>Oculus Application Settings.</li>\n<li>General settings.</li>\n<li>Toggle the Unknown Sources icon.</li>\n</ol>\n<p>Once done, you will now be able to from Firefox or Chromium and launch WebVR content directly into the headset. There are no changes to how this works, and WebVR experiences continue to be launched from the desktop browser application.</p>\n<h2 id=\"Compatibility-with-Consumer-Oculus-Rift-CV1\"><a href=\"#Compatibility-with-Consumer-Oculus-Rift-CV1\" class=\"headerlink\" title=\"Compatibility with Consumer Oculus Rift (CV1)\"></a>Compatibility with Consumer Oculus Rift (CV1)</h2><p>With 1.3 compatibility comes support for the consumer shipping versions of the Oculus Rift headset. This of course means that your content can now fully utilize the enhanced resolution, refresh rates, and tracking offered by the new headset.</p>\n<h2 id=\"Setting-up-Firefox-and-Chromium-for-WebVR\"><a href=\"#Setting-up-Firefox-and-Chromium-for-WebVR\" class=\"headerlink\" title=\"Setting up Firefox and Chromium for WebVR\"></a>Setting up Firefox and Chromium for WebVR</h2><p>Once your computer is setup and running with the <a href=\"https://developer.oculus.com/downloads/\" target=\"_blank\" rel=\"external\">latest Oculus Runtime</a>.</p>\n<h3 id=\"Using-Firefox-Nightly-with-WebVR\"><a href=\"#Using-Firefox-Nightly-with-WebVR\" class=\"headerlink\" title=\"Using Firefox Nightly with WebVR\"></a>Using Firefox Nightly with WebVR</h3><ol>\n<li><a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Download VR-enabled version of Firefox Nightly</a></li>\n<li><a href=\"https://addons.mozilla.org/en-US/firefox/addon/mozilla-webvr-enabler/\" target=\"_blank\" rel=\"external\">Download and Install WebVR enabler</a></li>\n<li>You are now ready to use WebVR.</li>\n</ol>\n<h3 id=\"Using-experimental-Chromium-builds\"><a href=\"#Using-experimental-Chromium-builds\" class=\"headerlink\" title=\"Using experimental Chromium builds\"></a>Using experimental Chromium builds</h3><ol>\n<li><a href=\"https://webvr.info/get-chrome/\" target=\"_blank\" rel=\"external\">Download VR-enabled Oculus build of Chromium</a> (you will need <a href=\"http://www.7-zip.org/download.html\" target=\"_blank\" rel=\"external\">7-Zip</a> installed to extract).</li>\n<li><a href=\"https://docs.google.com/document/d/1g02qHfX85vSRSOkWm9k33I0b7VuyN79md9U9t6MIa4E/edit\" target=\"_blank\" rel=\"external\">Enable WebVR</a> flag in <code>chrome://flags</code>.</li>\n<li>You are now ready to use WebVR content.<br>Only WebVR 1.0 API is supported with the Oculus 1.3 runtime.</li>\n</ol>\n<h2 id=\"Viewing-WebVR-content\"><a href=\"#Viewing-WebVR-content\" class=\"headerlink\" title=\"Viewing WebVR content\"></a>Viewing WebVR content</h2><p>To view WebVR content, start up your WebVR-enabled browser from your desktop and navigate to a <a href=\"https://mozvr.com/\" target=\"_blank\" rel=\"external\">WebVR enabled page</a>. Launch content into the headset by pressing the Enter VR button on the page.</p>\n<p><img src=\"/content/images/2016/05/mozvr.png\" alt=\"\"></p>\n<p>It should also be noted that your headset will display a black loading screen until content is launched using the Enter VR button. You will also be presented with a health and safety warning that will need to be dismissed before content is displayed.</p>\n<p>If Oculus Home is being displayed into the headset, the launched WebVR content will replace Home. With Oculus Home off, WebVR content is launched directly into the headset by-passing Oculus Home. Closing the browser will return the user back to Oculus Home.</p>\n<h2 id=\"Not-yet-integrated-with-Oculus-Home\"><a href=\"#Not-yet-integrated-with-Oculus-Home\" class=\"headerlink\" title=\"Not yet integrated with Oculus Home\"></a>Not yet integrated with Oculus Home</h2><p>The most significant change with the latest runtime updates for the Rift is the addition of Oculus Home, which is a central hub for launching Oculus-compatible VR applications. The main benefit is that the Oculus Home interface is accessible from both the desktop and within VR: a nice convenience that allows users to not have to take off the headset to navigate and launch into another application.</p>\n<p><img src=\"/content/images/2016/05/home.png\" alt=\"\"></p>\n<p>Oculus Home is unfortunately not yet integrated with the current desktop-browser based WebVR implementations since neither Firefox or Chromium currently implements a UI that can be rendered in VR. All navigation is done using the traditional desktop interface, and without VR UI, it wont be possible for users to navigate the browser in VR.</p>\n<p>This is something that we are actively investigating solutions for.</p>\n<h2 id=\"Not-much-changes-for-WebVR\"><a href=\"#Not-much-changes-for-WebVR\" class=\"headerlink\" title=\"Not much changes for WebVR\"></a>Not much changes for WebVR</h2><p>Although Oculus Home changes how most users will access VR content, existing WebVR content continues to run without any modifications and the experience for both users and developers are mostly unchanged.</p>\n<p>There certainly needs to be some consideration how this will change down the road, but for now, having WebVR compatible with the latest Oculus headset is a major win!</p>\n<h2 id=\"Wait-I-still-have-questions\"><a href=\"#Wait-I-still-have-questions\" class=\"headerlink\" title=\"Wait, I still have questions!\"></a>Wait, I still have questions!</h2><p><strong>Will Oculus runtime 1.3 continues to work with the Oculus DK2 developer kit?</strong></p>\n<p>Yes, the Oculus DK2 developer kit continues to work with WebVR using the 1.3 runtime.</p>\n<p><strong>Why do I see an hourglass loading indicator in the headset?</strong></p>\n<p>As soon as content requests access to a VR device, the Rift will display a hourglass loading indicator. Content is not presented into the headset until the user clicks an Enter VR button.</p>\n<p><strong>Im having trouble upgrading to the 1.3 runtime version.</strong></p>\n<p>If you are upgrading from a pre-1.3 runtime, you will need to manually uninstall the sensor application, followed by the runtime, before installing the 1.3 runtime.</p>\n<p><img src=\"/content/images/2016/05/uninstall.png\" alt=\"\"></p>\n","excerpt":"","more":"<p>There have been questions how <a href=\"https://webvr.info/\">WebVR</a> will work with the recently released <a href=\"https://www.oculus.com/rift/\">Oculus Rift consumer headset</a>, Oculus Home, and the new <a href=\"https://developer.oculus.com/downloads/pc/1.3.0/Oculus_SDK_for_Windows/\">1.3 version of the Oculus SDK/runtime</a>. This post covers what we learned in the past week since its release and how to best work with WebVR using the latest updates.</p>\n<h2 id=\"Oculus-1-3-runtime-support-in-Firefox-Nightly-and-experimental-Chromium-builds\"><a href=\"#Oculus-1-3-runtime-support-in-Firefox-Nightly-and-experimental-Chromium-builds\" class=\"headerlink\" title=\"Oculus 1.3 runtime support in Firefox Nightly and experimental Chromium builds\"></a>Oculus 1.3 runtime support in Firefox Nightly and experimental Chromium builds</h2><p>Updates to <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a> and <a href=\"webvr.info/get-chrome/\">experimental VR-enabled Chromium builds</a> are now available and working with the new Oculus 1.3 SDK/runtime, after enabling Unknown Sources from the Oculus Settings. Fortunately, you will need need to do this only once.</p>\n<h2 id=\"Enabling-Unknown-Sources\"><a href=\"#Enabling-Unknown-Sources\" class=\"headerlink\" title=\"Enabling Unknown Sources\"></a>Enabling Unknown Sources</h2><p><img src=\"/content/images/2016/05/settings.gif\" alt=\"\"></p>\n<p>In an effort to protect users from applications that have not been reviewed by Oculus (for comfort, content, or health/safety), Oculus by default will not display content from apps obtained outside of the Oculus Store. There are plenty of interesting experiences to try from trustworthy developers including content from the Web!</p>\n<p>When launching WebVR from within the browser, you will be presented with an Unknown Source screen that initially blocks WebVR content from being displayed.</p>\n<p><img src=\"/content/images/2016/05/unknown-sources.jpg\" alt=\"\"></p>\n<p>To resolve this, you will need to check the Enable Unknown Sources option. You can access this from the Oculus settings.</p>\n<ol>\n<li>Oculus Application Settings.</li>\n<li>General settings.</li>\n<li>Toggle the Unknown Sources icon.</li>\n</ol>\n<p>Once done, you will now be able to from Firefox or Chromium and launch WebVR content directly into the headset. There are no changes to how this works, and WebVR experiences continue to be launched from the desktop browser application.</p>\n<h2 id=\"Compatibility-with-Consumer-Oculus-Rift-CV1\"><a href=\"#Compatibility-with-Consumer-Oculus-Rift-CV1\" class=\"headerlink\" title=\"Compatibility with Consumer Oculus Rift (CV1)\"></a>Compatibility with Consumer Oculus Rift (CV1)</h2><p>With 1.3 compatibility comes support for the consumer shipping versions of the Oculus Rift headset. This of course means that your content can now fully utilize the enhanced resolution, refresh rates, and tracking offered by the new headset.</p>\n<h2 id=\"Setting-up-Firefox-and-Chromium-for-WebVR\"><a href=\"#Setting-up-Firefox-and-Chromium-for-WebVR\" class=\"headerlink\" title=\"Setting up Firefox and Chromium for WebVR\"></a>Setting up Firefox and Chromium for WebVR</h2><p>Once your computer is setup and running with the <a href=\"https://developer.oculus.com/downloads/\">latest Oculus Runtime</a>.</p>\n<h3 id=\"Using-Firefox-Nightly-with-WebVR\"><a href=\"#Using-Firefox-Nightly-with-WebVR\" class=\"headerlink\" title=\"Using Firefox Nightly with WebVR\"></a>Using Firefox Nightly with WebVR</h3><ol>\n<li><a href=\"https://nightly.mozilla.org/\">Download VR-enabled version of Firefox Nightly</a></li>\n<li><a href=\"https://addons.mozilla.org/en-US/firefox/addon/mozilla-webvr-enabler/\">Download and Install WebVR enabler</a></li>\n<li>You are now ready to use WebVR.</li>\n</ol>\n<h3 id=\"Using-experimental-Chromium-builds\"><a href=\"#Using-experimental-Chromium-builds\" class=\"headerlink\" title=\"Using experimental Chromium builds\"></a>Using experimental Chromium builds</h3><ol>\n<li><a href=\"https://webvr.info/get-chrome/\">Download VR-enabled Oculus build of Chromium</a> (you will need <a href=\"http://www.7-zip.org/download.html\">7-Zip</a> installed to extract).</li>\n<li><a href=\"https://docs.google.com/document/d/1g02qHfX85vSRSOkWm9k33I0b7VuyN79md9U9t6MIa4E/edit\">Enable WebVR</a> flag in <code>chrome://flags</code>.</li>\n<li>You are now ready to use WebVR content.<br>Only WebVR 1.0 API is supported with the Oculus 1.3 runtime.</li>\n</ol>\n<h2 id=\"Viewing-WebVR-content\"><a href=\"#Viewing-WebVR-content\" class=\"headerlink\" title=\"Viewing WebVR content\"></a>Viewing WebVR content</h2><p>To view WebVR content, start up your WebVR-enabled browser from your desktop and navigate to a <a href=\"https://mozvr.com/\">WebVR enabled page</a>. Launch content into the headset by pressing the Enter VR button on the page.</p>\n<p><img src=\"/content/images/2016/05/mozvr.png\" alt=\"\"></p>\n<p>It should also be noted that your headset will display a black loading screen until content is launched using the Enter VR button. You will also be presented with a health and safety warning that will need to be dismissed before content is displayed.</p>\n<p>If Oculus Home is being displayed into the headset, the launched WebVR content will replace Home. With Oculus Home off, WebVR content is launched directly into the headset by-passing Oculus Home. Closing the browser will return the user back to Oculus Home.</p>\n<h2 id=\"Not-yet-integrated-with-Oculus-Home\"><a href=\"#Not-yet-integrated-with-Oculus-Home\" class=\"headerlink\" title=\"Not yet integrated with Oculus Home\"></a>Not yet integrated with Oculus Home</h2><p>The most significant change with the latest runtime updates for the Rift is the addition of Oculus Home, which is a central hub for launching Oculus-compatible VR applications. The main benefit is that the Oculus Home interface is accessible from both the desktop and within VR: a nice convenience that allows users to not have to take off the headset to navigate and launch into another application.</p>\n<p><img src=\"/content/images/2016/05/home.png\" alt=\"\"></p>\n<p>Oculus Home is unfortunately not yet integrated with the current desktop-browser based WebVR implementations since neither Firefox or Chromium currently implements a UI that can be rendered in VR. All navigation is done using the traditional desktop interface, and without VR UI, it wont be possible for users to navigate the browser in VR.</p>\n<p>This is something that we are actively investigating solutions for.</p>\n<h2 id=\"Not-much-changes-for-WebVR\"><a href=\"#Not-much-changes-for-WebVR\" class=\"headerlink\" title=\"Not much changes for WebVR\"></a>Not much changes for WebVR</h2><p>Although Oculus Home changes how most users will access VR content, existing WebVR content continues to run without any modifications and the experience for both users and developers are mostly unchanged.</p>\n<p>There certainly needs to be some consideration how this will change down the road, but for now, having WebVR compatible with the latest Oculus headset is a major win!</p>\n<h2 id=\"Wait-I-still-have-questions\"><a href=\"#Wait-I-still-have-questions\" class=\"headerlink\" title=\"Wait, I still have questions!\"></a>Wait, I still have questions!</h2><p><strong>Will Oculus runtime 1.3 continues to work with the Oculus DK2 developer kit?</strong></p>\n<p>Yes, the Oculus DK2 developer kit continues to work with WebVR using the 1.3 runtime.</p>\n<p><strong>Why do I see an hourglass loading indicator in the headset?</strong></p>\n<p>As soon as content requests access to a VR device, the Rift will display a hourglass loading indicator. Content is not presented into the headset until the user clicks an Enter VR button.</p>\n<p><strong>Im having trouble upgrading to the 1.3 runtime version.</strong></p>\n<p>If you are upgrading from a pre-1.3 runtime, you will need to manually uninstall the sensor application, followed by the runtime, before installing the 1.3 runtime.</p>\n<p><img src=\"/content/images/2016/05/uninstall.png\" alt=\"\"></p>\n"},{"title":"Experimental HTC Vive Support in Firefox Nightly","id":"24","updated":"2016-09-24T02:36:32.000Z","date":"2016-09-24T02:08:30.000Z","_content":"\nAs of September 1st, [Firefox Nightly](https://nightly.mozilla.org/) will include experimental support for the [HTC Vive](https://www.htcvive.com/) headsets through the [OpenVR API](https://github.com/ValveSoftware/openvr). This is one of several upcoming hardware support updates that we will be announcing in the coming weeks, including support for the HTC Vive controllers, Oculus Touch controllers, and [OSVR headsets](http://www.osvr.org/hardware/buy/). Firefox will include support for WebVR on Mac and Linux using the OSVR API.\n\nThe HTC Vive includes the Lighthouse tracking system, which can track the position and orientation of the VR headset anywhere within a room-sized volume of space. Users can now enter a WebVR site and walk naturally around.\n\nHTC Vive Support is still experimental and support for the controllers [will be added separately](https://bugzilla.mozilla.org/show_bug.cgi?id=1299926) in a later update. To try it out early, follow these steps to enable it in the current [Firefox Nightly](https://nightly.mozilla.org/):\n\n1. It is recommended that you start with a clean profile by [refreshing Firefox](https://support.mozilla.org/en-US/kb/refresh-firefox-reset-add-ons-and-settings). Some preference adjustments needed for earlier WebVR builds will cause problems with the current Nightly build.\n2. Download version 1.02 of the `openvr_api.dll` from the [OpenVR GitHub](https://github.com/ValveSoftware/openvr) repository. A 64-bit machine is recommended for WebVR; [download the 64-bit version here](https://github.com/ValveSoftware/openvr/raw/master/bin/win64/openvr_api.dll). If you do not have a 64-bit version, you can [download the 32-bit version](https://github.com/ValveSoftware/openvr/raw/master/bin/win32/openvr_api.dll).\n3. Save the <code>openvr_api.dll</code> file somewhere on your computer where the user running Firefox can read it. For example, you could create a directory (e.g., `C:\\openvr\\`) and place the `DLL` there.\n4. In Firefox Nightly, navigate to `about:config`.\n  1. Change the value of `dom.vr.openvr.enabled` to `true`.\n  2. Change the value of `gfx.vr.openvr-runtime` to the full path of the `openvr_api.dll` that was downloaded (e.g., `C:\\openvr\\openvr_api.dll`).\n7. Restart Firefox Nightly.\n\nTo test if it works, try some of the [WebVR 1.0 examples](https://webvr.info/samples/) or sites such as [SketchFab](https://sketchfab.com/) that support room-scale WebVR. To make your own WebVR sites, check out [A-Frame](https://aframe.io/), [three.js](http://threejs.org/), or the [WebVR 1.0 Spec](https://w3c.github.io/webvr/) for details.\n\n### Credits\nSpecial thanks to [Christin Gilbert](https://twitter.com/christingilbert) for the [Vive header photo](https://blog.mozvr.com/content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg).\n","source":"_posts/Experimental-HTC-Vive-Support-in-Firefox-Nightly.md","raw":"---\ntitle: Experimental HTC Vive Support in Firefox Nightly\npermalink: experimental-htc-vive-support-in-firefox-nightly\nid: 24\nupdated: '2016-09-23 19:36:32'\ndate: 2016-09-23 19:08:30\ntags:\n  - Platform\n  - HTC VIVE\n---\n\nAs of September 1st, [Firefox Nightly](https://nightly.mozilla.org/) will include experimental support for the [HTC Vive](https://www.htcvive.com/) headsets through the [OpenVR API](https://github.com/ValveSoftware/openvr). This is one of several upcoming hardware support updates that we will be announcing in the coming weeks, including support for the HTC Vive controllers, Oculus Touch controllers, and [OSVR headsets](http://www.osvr.org/hardware/buy/). Firefox will include support for WebVR on Mac and Linux using the OSVR API.\n\nThe HTC Vive includes the Lighthouse tracking system, which can track the position and orientation of the VR headset anywhere within a room-sized volume of space. Users can now enter a WebVR site and walk naturally around.\n\nHTC Vive Support is still experimental and support for the controllers [will be added separately](https://bugzilla.mozilla.org/show_bug.cgi?id=1299926) in a later update. To try it out early, follow these steps to enable it in the current [Firefox Nightly](https://nightly.mozilla.org/):\n\n1. It is recommended that you start with a clean profile by [refreshing Firefox](https://support.mozilla.org/en-US/kb/refresh-firefox-reset-add-ons-and-settings). Some preference adjustments needed for earlier WebVR builds will cause problems with the current Nightly build.\n2. Download version 1.02 of the `openvr_api.dll` from the [OpenVR GitHub](https://github.com/ValveSoftware/openvr) repository. A 64-bit machine is recommended for WebVR; [download the 64-bit version here](https://github.com/ValveSoftware/openvr/raw/master/bin/win64/openvr_api.dll). If you do not have a 64-bit version, you can [download the 32-bit version](https://github.com/ValveSoftware/openvr/raw/master/bin/win32/openvr_api.dll).\n3. Save the <code>openvr_api.dll</code> file somewhere on your computer where the user running Firefox can read it. For example, you could create a directory (e.g., `C:\\openvr\\`) and place the `DLL` there.\n4. In Firefox Nightly, navigate to `about:config`.\n  1. Change the value of `dom.vr.openvr.enabled` to `true`.\n  2. Change the value of `gfx.vr.openvr-runtime` to the full path of the `openvr_api.dll` that was downloaded (e.g., `C:\\openvr\\openvr_api.dll`).\n7. Restart Firefox Nightly.\n\nTo test if it works, try some of the [WebVR 1.0 examples](https://webvr.info/samples/) or sites such as [SketchFab](https://sketchfab.com/) that support room-scale WebVR. To make your own WebVR sites, check out [A-Frame](https://aframe.io/), [three.js](http://threejs.org/), or the [WebVR 1.0 Spec](https://w3c.github.io/webvr/) for details.\n\n### Credits\nSpecial thanks to [Christin Gilbert](https://twitter.com/christingilbert) for the [Vive header photo](https://blog.mozvr.com/content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg).\n","slug":"experimental-htc-vive-support-in-firefox-nightly","published":1,"_id":"citot8hyt000eik1jcacfzk6x","comments":1,"layout":"post","photos":[],"link":"","content":"<p>As of September 1st, <a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a> will include experimental support for the <a href=\"https://www.htcvive.com/\" target=\"_blank\" rel=\"external\">HTC Vive</a> headsets through the <a href=\"https://github.com/ValveSoftware/openvr\" target=\"_blank\" rel=\"external\">OpenVR API</a>. This is one of several upcoming hardware support updates that we will be announcing in the coming weeks, including support for the HTC Vive controllers, Oculus Touch controllers, and <a href=\"http://www.osvr.org/hardware/buy/\" target=\"_blank\" rel=\"external\">OSVR headsets</a>. Firefox will include support for WebVR on Mac and Linux using the OSVR API.</p>\n<p>The HTC Vive includes the Lighthouse tracking system, which can track the position and orientation of the VR headset anywhere within a room-sized volume of space. Users can now enter a WebVR site and walk naturally around.</p>\n<p>HTC Vive Support is still experimental and support for the controllers <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1299926\" target=\"_blank\" rel=\"external\">will be added separately</a> in a later update. To try it out early, follow these steps to enable it in the current <a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a>:</p>\n<ol>\n<li>It is recommended that you start with a clean profile by <a href=\"https://support.mozilla.org/en-US/kb/refresh-firefox-reset-add-ons-and-settings\" target=\"_blank\" rel=\"external\">refreshing Firefox</a>. Some preference adjustments needed for earlier WebVR builds will cause problems with the current Nightly build.</li>\n<li>Download version 1.02 of the <code>openvr_api.dll</code> from the <a href=\"https://github.com/ValveSoftware/openvr\" target=\"_blank\" rel=\"external\">OpenVR GitHub</a> repository. A 64-bit machine is recommended for WebVR; <a href=\"https://github.com/ValveSoftware/openvr/raw/master/bin/win64/openvr_api.dll\" target=\"_blank\" rel=\"external\">download the 64-bit version here</a>. If you do not have a 64-bit version, you can <a href=\"https://github.com/ValveSoftware/openvr/raw/master/bin/win32/openvr_api.dll\" target=\"_blank\" rel=\"external\">download the 32-bit version</a>.</li>\n<li>Save the <code>openvr_api.dll</code> file somewhere on your computer where the user running Firefox can read it. For example, you could create a directory (e.g., <code>C:\\openvr\\</code>) and place the <code>DLL</code> there.</li>\n<li>In Firefox Nightly, navigate to <code>about:config</code>.<ol>\n<li>Change the value of <code>dom.vr.openvr.enabled</code> to <code>true</code>.</li>\n<li>Change the value of <code>gfx.vr.openvr-runtime</code> to the full path of the <code>openvr_api.dll</code> that was downloaded (e.g., <code>C:\\openvr\\openvr_api.dll</code>).</li>\n</ol>\n</li>\n<li>Restart Firefox Nightly.</li>\n</ol>\n<p>To test if it works, try some of the <a href=\"https://webvr.info/samples/\" target=\"_blank\" rel=\"external\">WebVR 1.0 examples</a> or sites such as <a href=\"https://sketchfab.com/\" target=\"_blank\" rel=\"external\">SketchFab</a> that support room-scale WebVR. To make your own WebVR sites, check out <a href=\"https://aframe.io/\" target=\"_blank\" rel=\"external\">A-Frame</a>, <a href=\"http://threejs.org/\" target=\"_blank\" rel=\"external\">three.js</a>, or the <a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">WebVR 1.0 Spec</a> for details.</p>\n<h3 id=\"Credits\"><a href=\"#Credits\" class=\"headerlink\" title=\"Credits\"></a>Credits</h3><p>Special thanks to <a href=\"https://twitter.com/christingilbert\" target=\"_blank\" rel=\"external\">Christin Gilbert</a> for the <a href=\"https://blog.mozvr.com/content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg\" target=\"_blank\" rel=\"external\">Vive header photo</a>.</p>\n","excerpt":"","more":"<p>As of September 1st, <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a> will include experimental support for the <a href=\"https://www.htcvive.com/\">HTC Vive</a> headsets through the <a href=\"https://github.com/ValveSoftware/openvr\">OpenVR API</a>. This is one of several upcoming hardware support updates that we will be announcing in the coming weeks, including support for the HTC Vive controllers, Oculus Touch controllers, and <a href=\"http://www.osvr.org/hardware/buy/\">OSVR headsets</a>. Firefox will include support for WebVR on Mac and Linux using the OSVR API.</p>\n<p>The HTC Vive includes the Lighthouse tracking system, which can track the position and orientation of the VR headset anywhere within a room-sized volume of space. Users can now enter a WebVR site and walk naturally around.</p>\n<p>HTC Vive Support is still experimental and support for the controllers <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1299926\">will be added separately</a> in a later update. To try it out early, follow these steps to enable it in the current <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a>:</p>\n<ol>\n<li>It is recommended that you start with a clean profile by <a href=\"https://support.mozilla.org/en-US/kb/refresh-firefox-reset-add-ons-and-settings\">refreshing Firefox</a>. Some preference adjustments needed for earlier WebVR builds will cause problems with the current Nightly build.</li>\n<li>Download version 1.02 of the <code>openvr_api.dll</code> from the <a href=\"https://github.com/ValveSoftware/openvr\">OpenVR GitHub</a> repository. A 64-bit machine is recommended for WebVR; <a href=\"https://github.com/ValveSoftware/openvr/raw/master/bin/win64/openvr_api.dll\">download the 64-bit version here</a>. If you do not have a 64-bit version, you can <a href=\"https://github.com/ValveSoftware/openvr/raw/master/bin/win32/openvr_api.dll\">download the 32-bit version</a>.</li>\n<li>Save the <code>openvr_api.dll</code> file somewhere on your computer where the user running Firefox can read it. For example, you could create a directory (e.g., <code>C:\\openvr\\</code>) and place the <code>DLL</code> there.</li>\n<li>In Firefox Nightly, navigate to <code>about:config</code>.<ol>\n<li>Change the value of <code>dom.vr.openvr.enabled</code> to <code>true</code>.</li>\n<li>Change the value of <code>gfx.vr.openvr-runtime</code> to the full path of the <code>openvr_api.dll</code> that was downloaded (e.g., <code>C:\\openvr\\openvr_api.dll</code>).</li>\n</ol>\n</li>\n<li>Restart Firefox Nightly.</li>\n</ol>\n<p>To test if it works, try some of the <a href=\"https://webvr.info/samples/\">WebVR 1.0 examples</a> or sites such as <a href=\"https://sketchfab.com/\">SketchFab</a> that support room-scale WebVR. To make your own WebVR sites, check out <a href=\"https://aframe.io/\">A-Frame</a>, <a href=\"http://threejs.org/\">three.js</a>, or the <a href=\"https://w3c.github.io/webvr/\">WebVR 1.0 Spec</a> for details.</p>\n<h3 id=\"Credits\"><a href=\"#Credits\" class=\"headerlink\" title=\"Credits\"></a>Credits</h3><p>Special thanks to <a href=\"https://twitter.com/christingilbert\">Christin Gilbert</a> for the <a href=\"https://blog.mozvr.com/content/images/2016/09/1-rppPzXIHehdGoJH6LKSIrg--1-.jpeg\">Vive header photo</a>.</p>\n"},{"title":"Fun WebVR Times at Innovation High","id":"10","updated":"2016-06-03T09:43:37.000Z","date":"2016-05-23T05:33:59.000Z","_content":"\nA group of high school students at New York's [Innovation High School](http://www.innovationhighschool.org/) attended a three-day workshop to learn how to make WebVR scenes using [A-Frame](https://aframe.io/).\n\nThis workshop was made possible by [Mozilla's Tech Speakers program](https://wiki.mozilla.org/TechSpeakers), presented by volunteer [Rabimba Karanjai](https://twitter.com/rabimba). Rabimba is an active Mozilla volunteer contributor, A-Frame enthusiast, and PhD student at [Rice University](http://www.rice.edu/).\n\n[Read his full blog post here.](http://blog.rabimba.com/2016/05/vr-for-everyone-when-you-get-to-play.html)\n\nAnd additional resources are available below:\n\n* [Slides for introductory A-Frame curriculum deck.](https://docs.google.com/presentation/d/1_Bo8CIlpcXfv7115qyM8t20nNufM_O874lWy24_0WRM/edit)\n* [Slides about A-Frame animations.](https://docs.google.com/presentation/d/1aPFz3aLBxa1x1B95GsUd6BmgUUXIudYpB2bQPfYAi-s/edit)\n* [CodePen examples.](http://codepen.io/rabimba/)\n\n\n![](/content/images/2016/05/IMG_20160314_135219.jpg)\n\n![](/content/images/2016/05/IMG_20160315_112900.jpg)\n\n![](/content/images/2016/05/IMG_20160315_111705.jpg)\n\n![](/content/images/2016/05/IMG_20160314_123708.jpg)\n\n![](/content/images/2016/05/PANO_20160314_123750.jpg)\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/0YIk_WD8Ox8?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/-1CIviLNU3w?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/F2-561renpg?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n","source":"_posts/Fun-WebVR-Times-at-Innovation-High.md","raw":"---\ntitle: Fun WebVR Times at Innovation High\ntags: Community\npermalink: fun-webvr-times-at-innovation-high\nid: 10\nupdated: '2016-06-03 02:43:37'\ndate: 2016-05-22 22:33:59\n---\n\nA group of high school students at New York's [Innovation High School](http://www.innovationhighschool.org/) attended a three-day workshop to learn how to make WebVR scenes using [A-Frame](https://aframe.io/).\n\nThis workshop was made possible by [Mozilla's Tech Speakers program](https://wiki.mozilla.org/TechSpeakers), presented by volunteer [Rabimba Karanjai](https://twitter.com/rabimba). Rabimba is an active Mozilla volunteer contributor, A-Frame enthusiast, and PhD student at [Rice University](http://www.rice.edu/).\n\n[Read his full blog post here.](http://blog.rabimba.com/2016/05/vr-for-everyone-when-you-get-to-play.html)\n\nAnd additional resources are available below:\n\n* [Slides for introductory A-Frame curriculum deck.](https://docs.google.com/presentation/d/1_Bo8CIlpcXfv7115qyM8t20nNufM_O874lWy24_0WRM/edit)\n* [Slides about A-Frame animations.](https://docs.google.com/presentation/d/1aPFz3aLBxa1x1B95GsUd6BmgUUXIudYpB2bQPfYAi-s/edit)\n* [CodePen examples.](http://codepen.io/rabimba/)\n\n\n![](/content/images/2016/05/IMG_20160314_135219.jpg)\n\n![](/content/images/2016/05/IMG_20160315_112900.jpg)\n\n![](/content/images/2016/05/IMG_20160315_111705.jpg)\n\n![](/content/images/2016/05/IMG_20160314_123708.jpg)\n\n![](/content/images/2016/05/PANO_20160314_123750.jpg)\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/0YIk_WD8Ox8?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/-1CIviLNU3w?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/F2-561renpg?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n","slug":"fun-webvr-times-at-innovation-high","published":1,"_id":"citot8hyv000fik1j01g9csdw","comments":1,"layout":"post","photos":[],"link":"","content":"<p>A group of high school students at New Yorks <a href=\"http://www.innovationhighschool.org/\" target=\"_blank\" rel=\"external\">Innovation High School</a> attended a three-day workshop to learn how to make WebVR scenes using <a href=\"https://aframe.io/\" target=\"_blank\" rel=\"external\">A-Frame</a>.</p>\n<p>This workshop was made possible by <a href=\"https://wiki.mozilla.org/TechSpeakers\" target=\"_blank\" rel=\"external\">Mozillas Tech Speakers program</a>, presented by volunteer <a href=\"https://twitter.com/rabimba\" target=\"_blank\" rel=\"external\">Rabimba Karanjai</a>. Rabimba is an active Mozilla volunteer contributor, A-Frame enthusiast, and PhD student at <a href=\"http://www.rice.edu/\" target=\"_blank\" rel=\"external\">Rice University</a>.</p>\n<p><a href=\"http://blog.rabimba.com/2016/05/vr-for-everyone-when-you-get-to-play.html\" target=\"_blank\" rel=\"external\">Read his full blog post here.</a></p>\n<p>And additional resources are available below:</p>\n<ul>\n<li><a href=\"https://docs.google.com/presentation/d/1_Bo8CIlpcXfv7115qyM8t20nNufM_O874lWy24_0WRM/edit\" target=\"_blank\" rel=\"external\">Slides for introductory A-Frame curriculum deck.</a></li>\n<li><a href=\"https://docs.google.com/presentation/d/1aPFz3aLBxa1x1B95GsUd6BmgUUXIudYpB2bQPfYAi-s/edit\" target=\"_blank\" rel=\"external\">Slides about A-Frame animations.</a></li>\n<li><a href=\"http://codepen.io/rabimba/\" target=\"_blank\" rel=\"external\">CodePen examples.</a></li>\n</ul>\n<p><img src=\"/content/images/2016/05/IMG_20160314_135219.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/IMG_20160315_112900.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/IMG_20160315_111705.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/IMG_20160314_123708.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/PANO_20160314_123750.jpg\" alt=\"\"></p>\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/0YIk_WD8Ox8?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/-1CIviLNU3w?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/F2-561renpg?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n","excerpt":"","more":"<p>A group of high school students at New Yorks <a href=\"http://www.innovationhighschool.org/\">Innovation High School</a> attended a three-day workshop to learn how to make WebVR scenes using <a href=\"https://aframe.io/\">A-Frame</a>.</p>\n<p>This workshop was made possible by <a href=\"https://wiki.mozilla.org/TechSpeakers\">Mozillas Tech Speakers program</a>, presented by volunteer <a href=\"https://twitter.com/rabimba\">Rabimba Karanjai</a>. Rabimba is an active Mozilla volunteer contributor, A-Frame enthusiast, and PhD student at <a href=\"http://www.rice.edu/\">Rice University</a>.</p>\n<p><a href=\"http://blog.rabimba.com/2016/05/vr-for-everyone-when-you-get-to-play.html\">Read his full blog post here.</a></p>\n<p>And additional resources are available below:</p>\n<ul>\n<li><a href=\"https://docs.google.com/presentation/d/1_Bo8CIlpcXfv7115qyM8t20nNufM_O874lWy24_0WRM/edit\">Slides for introductory A-Frame curriculum deck.</a></li>\n<li><a href=\"https://docs.google.com/presentation/d/1aPFz3aLBxa1x1B95GsUd6BmgUUXIudYpB2bQPfYAi-s/edit\">Slides about A-Frame animations.</a></li>\n<li><a href=\"http://codepen.io/rabimba/\">CodePen examples.</a></li>\n</ul>\n<p><img src=\"/content/images/2016/05/IMG_20160314_135219.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/IMG_20160315_112900.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/IMG_20160315_111705.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/IMG_20160314_123708.jpg\" alt=\"\"></p>\n<p><img src=\"/content/images/2016/05/PANO_20160314_123750.jpg\" alt=\"\"></p>\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/0YIk_WD8Ox8?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/-1CIviLNU3w?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/F2-561renpg?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n"},{"title":"A-Painter: Paint in VR in Your Browser","id":"17","updated":"2016-09-24T02:49:14.000Z","date":"2016-09-19T22:04:23.000Z","_content":"\n<p class=\"intro\">\n  Want to start painting now? Head to <a href=\"https://aframe.io/a-painter\"><strong>https://aframe.io/a-painter</strong></a>!\n  <small class=\"subintro\">Make sure you have a <a href=\"https://webvr.info/get-chrome/\">WebVR-enabled browser</a>. In Chromium, enable the flags for <code>chrome://flags/#enable-webvr</code> and <code>chrome://flags/#enable-gamepad-extensions</code>). <a href=\"https://blog.mozvr.com/experimental-htc-vive-support-in-firefox-nightly/\">Firefox support</a> is coming soon.</small>\n  <small class=\"subintro\">(Dont have a headset? No problem &ndash; you can still <a href=\"https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/\">view paintings from any device</a>!)</small>\n</p>\n\n![Looped recording of drawing in A-Painter](/content/images/2016/09/apainter_painting.gif \"Looped recording of drawing in A-Painter\")\n\nWe on the [Mozilla VR](https://mozvr.com/) team are hardcore fans of [Tilt Brush](https://www.tiltbrush.com/). Its a wonderful example of the power of VR as an expressive medium. In the last few weeks, we have been experimenting with our own Web-based interpretation of Tilt Brush. We wanted to show how easy is to produce and share your creations on the Web across platforms with no software installations.\n\n![Screenshot of Mozilla VR fox in A-Painter](/content/images/2016/09/foxlogo-1.png \"Screenshot of Mozilla VR fox in A-Painter\")\n\nTo browse paintings, you just need a browser with WebGL, but to fulfill your artistic urges you need a system with hand-tracked controllers. Today, that means only with the HTC Vive on Windows (though we hope this changes soon!).\n\n## What can I do with A-Painter today?\n- Paint in 3D using hand-tracked motion controllers. Use both hands to paint!\n- Share drawings with the world simply by copying and pasting a URL.\n- View 3D drawings anywhere both with and without a headset.\n- Paint on top of other peoples drawings and make them your own.\n- Drag and drop images and [`OBJ` models](https://aframe.io/docs/0.3.0/introduction/faq.html#where-can-i-find-assets) from your desktop to the browser, for a template or starting point to paint over.\n- Save and load local binary files of your drawings.\n- Over 30 brushes with a custom [A-Painter Brush API](https://github.com/aframevr/a-painter#brush-api) to easily create new ones.\n\n## How to play with it\t\nIts easy! Go to the [**A-Painter web site**](https://aframe.io/a-painter) with a [WebVR-enabled browser](https://webvr.info/get-chrome) (with Gamepad Extensions enabled in `about:config`) and put on your HTC Vive headset. Grab your controllers, hold the trigger button, and start painting!\n\nIf you don't have a headset, you can still [view other people's creations](https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/) using mouse and keyboard or mobile. \n\n### Controls\n\n![Diagram of A-Painter controls](/content/images/2016/09/controller_tooltips_medium.jpg \"Diagram of A-Painter controls\")\n\n- **Trigger**: Hold down to paint (its pressure sensitive).\n- **Thumbpad**: Slide up and down to change the brush size.\n- **Grip**: Squeeze to undo the latest stroke.\n- **Menu Button**: Press to toggle the main menu.\n\nOnce you open the main menu, you can modify the color, size, and brush type by pointing the other controller to the desired option and clicking using the trigger (and the controller being used to point and click is the one is the one that receives the new settings).\n\n![Diagram of A-Painter menu options](/content/images/2016/09/menu.jpg \"Diagram of A-Painter menu options\")\n\n- **Color history**: The latest seven colors used will be saved in these swatches.\n- **Clear**: Clears the painting. Use with care!\n- **Save**: The whole painting will be saved and uploaded to a server in a binary format, and outside of VR (but still in your browser) you will get a URL that you can use to share your painting and resume your work later.\n- **Copy**: The current brush settings (type, color, and size) of the controller holding the menu will be transferred to the pointing controller.\n\n![Looped recording of changing brush options in A-Painter menu](/content/images/2016/09/apainter_menuc.gif \"Looped recording of changing brush options in A-Painter menu\")\n\n## A-Painter is extensible\nTo create a new brush, implement the following interface, and register it by calling `AFRAME.registerBrush(brushName, definition, options)`.\n\nAnd, from within your `AFRAME.registerBrush` call, define the following:\n\n```javascript\nBrushInterface.prototype = {\n  addPoint: function (position, orientation, pointerPosition, pressure, timestamp) {},\n  tick: function (timeOffset, delta) {}\n};\n```\n\nThe only required method to implement is **addPoint**. With **addPoint**, you should do something with the point, orientation, and pressure data returned from the controller (i.e., create or modify a geometry), and return *true* if youve added something to the scene and `false` otherwise. If you want to add dynamic behavior, implement the **tick** method, which will be called on every frame.\n\nHere is the code for a custom `spheres` brush:\n\n```javascript\n/* globals AFRAME, THREE */\nAFRAME.registerBrush(\n  // Name of brush.\n  'spheres',\n\n  // Methods for brush definition.\n  {\n    init: function (color, width) {\n      // Initialize the material based on the stroke color.\n      this.material = new THREE.MeshStandardMaterial({\n        color: this.data.color,\n        roughness: 0.5,\n        metalness: 0.5,\n        side: THREE.DoubleSide,\n        shading: THREE.FlatShading\n      });\n      this.geometry = new THREE.IcosahedronGeometry(1, 0);\n    },\n\n    // This method is called every time we need to add a point\n    // to our stroke. It should return `true` if the point is\n    // added correctly and `false` otherwise.\n    addPoint: function (position, orientation, pointerPosition,\n                        pressure, timestamp) {\n      // Create a new sphere mesh to insert at the given position.\n      var sphere = new THREE.Mesh(this.geometry, this.material);\n\n      // The scale is determined by the trigger pressure.\n      var scale = this.data.size / 2 * pressure;\n      sphere.scale.set(scale, scale, scale);\n      sphere.initialScale = sphere.scale.clone();\n\n      // Generate a random phase to be used in the tick animation.\n      sphere.phase = Math.random() * Math.PI * 2;\n\n      // Set the position and orientation of the sphere to match\n      // the controllers.\n      sphere.position.copy(pointerPosition);\n      sphere.rotation.copy(orientation);\n\n      // Add the sphere to the `object3D`.\n      this.object3D.add(sphere);\n\n      // Return `true`, since weve correctly added a new point (sphere).\n      return true;\n    },\n\n    // This method is called on every frame.\n    tick: function (timeOffset, delta) {\n      for (var i = 0; i < this.object3D.children.length; i++) {\n        var sphere = this.object3D.children[i];\n        // Calculate the sine value based on the time and the phase for\n        // this sphere, and use it to scale the geometry.\n        var sin = (Math.sin(sphere.phase + timeOffset / 500.0) + 1) / 2 + 0.1;\n        sphere.scale.copy(sphere.initialScale).multiplyScalar(sin);\n      }\n    },\n  },\n\n  // Additional options for this brush.\n  {\n    thumbnail: 'brushes/thumb_spheres.gif',\n    spacing: 0.01\n  }\n);\n```\n\n![Looped recording of walking around in a painting with the custom `spheres` brush in A-Painter](/content/images/2016/09/spheres-brush.gif)\n\n[**Read more about creating custom brushes.**](https://github.com/aframevr/a-painter#brush-api)\n\n## Perhaps we could\nWhile developing this tool, we got plenty of interesting ideas to implement. The future of A-Painter depends on you and its general acceptance and feedback, but here are some ideas of features we would like to add:\n\n- More and better tools, such as a color picker and eraser\n- More and better brushes\n- Save screenshots and `GIF` animations\n- Audio-reactive brushes\n- Multi-user painters and spectators\n- Import [`glTF`](https://github.com/KhronosGroup/glTF) models\n- Export to standard 3D file formats, such as `OBJ` and `glTF`\n- Dedicated web site with gallery of users' submissions\n- Post-processing filters\n- Performance optimizations to existing brushes\n\nAnd, of course if you have an idea, issue, or want to contribute directly to the codebase, please feel free to join us at **https://github.com/aframevr/a-painter**.\n","source":"_posts/A-Painter-Paint-in-VR-in-Your-Browser.md","raw":"---\ntitle: 'A-Painter: Paint in VR in Your Browser'\ntags: A-Frame\npermalink: a-painter\nid: 17\nupdated: '2016-09-23 19:49:14'\ndate: 2016-09-19 15:04:23\n---\n\n<p class=\"intro\">\n  Want to start painting now? Head to <a href=\"https://aframe.io/a-painter\"><strong>https://aframe.io/a-painter</strong></a>!\n  <small class=\"subintro\">Make sure you have a <a href=\"https://webvr.info/get-chrome/\">WebVR-enabled browser</a>. In Chromium, enable the flags for <code>chrome://flags/#enable-webvr</code> and <code>chrome://flags/#enable-gamepad-extensions</code>). <a href=\"https://blog.mozvr.com/experimental-htc-vive-support-in-firefox-nightly/\">Firefox support</a> is coming soon.</small>\n  <small class=\"subintro\">(Dont have a headset? No problem &ndash; you can still <a href=\"https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/\">view paintings from any device</a>!)</small>\n</p>\n\n![Looped recording of drawing in A-Painter](/content/images/2016/09/apainter_painting.gif \"Looped recording of drawing in A-Painter\")\n\nWe on the [Mozilla VR](https://mozvr.com/) team are hardcore fans of [Tilt Brush](https://www.tiltbrush.com/). Its a wonderful example of the power of VR as an expressive medium. In the last few weeks, we have been experimenting with our own Web-based interpretation of Tilt Brush. We wanted to show how easy is to produce and share your creations on the Web across platforms with no software installations.\n\n![Screenshot of Mozilla VR fox in A-Painter](/content/images/2016/09/foxlogo-1.png \"Screenshot of Mozilla VR fox in A-Painter\")\n\nTo browse paintings, you just need a browser with WebGL, but to fulfill your artistic urges you need a system with hand-tracked controllers. Today, that means only with the HTC Vive on Windows (though we hope this changes soon!).\n\n## What can I do with A-Painter today?\n- Paint in 3D using hand-tracked motion controllers. Use both hands to paint!\n- Share drawings with the world simply by copying and pasting a URL.\n- View 3D drawings anywhere both with and without a headset.\n- Paint on top of other peoples drawings and make them your own.\n- Drag and drop images and [`OBJ` models](https://aframe.io/docs/0.3.0/introduction/faq.html#where-can-i-find-assets) from your desktop to the browser, for a template or starting point to paint over.\n- Save and load local binary files of your drawings.\n- Over 30 brushes with a custom [A-Painter Brush API](https://github.com/aframevr/a-painter#brush-api) to easily create new ones.\n\n## How to play with it\t\nIts easy! Go to the [**A-Painter web site**](https://aframe.io/a-painter) with a [WebVR-enabled browser](https://webvr.info/get-chrome) (with Gamepad Extensions enabled in `about:config`) and put on your HTC Vive headset. Grab your controllers, hold the trigger button, and start painting!\n\nIf you don't have a headset, you can still [view other people's creations](https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/) using mouse and keyboard or mobile. \n\n### Controls\n\n![Diagram of A-Painter controls](/content/images/2016/09/controller_tooltips_medium.jpg \"Diagram of A-Painter controls\")\n\n- **Trigger**: Hold down to paint (its pressure sensitive).\n- **Thumbpad**: Slide up and down to change the brush size.\n- **Grip**: Squeeze to undo the latest stroke.\n- **Menu Button**: Press to toggle the main menu.\n\nOnce you open the main menu, you can modify the color, size, and brush type by pointing the other controller to the desired option and clicking using the trigger (and the controller being used to point and click is the one is the one that receives the new settings).\n\n![Diagram of A-Painter menu options](/content/images/2016/09/menu.jpg \"Diagram of A-Painter menu options\")\n\n- **Color history**: The latest seven colors used will be saved in these swatches.\n- **Clear**: Clears the painting. Use with care!\n- **Save**: The whole painting will be saved and uploaded to a server in a binary format, and outside of VR (but still in your browser) you will get a URL that you can use to share your painting and resume your work later.\n- **Copy**: The current brush settings (type, color, and size) of the controller holding the menu will be transferred to the pointing controller.\n\n![Looped recording of changing brush options in A-Painter menu](/content/images/2016/09/apainter_menuc.gif \"Looped recording of changing brush options in A-Painter menu\")\n\n## A-Painter is extensible\nTo create a new brush, implement the following interface, and register it by calling `AFRAME.registerBrush(brushName, definition, options)`.\n\nAnd, from within your `AFRAME.registerBrush` call, define the following:\n\n```javascript\nBrushInterface.prototype = {\n  addPoint: function (position, orientation, pointerPosition, pressure, timestamp) {},\n  tick: function (timeOffset, delta) {}\n};\n```\n\nThe only required method to implement is **addPoint**. With **addPoint**, you should do something with the point, orientation, and pressure data returned from the controller (i.e., create or modify a geometry), and return *true* if youve added something to the scene and `false` otherwise. If you want to add dynamic behavior, implement the **tick** method, which will be called on every frame.\n\nHere is the code for a custom `spheres` brush:\n\n```javascript\n/* globals AFRAME, THREE */\nAFRAME.registerBrush(\n  // Name of brush.\n  'spheres',\n\n  // Methods for brush definition.\n  {\n    init: function (color, width) {\n      // Initialize the material based on the stroke color.\n      this.material = new THREE.MeshStandardMaterial({\n        color: this.data.color,\n        roughness: 0.5,\n        metalness: 0.5,\n        side: THREE.DoubleSide,\n        shading: THREE.FlatShading\n      });\n      this.geometry = new THREE.IcosahedronGeometry(1, 0);\n    },\n\n    // This method is called every time we need to add a point\n    // to our stroke. It should return `true` if the point is\n    // added correctly and `false` otherwise.\n    addPoint: function (position, orientation, pointerPosition,\n                        pressure, timestamp) {\n      // Create a new sphere mesh to insert at the given position.\n      var sphere = new THREE.Mesh(this.geometry, this.material);\n\n      // The scale is determined by the trigger pressure.\n      var scale = this.data.size / 2 * pressure;\n      sphere.scale.set(scale, scale, scale);\n      sphere.initialScale = sphere.scale.clone();\n\n      // Generate a random phase to be used in the tick animation.\n      sphere.phase = Math.random() * Math.PI * 2;\n\n      // Set the position and orientation of the sphere to match\n      // the controllers.\n      sphere.position.copy(pointerPosition);\n      sphere.rotation.copy(orientation);\n\n      // Add the sphere to the `object3D`.\n      this.object3D.add(sphere);\n\n      // Return `true`, since weve correctly added a new point (sphere).\n      return true;\n    },\n\n    // This method is called on every frame.\n    tick: function (timeOffset, delta) {\n      for (var i = 0; i < this.object3D.children.length; i++) {\n        var sphere = this.object3D.children[i];\n        // Calculate the sine value based on the time and the phase for\n        // this sphere, and use it to scale the geometry.\n        var sin = (Math.sin(sphere.phase + timeOffset / 500.0) + 1) / 2 + 0.1;\n        sphere.scale.copy(sphere.initialScale).multiplyScalar(sin);\n      }\n    },\n  },\n\n  // Additional options for this brush.\n  {\n    thumbnail: 'brushes/thumb_spheres.gif',\n    spacing: 0.01\n  }\n);\n```\n\n![Looped recording of walking around in a painting with the custom `spheres` brush in A-Painter](/content/images/2016/09/spheres-brush.gif)\n\n[**Read more about creating custom brushes.**](https://github.com/aframevr/a-painter#brush-api)\n\n## Perhaps we could\nWhile developing this tool, we got plenty of interesting ideas to implement. The future of A-Painter depends on you and its general acceptance and feedback, but here are some ideas of features we would like to add:\n\n- More and better tools, such as a color picker and eraser\n- More and better brushes\n- Save screenshots and `GIF` animations\n- Audio-reactive brushes\n- Multi-user painters and spectators\n- Import [`glTF`](https://github.com/KhronosGroup/glTF) models\n- Export to standard 3D file formats, such as `OBJ` and `glTF`\n- Dedicated web site with gallery of users' submissions\n- Post-processing filters\n- Performance optimizations to existing brushes\n\nAnd, of course if you have an idea, issue, or want to contribute directly to the codebase, please feel free to join us at **https://github.com/aframevr/a-painter**.\n","slug":"a-painter","published":1,"_id":"citot8hyw000gik1jp788bfw9","comments":1,"layout":"post","photos":[],"link":"","content":"<p class=\"intro\"><br>  Want to start painting now? Head to <a href=\"https://aframe.io/a-painter\" target=\"_blank\" rel=\"external\"><strong>https://aframe.io/a-painter</strong></a>!<br>  <small class=\"subintro\">Make sure you have a <a href=\"https://webvr.info/get-chrome/\" target=\"_blank\" rel=\"external\">WebVR-enabled browser</a>. In Chromium, enable the flags for <code>chrome://flags/#enable-webvr</code> and <code>chrome://flags/#enable-gamepad-extensions</code>). <a href=\"https://blog.mozvr.com/experimental-htc-vive-support-in-firefox-nightly/\" target=\"_blank\" rel=\"external\">Firefox support</a> is coming soon.</small><br>  <small class=\"subintro\">(Dont have a headset? No problem &ndash; you can still <a href=\"https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/\" target=\"_blank\" rel=\"external\">view paintings from any device</a>!)</small><br></p>\n\n<p><img src=\"/content/images/2016/09/apainter_painting.gif\" alt=\"Looped recording of drawing in A-Painter\" title=\"Looped recording of drawing in A-Painter\"></p>\n<p>We on the <a href=\"https://mozvr.com/\" target=\"_blank\" rel=\"external\">Mozilla VR</a> team are hardcore fans of <a href=\"https://www.tiltbrush.com/\" target=\"_blank\" rel=\"external\">Tilt Brush</a>. Its a wonderful example of the power of VR as an expressive medium. In the last few weeks, we have been experimenting with our own Web-based interpretation of Tilt Brush. We wanted to show how easy is to produce and share your creations on the Web across platforms with no software installations.</p>\n<p><img src=\"/content/images/2016/09/foxlogo-1.png\" alt=\"Screenshot of Mozilla VR fox in A-Painter\" title=\"Screenshot of Mozilla VR fox in A-Painter\"></p>\n<p>To browse paintings, you just need a browser with WebGL, but to fulfill your artistic urges you need a system with hand-tracked controllers. Today, that means only with the HTC Vive on Windows (though we hope this changes soon!).</p>\n<h2 id=\"What-can-I-do-with-A-Painter-today\"><a href=\"#What-can-I-do-with-A-Painter-today\" class=\"headerlink\" title=\"What can I do with A-Painter today?\"></a>What can I do with A-Painter today?</h2><ul>\n<li>Paint in 3D using hand-tracked motion controllers. Use both hands to paint!</li>\n<li>Share drawings with the world simply by copying and pasting a URL.</li>\n<li>View 3D drawings anywhere both with and without a headset.</li>\n<li>Paint on top of other peoples drawings and make them your own.</li>\n<li>Drag and drop images and <a href=\"https://aframe.io/docs/0.3.0/introduction/faq.html#where-can-i-find-assets\" target=\"_blank\" rel=\"external\"><code>OBJ</code> models</a> from your desktop to the browser, for a template or starting point to paint over.</li>\n<li>Save and load local binary files of your drawings.</li>\n<li>Over 30 brushes with a custom <a href=\"https://github.com/aframevr/a-painter#brush-api\" target=\"_blank\" rel=\"external\">A-Painter Brush API</a> to easily create new ones.</li>\n</ul>\n<h2 id=\"How-to-play-with-it\"><a href=\"#How-to-play-with-it\" class=\"headerlink\" title=\"How to play with it\"></a>How to play with it</h2><p>Its easy! Go to the <a href=\"https://aframe.io/a-painter\" target=\"_blank\" rel=\"external\"><strong>A-Painter web site</strong></a> with a <a href=\"https://webvr.info/get-chrome\" target=\"_blank\" rel=\"external\">WebVR-enabled browser</a> (with Gamepad Extensions enabled in <code>about:config</code>) and put on your HTC Vive headset. Grab your controllers, hold the trigger button, and start painting!</p>\n<p>If you dont have a headset, you can still <a href=\"https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/\" target=\"_blank\" rel=\"external\">view other peoples creations</a> using mouse and keyboard or mobile. </p>\n<h3 id=\"Controls\"><a href=\"#Controls\" class=\"headerlink\" title=\"Controls\"></a>Controls</h3><p><img src=\"/content/images/2016/09/controller_tooltips_medium.jpg\" alt=\"Diagram of A-Painter controls\" title=\"Diagram of A-Painter controls\"></p>\n<ul>\n<li><strong>Trigger</strong>: Hold down to paint (its pressure sensitive).</li>\n<li><strong>Thumbpad</strong>: Slide up and down to change the brush size.</li>\n<li><strong>Grip</strong>: Squeeze to undo the latest stroke.</li>\n<li><strong>Menu Button</strong>: Press to toggle the main menu.</li>\n</ul>\n<p>Once you open the main menu, you can modify the color, size, and brush type by pointing the other controller to the desired option and clicking using the trigger (and the controller being used to point and click is the one is the one that receives the new settings).</p>\n<p><img src=\"/content/images/2016/09/menu.jpg\" alt=\"Diagram of A-Painter menu options\" title=\"Diagram of A-Painter menu options\"></p>\n<ul>\n<li><strong>Color history</strong>: The latest seven colors used will be saved in these swatches.</li>\n<li><strong>Clear</strong>: Clears the painting. Use with care!</li>\n<li><strong>Save</strong>: The whole painting will be saved and uploaded to a server in a binary format, and outside of VR (but still in your browser) you will get a URL that you can use to share your painting and resume your work later.</li>\n<li><strong>Copy</strong>: The current brush settings (type, color, and size) of the controller holding the menu will be transferred to the pointing controller.</li>\n</ul>\n<p><img src=\"/content/images/2016/09/apainter_menuc.gif\" alt=\"Looped recording of changing brush options in A-Painter menu\" title=\"Looped recording of changing brush options in A-Painter menu\"></p>\n<h2 id=\"A-Painter-is-extensible\"><a href=\"#A-Painter-is-extensible\" class=\"headerlink\" title=\"A-Painter is extensible\"></a>A-Painter is extensible</h2><p>To create a new brush, implement the following interface, and register it by calling <code>AFRAME.registerBrush(brushName, definition, options)</code>.</p>\n<p>And, from within your <code>AFRAME.registerBrush</code> call, define the following:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">BrushInterface.prototype = &#123;</div><div class=\"line\">  <span class=\"attr\">addPoint</span>: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">position, orientation, pointerPosition, pressure, timestamp</span>) </span>&#123;&#125;,</div><div class=\"line\">  <span class=\"attr\">tick</span>: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">timeOffset, delta</span>) </span>&#123;&#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>The only required method to implement is <strong>addPoint</strong>. With <strong>addPoint</strong>, you should do something with the point, orientation, and pressure data returned from the controller (i.e., create or modify a geometry), and return <em>true</em> if youve added something to the scene and <code>false</code> otherwise. If you want to add dynamic behavior, implement the <strong>tick</strong> method, which will be called on every frame.</p>\n<p>Here is the code for a custom <code>spheres</code> brush:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* globals AFRAME, THREE */</span></div><div class=\"line\">AFRAME.registerBrush(</div><div class=\"line\">  <span class=\"comment\">// Name of brush.</span></div><div class=\"line\">  <span class=\"string\">'spheres'</span>,</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// Methods for brush definition.</span></div><div class=\"line\">  &#123;</div><div class=\"line\">    <span class=\"attr\">init</span>: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">color, width</span>) </span>&#123;</div><div class=\"line\">      <span class=\"comment\">// Initialize the material based on the stroke color.</span></div><div class=\"line\">      <span class=\"keyword\">this</span>.material = <span class=\"keyword\">new</span> THREE.MeshStandardMaterial(&#123;</div><div class=\"line\">        <span class=\"attr\">color</span>: <span class=\"keyword\">this</span>.data.color,</div><div class=\"line\">        <span class=\"attr\">roughness</span>: <span class=\"number\">0.5</span>,</div><div class=\"line\">        <span class=\"attr\">metalness</span>: <span class=\"number\">0.5</span>,</div><div class=\"line\">        <span class=\"attr\">side</span>: THREE.DoubleSide,</div><div class=\"line\">        <span class=\"attr\">shading</span>: THREE.FlatShading</div><div class=\"line\">      &#125;);</div><div class=\"line\">      <span class=\"keyword\">this</span>.geometry = <span class=\"keyword\">new</span> THREE.IcosahedronGeometry(<span class=\"number\">1</span>, <span class=\"number\">0</span>);</div><div class=\"line\">    &#125;,</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// This method is called every time we need to add a point</span></div><div class=\"line\">    <span class=\"comment\">// to our stroke. It should return `true` if the point is</span></div><div class=\"line\">    <span class=\"comment\">// added correctly and `false` otherwise.</span></div><div class=\"line\">    addPoint: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">position, orientation, pointerPosition,</span></span></div><div class=\"line\">                        pressure, timestamp) &#123;</div><div class=\"line\">      <span class=\"comment\">// Create a new sphere mesh to insert at the given position.</span></div><div class=\"line\">      <span class=\"keyword\">var</span> sphere = <span class=\"keyword\">new</span> THREE.Mesh(<span class=\"keyword\">this</span>.geometry, <span class=\"keyword\">this</span>.material);</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// The scale is determined by the trigger pressure.</span></div><div class=\"line\">      <span class=\"keyword\">var</span> scale = <span class=\"keyword\">this</span>.data.size / <span class=\"number\">2</span> * pressure;</div><div class=\"line\">      sphere.scale.set(scale, scale, scale);</div><div class=\"line\">      sphere.initialScale = sphere.scale.clone();</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Generate a random phase to be used in the tick animation.</span></div><div class=\"line\">      sphere.phase = <span class=\"built_in\">Math</span>.random() * <span class=\"built_in\">Math</span>.PI * <span class=\"number\">2</span>;</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Set the position and orientation of the sphere to match</span></div><div class=\"line\">      <span class=\"comment\">// the controllers.</span></div><div class=\"line\">      sphere.position.copy(pointerPosition);</div><div class=\"line\">      sphere.rotation.copy(orientation);</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Add the sphere to the `object3D`.</span></div><div class=\"line\">      <span class=\"keyword\">this</span>.object3D.add(sphere);</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Return `true`, since weve correctly added a new point (sphere).</span></div><div class=\"line\">      <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;,</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// This method is called on every frame.</span></div><div class=\"line\">    tick: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">timeOffset, delta</span>) </span>&#123;</div><div class=\"line\">      <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>.object3D.children.length; i++) &#123;</div><div class=\"line\">        <span class=\"keyword\">var</span> sphere = <span class=\"keyword\">this</span>.object3D.children[i];</div><div class=\"line\">        <span class=\"comment\">// Calculate the sine value based on the time and the phase for</span></div><div class=\"line\">        <span class=\"comment\">// this sphere, and use it to scale the geometry.</span></div><div class=\"line\">        <span class=\"keyword\">var</span> sin = (<span class=\"built_in\">Math</span>.sin(sphere.phase + timeOffset / <span class=\"number\">500.0</span>) + <span class=\"number\">1</span>) / <span class=\"number\">2</span> + <span class=\"number\">0.1</span>;</div><div class=\"line\">        sphere.scale.copy(sphere.initialScale).multiplyScalar(sin);</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">  &#125;,</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// Additional options for this brush.</span></div><div class=\"line\">  &#123;</div><div class=\"line\">    <span class=\"attr\">thumbnail</span>: <span class=\"string\">'brushes/thumb_spheres.gif'</span>,</div><div class=\"line\">    <span class=\"attr\">spacing</span>: <span class=\"number\">0.01</span></div><div class=\"line\">  &#125;</div><div class=\"line\">);</div></pre></td></tr></table></figure>\n<p><img src=\"/content/images/2016/09/spheres-brush.gif\" alt=\"Looped recording of walking around in a painting with the custom `spheres` brush in A-Painter\"></p>\n<p><a href=\"https://github.com/aframevr/a-painter#brush-api\" target=\"_blank\" rel=\"external\"><strong>Read more about creating custom brushes.</strong></a></p>\n<h2 id=\"Perhaps-we-could\"><a href=\"#Perhaps-we-could\" class=\"headerlink\" title=\"Perhaps we could\"></a>Perhaps we could</h2><p>While developing this tool, we got plenty of interesting ideas to implement. The future of A-Painter depends on you and its general acceptance and feedback, but here are some ideas of features we would like to add:</p>\n<ul>\n<li>More and better tools, such as a color picker and eraser</li>\n<li>More and better brushes</li>\n<li>Save screenshots and <code>GIF</code> animations</li>\n<li>Audio-reactive brushes</li>\n<li>Multi-user painters and spectators</li>\n<li>Import <a href=\"https://github.com/KhronosGroup/glTF\" target=\"_blank\" rel=\"external\"><code>glTF</code></a> models</li>\n<li>Export to standard 3D file formats, such as <code>OBJ</code> and <code>glTF</code></li>\n<li>Dedicated web site with gallery of users submissions</li>\n<li>Post-processing filters</li>\n<li>Performance optimizations to existing brushes</li>\n</ul>\n<p>And, of course if you have an idea, issue, or want to contribute directly to the codebase, please feel free to join us at <strong><a href=\"https://github.com/aframevr/a-painter\" target=\"_blank\" rel=\"external\">https://github.com/aframevr/a-painter</a></strong>.</p>\n","excerpt":"","more":"<p class=\"intro\"><br>  Want to start painting now? Head to <a href=\"https://aframe.io/a-painter\"><strong>https://aframe.io/a-painter</strong></a>!<br>  <small class=\"subintro\">Make sure you have a <a href=\"https://webvr.info/get-chrome/\">WebVR-enabled browser</a>. In Chromium, enable the flags for <code>chrome://flags/#enable-webvr</code> and <code>chrome://flags/#enable-gamepad-extensions</code>). <a href=\"https://blog.mozvr.com/experimental-htc-vive-support-in-firefox-nightly/\">Firefox support</a> is coming soon.</small><br>  <small class=\"subintro\">(Dont have a headset? No problem &ndash; you can still <a href=\"https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/\">view paintings from any device</a>!)</small><br></p>\n\n<p><img src=\"/content/images/2016/09/apainter_painting.gif\" alt=\"Looped recording of drawing in A-Painter\" title=\"Looped recording of drawing in A-Painter\"></p>\n<p>We on the <a href=\"https://mozvr.com/\">Mozilla VR</a> team are hardcore fans of <a href=\"https://www.tiltbrush.com/\">Tilt Brush</a>. Its a wonderful example of the power of VR as an expressive medium. In the last few weeks, we have been experimenting with our own Web-based interpretation of Tilt Brush. We wanted to show how easy is to produce and share your creations on the Web across platforms with no software installations.</p>\n<p><img src=\"/content/images/2016/09/foxlogo-1.png\" alt=\"Screenshot of Mozilla VR fox in A-Painter\" title=\"Screenshot of Mozilla VR fox in A-Painter\"></p>\n<p>To browse paintings, you just need a browser with WebGL, but to fulfill your artistic urges you need a system with hand-tracked controllers. Today, that means only with the HTC Vive on Windows (though we hope this changes soon!).</p>\n<h2 id=\"What-can-I-do-with-A-Painter-today\"><a href=\"#What-can-I-do-with-A-Painter-today\" class=\"headerlink\" title=\"What can I do with A-Painter today?\"></a>What can I do with A-Painter today?</h2><ul>\n<li>Paint in 3D using hand-tracked motion controllers. Use both hands to paint!</li>\n<li>Share drawings with the world simply by copying and pasting a URL.</li>\n<li>View 3D drawings anywhere both with and without a headset.</li>\n<li>Paint on top of other peoples drawings and make them your own.</li>\n<li>Drag and drop images and <a href=\"https://aframe.io/docs/0.3.0/introduction/faq.html#where-can-i-find-assets\"><code>OBJ</code> models</a> from your desktop to the browser, for a template or starting point to paint over.</li>\n<li>Save and load local binary files of your drawings.</li>\n<li>Over 30 brushes with a custom <a href=\"https://github.com/aframevr/a-painter#brush-api\">A-Painter Brush API</a> to easily create new ones.</li>\n</ul>\n<h2 id=\"How-to-play-with-it\"><a href=\"#How-to-play-with-it\" class=\"headerlink\" title=\"How to play with it\"></a>How to play with it</h2><p>Its easy! Go to the <a href=\"https://aframe.io/a-painter\"><strong>A-Painter web site</strong></a> with a <a href=\"https://webvr.info/get-chrome\">WebVR-enabled browser</a> (with Gamepad Extensions enabled in <code>about:config</code>) and put on your HTC Vive headset. Grab your controllers, hold the trigger button, and start painting!</p>\n<p>If you dont have a headset, you can still <a href=\"https://aframe.io/a-painter/?url=https://ucarecdn.com/3e089e07-be62-48e1-9f12-9a284c249e77/\">view other peoples creations</a> using mouse and keyboard or mobile. </p>\n<h3 id=\"Controls\"><a href=\"#Controls\" class=\"headerlink\" title=\"Controls\"></a>Controls</h3><p><img src=\"/content/images/2016/09/controller_tooltips_medium.jpg\" alt=\"Diagram of A-Painter controls\" title=\"Diagram of A-Painter controls\"></p>\n<ul>\n<li><strong>Trigger</strong>: Hold down to paint (its pressure sensitive).</li>\n<li><strong>Thumbpad</strong>: Slide up and down to change the brush size.</li>\n<li><strong>Grip</strong>: Squeeze to undo the latest stroke.</li>\n<li><strong>Menu Button</strong>: Press to toggle the main menu.</li>\n</ul>\n<p>Once you open the main menu, you can modify the color, size, and brush type by pointing the other controller to the desired option and clicking using the trigger (and the controller being used to point and click is the one is the one that receives the new settings).</p>\n<p><img src=\"/content/images/2016/09/menu.jpg\" alt=\"Diagram of A-Painter menu options\" title=\"Diagram of A-Painter menu options\"></p>\n<ul>\n<li><strong>Color history</strong>: The latest seven colors used will be saved in these swatches.</li>\n<li><strong>Clear</strong>: Clears the painting. Use with care!</li>\n<li><strong>Save</strong>: The whole painting will be saved and uploaded to a server in a binary format, and outside of VR (but still in your browser) you will get a URL that you can use to share your painting and resume your work later.</li>\n<li><strong>Copy</strong>: The current brush settings (type, color, and size) of the controller holding the menu will be transferred to the pointing controller.</li>\n</ul>\n<p><img src=\"/content/images/2016/09/apainter_menuc.gif\" alt=\"Looped recording of changing brush options in A-Painter menu\" title=\"Looped recording of changing brush options in A-Painter menu\"></p>\n<h2 id=\"A-Painter-is-extensible\"><a href=\"#A-Painter-is-extensible\" class=\"headerlink\" title=\"A-Painter is extensible\"></a>A-Painter is extensible</h2><p>To create a new brush, implement the following interface, and register it by calling <code>AFRAME.registerBrush(brushName, definition, options)</code>.</p>\n<p>And, from within your <code>AFRAME.registerBrush</code> call, define the following:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">BrushInterface.prototype = &#123;</div><div class=\"line\">  <span class=\"attr\">addPoint</span>: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">position, orientation, pointerPosition, pressure, timestamp</span>) </span>&#123;&#125;,</div><div class=\"line\">  <span class=\"attr\">tick</span>: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">timeOffset, delta</span>) </span>&#123;&#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>The only required method to implement is <strong>addPoint</strong>. With <strong>addPoint</strong>, you should do something with the point, orientation, and pressure data returned from the controller (i.e., create or modify a geometry), and return <em>true</em> if youve added something to the scene and <code>false</code> otherwise. If you want to add dynamic behavior, implement the <strong>tick</strong> method, which will be called on every frame.</p>\n<p>Here is the code for a custom <code>spheres</code> brush:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/* globals AFRAME, THREE */</span></div><div class=\"line\">AFRAME.registerBrush(</div><div class=\"line\">  <span class=\"comment\">// Name of brush.</span></div><div class=\"line\">  <span class=\"string\">'spheres'</span>,</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// Methods for brush definition.</span></div><div class=\"line\">  &#123;</div><div class=\"line\">    <span class=\"attr\">init</span>: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">color, width</span>) </span>&#123;</div><div class=\"line\">      <span class=\"comment\">// Initialize the material based on the stroke color.</span></div><div class=\"line\">      <span class=\"keyword\">this</span>.material = <span class=\"keyword\">new</span> THREE.MeshStandardMaterial(&#123;</div><div class=\"line\">        <span class=\"attr\">color</span>: <span class=\"keyword\">this</span>.data.color,</div><div class=\"line\">        <span class=\"attr\">roughness</span>: <span class=\"number\">0.5</span>,</div><div class=\"line\">        <span class=\"attr\">metalness</span>: <span class=\"number\">0.5</span>,</div><div class=\"line\">        <span class=\"attr\">side</span>: THREE.DoubleSide,</div><div class=\"line\">        <span class=\"attr\">shading</span>: THREE.FlatShading</div><div class=\"line\">      &#125;);</div><div class=\"line\">      <span class=\"keyword\">this</span>.geometry = <span class=\"keyword\">new</span> THREE.IcosahedronGeometry(<span class=\"number\">1</span>, <span class=\"number\">0</span>);</div><div class=\"line\">    &#125;,</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// This method is called every time we need to add a point</span></div><div class=\"line\">    <span class=\"comment\">// to our stroke. It should return `true` if the point is</span></div><div class=\"line\">    <span class=\"comment\">// added correctly and `false` otherwise.</span></div><div class=\"line\">    addPoint: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">position, orientation, pointerPosition,</div><div class=\"line\">                        pressure, timestamp</span>) </span>&#123;</div><div class=\"line\">      <span class=\"comment\">// Create a new sphere mesh to insert at the given position.</span></div><div class=\"line\">      <span class=\"keyword\">var</span> sphere = <span class=\"keyword\">new</span> THREE.Mesh(<span class=\"keyword\">this</span>.geometry, <span class=\"keyword\">this</span>.material);</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// The scale is determined by the trigger pressure.</span></div><div class=\"line\">      <span class=\"keyword\">var</span> scale = <span class=\"keyword\">this</span>.data.size / <span class=\"number\">2</span> * pressure;</div><div class=\"line\">      sphere.scale.set(scale, scale, scale);</div><div class=\"line\">      sphere.initialScale = sphere.scale.clone();</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Generate a random phase to be used in the tick animation.</span></div><div class=\"line\">      sphere.phase = <span class=\"built_in\">Math</span>.random() * <span class=\"built_in\">Math</span>.PI * <span class=\"number\">2</span>;</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Set the position and orientation of the sphere to match</span></div><div class=\"line\">      <span class=\"comment\">// the controllers.</span></div><div class=\"line\">      sphere.position.copy(pointerPosition);</div><div class=\"line\">      sphere.rotation.copy(orientation);</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Add the sphere to the `object3D`.</span></div><div class=\"line\">      <span class=\"keyword\">this</span>.object3D.add(sphere);</div><div class=\"line\"></div><div class=\"line\">      <span class=\"comment\">// Return `true`, since weve correctly added a new point (sphere).</span></div><div class=\"line\">      <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;,</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// This method is called on every frame.</span></div><div class=\"line\">    tick: <span class=\"function\"><span class=\"keyword\">function</span> (<span class=\"params\">timeOffset, delta</span>) </span>&#123;</div><div class=\"line\">      <span class=\"keyword\">for</span> (<span class=\"keyword\">var</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>.object3D.children.length; i++) &#123;</div><div class=\"line\">        <span class=\"keyword\">var</span> sphere = <span class=\"keyword\">this</span>.object3D.children[i];</div><div class=\"line\">        <span class=\"comment\">// Calculate the sine value based on the time and the phase for</span></div><div class=\"line\">        <span class=\"comment\">// this sphere, and use it to scale the geometry.</span></div><div class=\"line\">        <span class=\"keyword\">var</span> sin = (<span class=\"built_in\">Math</span>.sin(sphere.phase + timeOffset / <span class=\"number\">500.0</span>) + <span class=\"number\">1</span>) / <span class=\"number\">2</span> + <span class=\"number\">0.1</span>;</div><div class=\"line\">        sphere.scale.copy(sphere.initialScale).multiplyScalar(sin);</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">  &#125;,</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// Additional options for this brush.</span></div><div class=\"line\">  &#123;</div><div class=\"line\">    <span class=\"attr\">thumbnail</span>: <span class=\"string\">'brushes/thumb_spheres.gif'</span>,</div><div class=\"line\">    <span class=\"attr\">spacing</span>: <span class=\"number\">0.01</span></div><div class=\"line\">  &#125;</div><div class=\"line\">);</div></pre></td></tr></table></figure>\n<p><img src=\"/content/images/2016/09/spheres-brush.gif\" alt=\"Looped recording of walking around in a painting with the custom `spheres` brush in A-Painter\"></p>\n<p><a href=\"https://github.com/aframevr/a-painter#brush-api\"><strong>Read more about creating custom brushes.</strong></a></p>\n<h2 id=\"Perhaps-we-could\"><a href=\"#Perhaps-we-could\" class=\"headerlink\" title=\"Perhaps we could\"></a>Perhaps we could</h2><p>While developing this tool, we got plenty of interesting ideas to implement. The future of A-Painter depends on you and its general acceptance and feedback, but here are some ideas of features we would like to add:</p>\n<ul>\n<li>More and better tools, such as a color picker and eraser</li>\n<li>More and better brushes</li>\n<li>Save screenshots and <code>GIF</code> animations</li>\n<li>Audio-reactive brushes</li>\n<li>Multi-user painters and spectators</li>\n<li>Import <a href=\"https://github.com/KhronosGroup/glTF\"><code>glTF</code></a> models</li>\n<li>Export to standard 3D file formats, such as <code>OBJ</code> and <code>glTF</code></li>\n<li>Dedicated web site with gallery of users submissions</li>\n<li>Post-processing filters</li>\n<li>Performance optimizations to existing brushes</li>\n</ul>\n<p>And, of course if you have an idea, issue, or want to contribute directly to the codebase, please feel free to join us at <strong><a href=\"https://github.com/aframevr/a-painter\">https://github.com/aframevr/a-painter</a></strong>.</p>\n"},{"title":"Introducing A-Frame: Building Blocks for WebVR","id":"5","updated":"2016-02-19T00:19:44.000Z","date":"2016-02-19T00:14:02.000Z","_content":"\n<p class=\"intro\">Today the MozVR team releases the first version of <a href=\"https://aframe.io/\">A-Frame</a>: an open source framework for creating WebVR experiences with markup.</p>\n\nA-Frame makes it easy for web developers to create virtual reality experiences that work across desktop, iPhones (Android support coming soon), and the Oculus Rift.\n\n__[Read more on the A-Frame blog!](https://aframe.io/blog/2015/12/16/introducing-aframe/)__\n","source":"_posts/Introducing-A-Frame-Building-Blocks-for-WebVR.md","raw":"---\ntitle: 'Introducing A-Frame: Building Blocks for WebVR'\npermalink: introducing-aframe\nid: 5\nupdated: '2016-02-18 16:19:44'\ndate: 2016-02-18 16:14:02\ntags: A-Frame\n---\n\n<p class=\"intro\">Today the MozVR team releases the first version of <a href=\"https://aframe.io/\">A-Frame</a>: an open source framework for creating WebVR experiences with markup.</p>\n\nA-Frame makes it easy for web developers to create virtual reality experiences that work across desktop, iPhones (Android support coming soon), and the Oculus Rift.\n\n__[Read more on the A-Frame blog!](https://aframe.io/blog/2015/12/16/introducing-aframe/)__\n","slug":"introducing-aframe","published":1,"_id":"citot8hyy000iik1jtq3j4pqy","comments":1,"layout":"post","photos":[],"link":"","content":"<p class=\"intro\">Today the MozVR team releases the first version of <a href=\"https://aframe.io/\" target=\"_blank\" rel=\"external\">A-Frame</a>: an open source framework for creating WebVR experiences with markup.</p>\n\n<p>A-Frame makes it easy for web developers to create virtual reality experiences that work across desktop, iPhones (Android support coming soon), and the Oculus Rift.</p>\n<p><strong><a href=\"https://aframe.io/blog/2015/12/16/introducing-aframe/\" target=\"_blank\" rel=\"external\">Read more on the A-Frame blog!</a></strong></p>\n","excerpt":"","more":"<p class=\"intro\">Today the MozVR team releases the first version of <a href=\"https://aframe.io/\">A-Frame</a>: an open source framework for creating WebVR experiences with markup.</p>\n\n<p>A-Frame makes it easy for web developers to create virtual reality experiences that work across desktop, iPhones (Android support coming soon), and the Oculus Rift.</p>\n<p><strong><a href=\"https://aframe.io/blog/2015/12/16/introducing-aframe/\">Read more on the A-Frame blog!</a></strong></p>\n"},{"title":"Oculus 0.8 Runtime Support Landing in Firefox Nightly","id":"4","updated":"2016-02-18T23:45:12.000Z","date":"2016-02-18T23:38:58.000Z","_content":"\n[Oculus 0.8 runtime](https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/) support has been committed and will be in Firefox Nightly within 48 hours. Please note that this replaces the 0.6 runtime support, so you will need to [upgrade](https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/). For Mac OS X users, [0.5 support](https://developer.oculus.com/downloads/pc/0.5.0.1-beta/Oculus_Runtime_for_OS_X/) should continue to function as usual.\n","source":"_posts/Oculus-0-8-Runtime-Support-Landing-in-Firefox-Nightly.md","raw":"---\ntitle: Oculus 0.8 Runtime Support Landing in Firefox Nightly\ntags:\n  - Platform\n  - Oculus\npermalink: oculus-0-8-runtime-support-landing-in-firefox\nid: 4\nupdated: '2016-02-18 15:45:12'\ndate: 2016-02-18 15:38:58\n---\n\n[Oculus 0.8 runtime](https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/) support has been committed and will be in Firefox Nightly within 48 hours. Please note that this replaces the 0.6 runtime support, so you will need to [upgrade](https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/). For Mac OS X users, [0.5 support](https://developer.oculus.com/downloads/pc/0.5.0.1-beta/Oculus_Runtime_for_OS_X/) should continue to function as usual.\n","slug":"oculus-0-8-runtime-support-landing-in-firefox","published":1,"_id":"citot8hz0000lik1j2b87ybdb","comments":1,"layout":"post","photos":[],"link":"","content":"<p><a href=\"https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/\" target=\"_blank\" rel=\"external\">Oculus 0.8 runtime</a> support has been committed and will be in Firefox Nightly within 48 hours. Please note that this replaces the 0.6 runtime support, so you will need to <a href=\"https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/\" target=\"_blank\" rel=\"external\">upgrade</a>. For Mac OS X users, <a href=\"https://developer.oculus.com/downloads/pc/0.5.0.1-beta/Oculus_Runtime_for_OS_X/\" target=\"_blank\" rel=\"external\">0.5 support</a> should continue to function as usual.</p>\n","excerpt":"","more":"<p><a href=\"https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/\">Oculus 0.8 runtime</a> support has been committed and will be in Firefox Nightly within 48 hours. Please note that this replaces the 0.6 runtime support, so you will need to <a href=\"https://developer.oculus.com/downloads/pc/0.8.0.0-beta/Oculus_Runtime_for_Windows/\">upgrade</a>. For Mac OS X users, <a href=\"https://developer.oculus.com/downloads/pc/0.5.0.1-beta/Oculus_Runtime_for_OS_X/\">0.5 support</a> should continue to function as usual.</p>\n"},{"title":"Upcoming W3C Workshop on Web & VR","id":"18","updated":"2016-09-29T04:53:49.000Z","date":"2016-09-22T11:17:25.000Z","_content":"\nOn October 19-20, 2016, the [W3C](https://www.w3c.org/) will be hosting a [W3C Workshop on Web & VR](https://w3c.github.io/vr-workshop/) at the [Samsung Semiconductor building in San Jose, California](http://w3c.github.io/vr-workshop/#location).\n\nThe goal of the workshop is to bring together practitioners of Web and VR technologies to share experiences and identify potential future standards and establish timelines.\n\nThe format of the workshop will be breakout sessions and working discussions covering [topics](http://w3c.github.io/vr-workshop/#topics) including but not limited to the current [WebVR API](https://w3c.github.io/webvr/).\n\nThe workshop will be led by [Anssi Kostiainen](https://twitter.com/anssik) (of [Intel](http://www.intel.com/)) alongside yours truly, [Chris Van Wiemeersch](https://twitter.com/cvanw) (of [Mozilla](https://www.mozilla.org/)) and a [committee of Web and VR practitioners](https://w3c.github.io/vr-workshop/#committee).\n\n[Attendance](https://w3c.github.io/vr-workshop/#attend) is <strong>free</strong> for all invited participants and is open to the public, whether or not W3C members. Travel expenses are, however, cannot be covered. The aim is to get a diversity of attendees from a variety of industries and communities.\n\nIf you wish to express interest in attending, please fill out the **[registration form](https://www.w3.org/2002/09/wbs/1/vr-workshop/)**. Because the venue can accommodate unfortunately only 100 attendees, you must receive an acceptance email in order to attend. Also, be sure to keep an eye on [these important dates](https://w3c.github.io/vr-workshop/#dates).\n\nLook forward to seeing you there!","source":"_posts/Upcoming-W3C-Workshop-on-Web-VR.md","raw":"---\ntitle: Upcoming W3C Workshop on Web & VR\npermalink: upcoming-w3c-workshop-on-web-vr\nid: 18\nupdated: '2016-09-28 21:53:49'\ndate: 2016-09-22 04:17:25\ntags: Standards\n---\n\nOn October 19-20, 2016, the [W3C](https://www.w3c.org/) will be hosting a [W3C Workshop on Web & VR](https://w3c.github.io/vr-workshop/) at the [Samsung Semiconductor building in San Jose, California](http://w3c.github.io/vr-workshop/#location).\n\nThe goal of the workshop is to bring together practitioners of Web and VR technologies to share experiences and identify potential future standards and establish timelines.\n\nThe format of the workshop will be breakout sessions and working discussions covering [topics](http://w3c.github.io/vr-workshop/#topics) including but not limited to the current [WebVR API](https://w3c.github.io/webvr/).\n\nThe workshop will be led by [Anssi Kostiainen](https://twitter.com/anssik) (of [Intel](http://www.intel.com/)) alongside yours truly, [Chris Van Wiemeersch](https://twitter.com/cvanw) (of [Mozilla](https://www.mozilla.org/)) and a [committee of Web and VR practitioners](https://w3c.github.io/vr-workshop/#committee).\n\n[Attendance](https://w3c.github.io/vr-workshop/#attend) is <strong>free</strong> for all invited participants and is open to the public, whether or not W3C members. Travel expenses are, however, cannot be covered. The aim is to get a diversity of attendees from a variety of industries and communities.\n\nIf you wish to express interest in attending, please fill out the **[registration form](https://www.w3.org/2002/09/wbs/1/vr-workshop/)**. Because the venue can accommodate unfortunately only 100 attendees, you must receive an acceptance email in order to attend. Also, be sure to keep an eye on [these important dates](https://w3c.github.io/vr-workshop/#dates).\n\nLook forward to seeing you there!","slug":"upcoming-w3c-workshop-on-web-vr","published":1,"_id":"citot8hz4000mik1jifoxfg9d","comments":1,"layout":"post","photos":[],"link":"","content":"<p>On October 19-20, 2016, the <a href=\"https://www.w3c.org/\" target=\"_blank\" rel=\"external\">W3C</a> will be hosting a <a href=\"https://w3c.github.io/vr-workshop/\" target=\"_blank\" rel=\"external\">W3C Workshop on Web &amp; VR</a> at the <a href=\"http://w3c.github.io/vr-workshop/#location\" target=\"_blank\" rel=\"external\">Samsung Semiconductor building in San Jose, California</a>.</p>\n<p>The goal of the workshop is to bring together practitioners of Web and VR technologies to share experiences and identify potential future standards and establish timelines.</p>\n<p>The format of the workshop will be breakout sessions and working discussions covering <a href=\"http://w3c.github.io/vr-workshop/#topics\" target=\"_blank\" rel=\"external\">topics</a> including but not limited to the current <a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">WebVR API</a>.</p>\n<p>The workshop will be led by <a href=\"https://twitter.com/anssik\" target=\"_blank\" rel=\"external\">Anssi Kostiainen</a> (of <a href=\"http://www.intel.com/\" target=\"_blank\" rel=\"external\">Intel</a>) alongside yours truly, <a href=\"https://twitter.com/cvanw\" target=\"_blank\" rel=\"external\">Chris Van Wiemeersch</a> (of <a href=\"https://www.mozilla.org/\" target=\"_blank\" rel=\"external\">Mozilla</a>) and a <a href=\"https://w3c.github.io/vr-workshop/#committee\" target=\"_blank\" rel=\"external\">committee of Web and VR practitioners</a>.</p>\n<p><a href=\"https://w3c.github.io/vr-workshop/#attend\" target=\"_blank\" rel=\"external\">Attendance</a> is <strong>free</strong> for all invited participants and is open to the public, whether or not W3C members. Travel expenses are, however, cannot be covered. The aim is to get a diversity of attendees from a variety of industries and communities.</p>\n<p>If you wish to express interest in attending, please fill out the <strong><a href=\"https://www.w3.org/2002/09/wbs/1/vr-workshop/\" target=\"_blank\" rel=\"external\">registration form</a></strong>. Because the venue can accommodate unfortunately only 100 attendees, you must receive an acceptance email in order to attend. Also, be sure to keep an eye on <a href=\"https://w3c.github.io/vr-workshop/#dates\" target=\"_blank\" rel=\"external\">these important dates</a>.</p>\n<p>Look forward to seeing you there!</p>\n","excerpt":"","more":"<p>On October 19-20, 2016, the <a href=\"https://www.w3c.org/\">W3C</a> will be hosting a <a href=\"https://w3c.github.io/vr-workshop/\">W3C Workshop on Web &amp; VR</a> at the <a href=\"http://w3c.github.io/vr-workshop/#location\">Samsung Semiconductor building in San Jose, California</a>.</p>\n<p>The goal of the workshop is to bring together practitioners of Web and VR technologies to share experiences and identify potential future standards and establish timelines.</p>\n<p>The format of the workshop will be breakout sessions and working discussions covering <a href=\"http://w3c.github.io/vr-workshop/#topics\">topics</a> including but not limited to the current <a href=\"https://w3c.github.io/webvr/\">WebVR API</a>.</p>\n<p>The workshop will be led by <a href=\"https://twitter.com/anssik\">Anssi Kostiainen</a> (of <a href=\"http://www.intel.com/\">Intel</a>) alongside yours truly, <a href=\"https://twitter.com/cvanw\">Chris Van Wiemeersch</a> (of <a href=\"https://www.mozilla.org/\">Mozilla</a>) and a <a href=\"https://w3c.github.io/vr-workshop/#committee\">committee of Web and VR practitioners</a>.</p>\n<p><a href=\"https://w3c.github.io/vr-workshop/#attend\">Attendance</a> is <strong>free</strong> for all invited participants and is open to the public, whether or not W3C members. Travel expenses are, however, cannot be covered. The aim is to get a diversity of attendees from a variety of industries and communities.</p>\n<p>If you wish to express interest in attending, please fill out the <strong><a href=\"https://www.w3.org/2002/09/wbs/1/vr-workshop/\">registration form</a></strong>. Because the venue can accommodate unfortunately only 100 attendees, you must receive an acceptance email in order to attend. Also, be sure to keep an eye on <a href=\"https://w3c.github.io/vr-workshop/#dates\">these important dates</a>.</p>\n<p>Look forward to seeing you there!</p>\n"},{"title":"WebVR 1.0 available in Firefox Nightly","id":"15","updated":"2016-08-17T01:45:12.000Z","date":"2016-08-16T23:18:19.000Z","_content":"\nThe WebVR API is a set of DOM interfaces that enable WebGL rendering into Virtual Reality headsets and access to the various sensors for orientation, positioning, and input controls.\n\n![](/content/images/2016/08/w3c.jpg)\n\nAs of today, August 16, 2016, [Firefox Nightly](https://nightly.mozilla.org/) will support the [WebVR 1.0 API](https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/). This replaces the earlier WebVR API implementation with the standard proposed by the [WebVR W3C community group](https://w3c.github.io/webvr/). Our [earlier article](https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/) on the proposal has some resources to help you get started.\n\nFirefox has been heavily optimized for the best VR experience. The latest updates includes a dedicated VR rendering path that ensures smooth and consistent frame rendering, lower latency and rendering at headsets native frame rate, independent from the users main monitor.\n\nThis is the same API that has been implemented in the latest [Chromium experimental builds](https://webvr.info/get-chrome) and the [Samsung Gear VR browser](http://developer.samsung.com/technical-doc/view.do?v=T000000270L). In addition to enabling access to the latest WebVR sites, the new API supports new features such as rendering separate content to the users main display display for spectator views and the ability to traverse links between WebVR pages.\n\nIf you have set preferences to optimize your VR experience in earlier builds, please [create a new browser profile](https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles), as the fresh profile will contain the default values to provide optimal performance.\n\nThe update fully supports Oculus CV1 and DK2 devices on Windows using the [latest Oculus runtime](https://www.oculus.com/en-us/setup/). [Read here on how to configure Oculus Home to work with Firefox.](https://blog.mozvr.com/oculus-home-rift-cv1-webvr/) Unfortunately, Oculus 0.5 SDK on OS X is no longer supported, and Firefox for Android will support WebVR only through [polyfill libraries](https://github.com/borismus/webvr-polyfill).\n\n[Firefox 50 Developer Edition](https://www.mozilla.org/en-US/firefox/developer/) will continue to support the old WebVR API until September 12, 2016.\n\nSupport for [OpenVR](https://en.wikipedia.org/wiki/OpenVR) ([HTC Vive](http://www.htcvive.com/)), [OSVR](http://www.osvr.org/), and positionally tracked motion controllers will be coming soon.\n\nPlease [reach out](https://twitter.com/mozillavr) if you have any feedback on how to improve WebVR support in Firefox.\n\nI look forward to visiting all of your worlds through WebVR!","source":"_posts/WebVR-1-0-available-in-Firefox-Nightly.md","raw":"---\ntitle: WebVR 1.0 available in Firefox Nightly\npermalink: webvr-1-0-available-in-firefox-nightly\nid: 15\nupdated: '2016-08-16 18:45:12'\ndate: 2016-08-16 16:18:19\ntags:\n  - Platform\n---\n\nThe WebVR API is a set of DOM interfaces that enable WebGL rendering into Virtual Reality headsets and access to the various sensors for orientation, positioning, and input controls.\n\n![](/content/images/2016/08/w3c.jpg)\n\nAs of today, August 16, 2016, [Firefox Nightly](https://nightly.mozilla.org/) will support the [WebVR 1.0 API](https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/). This replaces the earlier WebVR API implementation with the standard proposed by the [WebVR W3C community group](https://w3c.github.io/webvr/). Our [earlier article](https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/) on the proposal has some resources to help you get started.\n\nFirefox has been heavily optimized for the best VR experience. The latest updates includes a dedicated VR rendering path that ensures smooth and consistent frame rendering, lower latency and rendering at headsets native frame rate, independent from the users main monitor.\n\nThis is the same API that has been implemented in the latest [Chromium experimental builds](https://webvr.info/get-chrome) and the [Samsung Gear VR browser](http://developer.samsung.com/technical-doc/view.do?v=T000000270L). In addition to enabling access to the latest WebVR sites, the new API supports new features such as rendering separate content to the users main display display for spectator views and the ability to traverse links between WebVR pages.\n\nIf you have set preferences to optimize your VR experience in earlier builds, please [create a new browser profile](https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles), as the fresh profile will contain the default values to provide optimal performance.\n\nThe update fully supports Oculus CV1 and DK2 devices on Windows using the [latest Oculus runtime](https://www.oculus.com/en-us/setup/). [Read here on how to configure Oculus Home to work with Firefox.](https://blog.mozvr.com/oculus-home-rift-cv1-webvr/) Unfortunately, Oculus 0.5 SDK on OS X is no longer supported, and Firefox for Android will support WebVR only through [polyfill libraries](https://github.com/borismus/webvr-polyfill).\n\n[Firefox 50 Developer Edition](https://www.mozilla.org/en-US/firefox/developer/) will continue to support the old WebVR API until September 12, 2016.\n\nSupport for [OpenVR](https://en.wikipedia.org/wiki/OpenVR) ([HTC Vive](http://www.htcvive.com/)), [OSVR](http://www.osvr.org/), and positionally tracked motion controllers will be coming soon.\n\nPlease [reach out](https://twitter.com/mozillavr) if you have any feedback on how to improve WebVR support in Firefox.\n\nI look forward to visiting all of your worlds through WebVR!","slug":"webvr-1-0-available-in-firefox-nightly","published":1,"_id":"citot8hz5000nik1jlp8ikoct","comments":1,"layout":"post","photos":[],"link":"","content":"<p>The WebVR API is a set of DOM interfaces that enable WebGL rendering into Virtual Reality headsets and access to the various sensors for orientation, positioning, and input controls.</p>\n<p><img src=\"/content/images/2016/08/w3c.jpg\" alt=\"\"></p>\n<p>As of today, August 16, 2016, <a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a> will support the <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\" target=\"_blank\" rel=\"external\">WebVR 1.0 API</a>. This replaces the earlier WebVR API implementation with the standard proposed by the <a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">WebVR W3C community group</a>. Our <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\" target=\"_blank\" rel=\"external\">earlier article</a> on the proposal has some resources to help you get started.</p>\n<p>Firefox has been heavily optimized for the best VR experience. The latest updates includes a dedicated VR rendering path that ensures smooth and consistent frame rendering, lower latency and rendering at headsets native frame rate, independent from the users main monitor.</p>\n<p>This is the same API that has been implemented in the latest <a href=\"https://webvr.info/get-chrome\" target=\"_blank\" rel=\"external\">Chromium experimental builds</a> and the <a href=\"http://developer.samsung.com/technical-doc/view.do?v=T000000270L\" target=\"_blank\" rel=\"external\">Samsung Gear VR browser</a>. In addition to enabling access to the latest WebVR sites, the new API supports new features such as rendering separate content to the users main display display for spectator views and the ability to traverse links between WebVR pages.</p>\n<p>If you have set preferences to optimize your VR experience in earlier builds, please <a href=\"https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles\" target=\"_blank\" rel=\"external\">create a new browser profile</a>, as the fresh profile will contain the default values to provide optimal performance.</p>\n<p>The update fully supports Oculus CV1 and DK2 devices on Windows using the <a href=\"https://www.oculus.com/en-us/setup/\" target=\"_blank\" rel=\"external\">latest Oculus runtime</a>. <a href=\"https://blog.mozvr.com/oculus-home-rift-cv1-webvr/\" target=\"_blank\" rel=\"external\">Read here on how to configure Oculus Home to work with Firefox.</a> Unfortunately, Oculus 0.5 SDK on OS X is no longer supported, and Firefox for Android will support WebVR only through <a href=\"https://github.com/borismus/webvr-polyfill\" target=\"_blank\" rel=\"external\">polyfill libraries</a>.</p>\n<p><a href=\"https://www.mozilla.org/en-US/firefox/developer/\" target=\"_blank\" rel=\"external\">Firefox 50 Developer Edition</a> will continue to support the old WebVR API until September 12, 2016.</p>\n<p>Support for <a href=\"https://en.wikipedia.org/wiki/OpenVR\" target=\"_blank\" rel=\"external\">OpenVR</a> (<a href=\"http://www.htcvive.com/\" target=\"_blank\" rel=\"external\">HTC Vive</a>), <a href=\"http://www.osvr.org/\" target=\"_blank\" rel=\"external\">OSVR</a>, and positionally tracked motion controllers will be coming soon.</p>\n<p>Please <a href=\"https://twitter.com/mozillavr\" target=\"_blank\" rel=\"external\">reach out</a> if you have any feedback on how to improve WebVR support in Firefox.</p>\n<p>I look forward to visiting all of your worlds through WebVR!</p>\n","excerpt":"","more":"<p>The WebVR API is a set of DOM interfaces that enable WebGL rendering into Virtual Reality headsets and access to the various sensors for orientation, positioning, and input controls.</p>\n<p><img src=\"/content/images/2016/08/w3c.jpg\" alt=\"\"></p>\n<p>As of today, August 16, 2016, <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a> will support the <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\">WebVR 1.0 API</a>. This replaces the earlier WebVR API implementation with the standard proposed by the <a href=\"https://w3c.github.io/webvr/\">WebVR W3C community group</a>. Our <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\">earlier article</a> on the proposal has some resources to help you get started.</p>\n<p>Firefox has been heavily optimized for the best VR experience. The latest updates includes a dedicated VR rendering path that ensures smooth and consistent frame rendering, lower latency and rendering at headsets native frame rate, independent from the users main monitor.</p>\n<p>This is the same API that has been implemented in the latest <a href=\"https://webvr.info/get-chrome\">Chromium experimental builds</a> and the <a href=\"http://developer.samsung.com/technical-doc/view.do?v=T000000270L\">Samsung Gear VR browser</a>. In addition to enabling access to the latest WebVR sites, the new API supports new features such as rendering separate content to the users main display display for spectator views and the ability to traverse links between WebVR pages.</p>\n<p>If you have set preferences to optimize your VR experience in earlier builds, please <a href=\"https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles\">create a new browser profile</a>, as the fresh profile will contain the default values to provide optimal performance.</p>\n<p>The update fully supports Oculus CV1 and DK2 devices on Windows using the <a href=\"https://www.oculus.com/en-us/setup/\">latest Oculus runtime</a>. <a href=\"https://blog.mozvr.com/oculus-home-rift-cv1-webvr/\">Read here on how to configure Oculus Home to work with Firefox.</a> Unfortunately, Oculus 0.5 SDK on OS X is no longer supported, and Firefox for Android will support WebVR only through <a href=\"https://github.com/borismus/webvr-polyfill\">polyfill libraries</a>.</p>\n<p><a href=\"https://www.mozilla.org/en-US/firefox/developer/\">Firefox 50 Developer Edition</a> will continue to support the old WebVR API until September 12, 2016.</p>\n<p>Support for <a href=\"https://en.wikipedia.org/wiki/OpenVR\">OpenVR</a> (<a href=\"http://www.htcvive.com/\">HTC Vive</a>), <a href=\"http://www.osvr.org/\">OSVR</a>, and positionally tracked motion controllers will be coming soon.</p>\n<p>Please <a href=\"https://twitter.com/mozillavr\">reach out</a> if you have any feedback on how to improve WebVR support in Firefox.</p>\n<p>I look forward to visiting all of your worlds through WebVR!</p>\n"},{"title":"WebVR Enabled by Default in Firefox Nightly","id":"6","updated":"2016-02-19T22:48:01.000Z","date":"2016-02-19T22:18:43.000Z","_content":"\nAs of 2016-01-05 [Firefox Nightly](https://nightly.mozilla.org/), __WebVR is enabled by default__. If you see any increased choppiness after updating, it may be solved by unchecking the Enable multi-process Nightly option in the Preferences.\n\nAlso, we are planning to [implement timewarp in Firefox](https://bugzilla.mozilla.org/show_bug.cgi?id=1237417).\n\nWe are focusing on latency over the next couple of months. A temporary solution to make it a bit better is to adjust the following:\n\n1. In `about:config`, set the `layout.frame_rate` preference to `75`.\n2. Uncheck the Enable Multi-process Nightly option in the Preferences.\n\n__*Tip:*__ You may want to [set up a separate Firefox profile](https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles) with these changes so you can easily turn them off when not using WebVR.","source":"_posts/WebVR-Enabled-by-Default-in-Firefox-Nightly.md","raw":"---\ntitle: WebVR Enabled by Default in Firefox Nightly\npermalink: webvr-enabled-by-default-in-firefox-nightly\nid: 6\nupdated: '2016-02-19 14:48:01'\ndate: 2016-02-19 14:18:43\ntags: Platform\n---\n\nAs of 2016-01-05 [Firefox Nightly](https://nightly.mozilla.org/), __WebVR is enabled by default__. If you see any increased choppiness after updating, it may be solved by unchecking the Enable multi-process Nightly option in the Preferences.\n\nAlso, we are planning to [implement timewarp in Firefox](https://bugzilla.mozilla.org/show_bug.cgi?id=1237417).\n\nWe are focusing on latency over the next couple of months. A temporary solution to make it a bit better is to adjust the following:\n\n1. In `about:config`, set the `layout.frame_rate` preference to `75`.\n2. Uncheck the Enable Multi-process Nightly option in the Preferences.\n\n__*Tip:*__ You may want to [set up a separate Firefox profile](https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles) with these changes so you can easily turn them off when not using WebVR.","slug":"webvr-enabled-by-default-in-firefox-nightly","published":1,"_id":"citot8hz7000qik1jr8nw1foh","comments":1,"layout":"post","photos":[],"link":"","content":"<p>As of 2016-01-05 <a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a>, <strong>WebVR is enabled by default</strong>. If you see any increased choppiness after updating, it may be solved by unchecking the Enable multi-process Nightly option in the Preferences.</p>\n<p>Also, we are planning to <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1237417\" target=\"_blank\" rel=\"external\">implement timewarp in Firefox</a>.</p>\n<p>We are focusing on latency over the next couple of months. A temporary solution to make it a bit better is to adjust the following:</p>\n<ol>\n<li>In <code>about:config</code>, set the <code>layout.frame_rate</code> preference to <code>75</code>.</li>\n<li>Uncheck the Enable Multi-process Nightly option in the Preferences.</li>\n</ol>\n<p><strong><em>Tip:</em></strong> You may want to <a href=\"https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles\" target=\"_blank\" rel=\"external\">set up a separate Firefox profile</a> with these changes so you can easily turn them off when not using WebVR.</p>\n","excerpt":"","more":"<p>As of 2016-01-05 <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a>, <strong>WebVR is enabled by default</strong>. If you see any increased choppiness after updating, it may be solved by unchecking the Enable multi-process Nightly option in the Preferences.</p>\n<p>Also, we are planning to <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1237417\">implement timewarp in Firefox</a>.</p>\n<p>We are focusing on latency over the next couple of months. A temporary solution to make it a bit better is to adjust the following:</p>\n<ol>\n<li>In <code>about:config</code>, set the <code>layout.frame_rate</code> preference to <code>75</code>.</li>\n<li>Uncheck the Enable Multi-process Nightly option in the Preferences.</li>\n</ol>\n<p><strong><em>Tip:</em></strong> You may want to <a href=\"https://support.mozilla.org/en-US/kb/profile-manager-create-and-remove-firefox-profiles\">set up a separate Firefox profile</a> with these changes so you can easily turn them off when not using WebVR.</p>\n"},{"title":"Quick VR Prototypes","id":"1","updated":"2016-03-23T09:23:43.000Z","date":"2016-02-16T23:51:56.000Z","_content":"\n<p class=\"intro\">Designing for the VR web is nothing like designing for the desktop and mobile web. Every process and principle must be rethought, including how we prototype our ideas. With a simple cylinder and some precise measurements, however, we can move rapidly between our favorite 2D design apps and the virtual canvas of our headsets.</p>\n\nAfter years of bouncing between Photoshop and Keynote, I've happily settled on Illustrator as my primary interface design tool. I'm good with 3D apps such as Cinema 4D, but for all their power, they're painful to use for typography, interface layout, etc. So when it came time to design a VR web navigation UI, I wanted a workflow that let me rapidly iterate from mockups created in Illustrator to wrap-around WebVR test scenes.\n\n<div class=\"post-summary\">\n  <h2>In Brief</h2>\n  <ol>\n    <li>Create your layout in a 2D design app and export as a bitmap.</li>\n    <li>Create a cylinder mesh in three.js with a circumference/height ratio that matches the width/height ratio of the bitmap.</li>\n    <li>Apply the bitmap as a texture to the cylinder and flip the cylinder faces.</li>\n    <li>View in VR!</li>\n  </ol>\n  <a href=\"http://mozvr.github.io/vr-web-examples/mockups-on-cylinders/\" class=\"assets-link\" target=\"_blank\">\n    <div class=\"table\">\n      <div class=\"table-cell\">\n        View Demo\n      </div>\n      <div class=\"table-cell\">\n        <img src=\"/content/images/2016/02/icon-goggles-2-white.svg\" class=\"left w3\">\n      </div>\n    </div>\n  </a>\n  <a href=\"https://drive.google.com/file/d/0BzU9Qn2t09hSemI5REw0ek54eWc/view?usp=sharing\" class=\"assets-link\">\n    <div class=\"table\">\n      <div class=\"table-cell\">\n        Get the files\n      </div>\n      <div class=\"table-cell\">\n        <img src=\"/content/images/2016/02/icon-download-2-white-1.svg\" class=\"left w3\">\n      </div>\n    </div>\n  </a>\n</div>\n\nWe start in our preferred 2D design app - in my case, Illustrator. We create a canvas that is **360cm &times; 90cm**. When later viewed in the Rift, this canvas will wrap around us, mapped onto a cylinder which we (or the WebGL camera, more accurately) are in the center of. Like the following:\n\n<figure>\n  <img src=\"/content/images/2016/02/mockup1.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\">\n  <figcaption>\n    Our 360cm &times; 90cm Illustrator layout will be mapped onto a WebGL cylinder with a 360cm circumference and 90cm height.\n  </figcaption>\n</figure>\n\nWorking with real-world units is important because sense of scale is integral to virtual reality, and the scale your users will perceive will be determined primarily by the size of the elements in your scene relative to the distance between the user's eyes. That distance is defined in real-world measurements (meters, to be precise). Working in real-world units throughout our pipeline ensures we don't encounter any weird surprises, such as text blocks that suddenly appear 10 stories tall (unless of course you _want_ that).\n\nAs we create our layouts, it's also important that we know where on the cylinder our elements will eventually appear. That's why a 360cm width is convenient: each centimeter on the horizontal of our composition will equal 1 on the circumference of the 3D cylinder. The center of our layout (180cm/180) will appear directly in front of the viewer, while the left and right edges will appear behind them.\n\n<figure>\n  <img src=\"/content/images/2016/02/mockup2.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\">\n</figure>\n\nBut wait! How much of our layout will be visible to the user? Human field of view is [limited](http://xkcd.com/1080/), after all. We wouldn't want to make our users turn their heads 90 to read an important status indicator. The following diagram from Extron gives us some idea of what we have to work with.\n\n<figure>\n  <img src=\"/content/images/2016/02/human-visual-field.jpg\" alt=\"Diagram of human visual field. Source: Extron.\">\n  <figcaption>\n    Human field of vision is approximately 180 horizontal, but our ability to read text is limited to just the center 10, and our ability to perceive symbols to the center 60.\n  </figcaption>\n</figure>\n\nTo help us keep track of what our users can see, it's helpful to set up a few guides in our layout template that express these values. Most importantly, the center 60, 30, and 10 of our vision, within which we can see color, shape, and text, respectively.\n\n<figure>\n  <img src=\"/content/images/2016/02/mockup3.png\" alt=\"Mockup of a 360x90cm layout template with overlays for important field-of-view measurements.\">\n</figure>\n\nWe also need to remember that current VR headsets have a fairly limited field of view. The DK2, for example, has an effective horizontal field of view of approximately 90. This crops what we can see in the headset (without turning our heads) to the following:\n\n<figure>\n  <img src=\"/content/images/2016/02/visual-field-DK2.png\" alt=\"Diagram of Oculus Rift DK2 field of view. Source: Extron.\">\n</figure>\n\nOnce we have a layout ready, we want to export it as a bitmap. We can scale at export-time as much as we need, so long as we do not change the same layout's width/height ratio. \n\n## Viewing our layout in VR\n\nThe good news is we don't need much JS to create our WebGL VR scene. The following scene is built on the MozVR three.js WebVR boilerplate, available from our [vr-web-examples repo](https://github.com/MozVR/vr-web-examples). It uses [three.js](https://github.com/mrdoob/three.js) and two extra libraries that handle detecting, communicating, and rendering to an attached VR headset.\n\nTo preview our mockup, we simply copy the bitmap we saved into the `/images` directory and rename it `mockup.png`, overwriting the existing file. We then load `index.html` into our VR-enabled browser (e.g., [Firefox with VR](http://mozvr.com/#downloads)), and enter VR mode by pressing `F` or double-clicking. In our headset, the browser should render our scene, and we should see our layout wrapped around us on a cylinder.\n\n### The code\n\nLet's look at `index.html` to see how this works. Most of the code is standard boilerplate for a three.js scene with VR support. To add our layouts, we must do the following:\n\n1. Create a cylinder geometry with a circumference/height ratio that matches the width/height ratio of the bitmap.\n1. Create a material and load our mockup as a texture.\n1. Flip the cylinder geometry to ensure the mockup displays correctly (facing \"inwards\").\n1. Create a mesh from our geometry and material and add it to the scene so it renders.\n\nTo do this we first set up a few variables for our cylinder geometry:\n\n```javascript\n/*\nSet up the key measurements of the cylinder that will display our mockup image. It is important to match these measurements to the size of the image, or the surface area of the cylinder will be different from the image, causing it to appear squished or stretched. We start with the circumference of the cylinder. Set it to match the width of the image. Remember that the standard unit of measurement for VR scenes is meters. If our mockup canvas is 36cm wide, for example, we set the circumference value to be 3.6cm (360 / 100).\n*/\n\nvar circumference = 3.6;\n\n/*\nSet up the radius of the cylinder. We derive the radius from the circumference.\n*/\n\nvar radius = circumference / 3.14 / 2;\n\n/*\nSet up the height of the cylinder. As with the circumference, we match this value to the height of our mockup, and convert to meters (from 90cm to 0.9m).\n*/\n\nvar height = 0.9;\n\n```\n\nWe then create a cylinder geometry instance using the variables, and then invert its faces:\n\n```javascript\n/*\nCreate the geometry for the cylinder object that will display our mockups.\nThe cylinder constructor takes the following arguments: `CylinderGeometry(radiusTop, radiusBottom, height, radiusSegments, heightSegments, openEnded)`. We add 60 `radiusSegments` to make the cylinder smooth, and leave the top and bottom `openEnded`.\n*/\n\nvar geometry = new THREE.CylinderGeometry( radius, radius, height, 60, 1, true );\n\n/*\nInvert the scale of the geometry on the X axis. This flips the faces of the cylinder so they face inwards, which has the visible effect of displaying the mockups as we expect: facing inwards and in the correct orientation. Try removing this line to see what happens without flipping the scale.\n*/\n\ngeometry.applyMatrix( new THREE.Matrix4().makeScale( -1, 1, 1 ) );\n\n```\n\nWe then create a material for our mesh:\n\n```javascript\n/*\nCreate the material that we will load our mockup into and apply to our cylinder object. We set `transparent` to `true`, enabling us to optionally use mockups with alpha channels. We set `side` to `THREE.DoubleSide` so that our material renders facing both inwards and outwards (relative to the direction of the faces of the cylinder object). By default, materials and the faces of three.js meshes face outwards and are invisible from the reverse. Setting `THREE.DoubleSide` ensures the cylinder and its material will be visible no matter which direction (inside or out) we are viewing it from. This step is not strictly necessary, since we are actually going to invert the faces of the object to face inwards in a later step, but it is good to be aware of the `side` material attribute and how to define it. We then load our mockup as a texture.\n*/\n\nvar material = new THREE.MeshBasicMaterial( { \n  transparent: true, \n  side: THREE.DoubleSide,\n  map: THREE.ImageUtils.loadTexture( 'images/mockup.png' )\n});\n```\n\nNext, we create the mesh and add it to our scene:\n\n```javascript\n/*\nCreate the mesh of our cylinder object from the geometry and material.\n*/\n\nvar mesh = new THREE.Mesh( geometry, material );\n\n/*\nAdd our cylinder object to the scene. The default position of elements added to a three.js scene is `0,0,0`, which is also the default position of our scene's camera. So, our camera sits inside our cylinder.\n*/\n\nscene.add( mesh );\n```\n\nOur cylinder should now render in the scene, and we are positioned at its center.\n\n## Experimenting further\n\nWith our layout loaded, there's a lot more we can optionally do.\n\n### 1. Change the radius of our cylinder\n\nThis has the effect of bringing the mockup closer or farther from the user. By default, a cylinder with a circumference of 3.6m has a radius of 0.573m (22.5in). This is about the average distance that most of us view our desktop or laptop displays from. Using your VR headset, you can adjust the mesh scale to see what feels right for your layout. Make sure to set the same values for the X, Y and Z; otherwise, the cylinder will be stretched.\n\n```javascript\n/*\nTo adjust the distance between our mockups and the user, we can optionally scale our mesh. If we apply 0.5 to the X,Y,Z, for example, the radius shrinks by half, and the mockups become twice as close to our eyes. Because we are scaling proportionally (equal on X,Y,Z) the mockups do not _appear_ any larger, but the stereo effect of the VR headset tells us they are closer. Play with this setting to find a value that you like.\n*/\n\nmesh.scale.set( 0.5, 0.5, 0.5 );\n```\n\nAs you experiment, also consider the potential for other objects in your scene to come between your layout and the user. If I design a heads-up display (HUD)-style navigation interface with a 0.5-meter radius, for example, and my avatar in the VR world walks up to a wall, the geometry of the wall is probably going to come closer than the interface, thereby occluding it. My loading indicator suddenly disappears into brick.\n\nThe [Oculus Best Practices Guide](http://static.oculus.com/sdk-downloads/documents/Oculus_Best_Practices_Guide.pdf) (which is required reading for any creator of VR content) suggests the following:\n\n> Bringing UIs in closer (e.g., 20cm) can help prevent occlusion (where in-world objects come closer to the user than HUD objects), but require the user to \"...shift their focus between the close-up HUD and the much more distant scene whenever they check the HUD. These kinds of shifts in eye convergence and accommodation (eye lens focus) can quickly lead to fatigue and eyestrain.\"\n\n### 2. Add a background image\n\nBy default the background of our scene is black, but it's easy to add a background image.\n\n```javascript\n/*\nTo optionally add a background image to the scene, create a large sphere and apply a bitmap to it. First, create the geometry for the sphere. The `SphereGeometry` constructor takes several arguments, but we need only the basic three: `radius`, `widthSegments`, and `heightSegments`. We set `radius` to a big 5000 meters so the sphere is less likely to occlude other objects in our scene. We set the width and height segments to 64 and 32, respectively, to make its sphere surface smooth. And, we then invert the geometry on the X-axis using `THREE.Matrix4().makeScale()`, to flip the geometry faces so they face \"inwards,\" as we did with the mockup cylinder.\n*/\n\nvar geometry = new THREE.SphereGeometry( 5000, 64, 32 );\ngeometry.applyMatrix( new THREE.Matrix4().makeScale( -1, 1, 1 ) );\n\n/*\nCreate the material we will load our background image into.\n*/\n\nvar material = new THREE.MeshBasicMaterial( {\n  map: THREE.ImageUtils.loadTexture( 'images/background.png' )\n} );\n\n/*\nCreate the mesh of our background from the geometry and material, and add it to the scene.\n*/\n\nvar mesh = new THREE.Mesh( geometry, material );\nscene.add( mesh );\n\n```\n\nAnd that's it! When we load the scene and put on our headset, we should by standing inside our mockup layout, with a distant background image wrapping everything.\n\nPlay around with different background images to find one that gives you the contrast you want. I tend to use something that approximates the look of my final 3D scene, so I can judge colors, legibility, etc. For best results, use panoramic images in equirectangular format (see below). They will map perfectly (without distortion) to the WebGL sphere:\n\n<figure>\n  <img src=\"/content/images/2016/02/puydesancy.jpg\" alt=\"Equirectangular panorama photo of mountain top in France by Alexandre Duret-Lutz\">\n  <figcaption>\n    An example of an equirectangular image, taken by Alexandre Duret-Lutz. Find more of Alexandre's beautiful panos on <a href=\"https://www.flickr.com/photos/gadl/\" target=\"_blank\">Flickr</a>.\n  </figcaption>\n</figure>\n\nFlickr's [Equirectangular Pool](https://www.flickr.com/groups/equirectangular/) is a fantastic source for images (just be sure to check the licenses). You can also use 3D apps to render 3D scenes into equirectangular format. I used Cinema 4D + Vray to create the blurred pano used in this tutorial, for example. Or if you need just a simple gradient or solid color, use your favorite image-editing app to fill a canvas with 2:1 width:height proportions.\n\n### 3. Create multiple layers at different depths\n\nDepth is a fundamental element of design for virtual reality. Through the two separate eyes of a VR headset we can perceive even slight differences in z-position between elements. We can see that a glowing button hovers 0.5cm above the surface of its parent dialogue, for example, or that a UI stretches off into the horizon. Depth in VR does naturally what drop shadows do skeuomorphically in 2D layouts: create visual contrast between stacked layers.\n\nAdding additional layers to our scene is easy. We create additional meshes and load a different bitmaps into their materials.\n\n* Copy and paste the code above, not including the variables for `circumference`, `radius`, and `height` (they need to be specified only once).\n* In the new material, specify a different bitmap (e.g., `THREE.ImageUtils.loadTexture( 'images/mockup-background.png' )`).\n* Tweak the mesh scale values to push the layout closer or further, as desired. This creates separation between layers.\n\nMy tactic in creating the MozVR.com layout was to start by building my layouts in a single Illustrator layer without thinking too much about 3D composition, and then group the elements into new layers towards the end of the process, with each layer representing a different depth. I then saved each layer individually as a bitmap with transparency. Each of these I then loaded into its own cylinder mesh, which I then tweaked the scale to find the desired separations. I found quickly that depth is particularly spectacular when combined with the DK2's 3D camera, which enables us to instantly perceive the parallax effect between layers as we lean our bodies around inside the virtual world.\n\n## Have fun!\n\nThis technique enables us to bridge the workflows we know with the new world of virtual reality. It's a quick and simple way to iterate rapidly. Start hacking - and have fun!\n","source":"_posts/Quick-VR-Prototypes.md","raw":"---\ntitle: Quick VR Prototypes\ntags:\n  - Tutorials\n  - Design\npermalink: quick-vr-prototypes\nid: 1\nupdated: '2016-03-23 02:23:43'\ndate: 2016-02-16 15:51:56\n---\n\n<p class=\"intro\">Designing for the VR web is nothing like designing for the desktop and mobile web. Every process and principle must be rethought, including how we prototype our ideas. With a simple cylinder and some precise measurements, however, we can move rapidly between our favorite 2D design apps and the virtual canvas of our headsets.</p>\n\nAfter years of bouncing between Photoshop and Keynote, I've happily settled on Illustrator as my primary interface design tool. I'm good with 3D apps such as Cinema 4D, but for all their power, they're painful to use for typography, interface layout, etc. So when it came time to design a VR web navigation UI, I wanted a workflow that let me rapidly iterate from mockups created in Illustrator to wrap-around WebVR test scenes.\n\n<div class=\"post-summary\">\n  <h2>In Brief</h2>\n  <ol>\n    <li>Create your layout in a 2D design app and export as a bitmap.</li>\n    <li>Create a cylinder mesh in three.js with a circumference/height ratio that matches the width/height ratio of the bitmap.</li>\n    <li>Apply the bitmap as a texture to the cylinder and flip the cylinder faces.</li>\n    <li>View in VR!</li>\n  </ol>\n  <a href=\"http://mozvr.github.io/vr-web-examples/mockups-on-cylinders/\" class=\"assets-link\" target=\"_blank\">\n    <div class=\"table\">\n      <div class=\"table-cell\">\n        View Demo\n      </div>\n      <div class=\"table-cell\">\n        <img src=\"/content/images/2016/02/icon-goggles-2-white.svg\" class=\"left w3\">\n      </div>\n    </div>\n  </a>\n  <a href=\"https://drive.google.com/file/d/0BzU9Qn2t09hSemI5REw0ek54eWc/view?usp=sharing\" class=\"assets-link\">\n    <div class=\"table\">\n      <div class=\"table-cell\">\n        Get the files\n      </div>\n      <div class=\"table-cell\">\n        <img src=\"/content/images/2016/02/icon-download-2-white-1.svg\" class=\"left w3\">\n      </div>\n    </div>\n  </a>\n</div>\n\nWe start in our preferred 2D design app - in my case, Illustrator. We create a canvas that is **360cm &times; 90cm**. When later viewed in the Rift, this canvas will wrap around us, mapped onto a cylinder which we (or the WebGL camera, more accurately) are in the center of. Like the following:\n\n<figure>\n  <img src=\"/content/images/2016/02/mockup1.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\">\n  <figcaption>\n    Our 360cm &times; 90cm Illustrator layout will be mapped onto a WebGL cylinder with a 360cm circumference and 90cm height.\n  </figcaption>\n</figure>\n\nWorking with real-world units is important because sense of scale is integral to virtual reality, and the scale your users will perceive will be determined primarily by the size of the elements in your scene relative to the distance between the user's eyes. That distance is defined in real-world measurements (meters, to be precise). Working in real-world units throughout our pipeline ensures we don't encounter any weird surprises, such as text blocks that suddenly appear 10 stories tall (unless of course you _want_ that).\n\nAs we create our layouts, it's also important that we know where on the cylinder our elements will eventually appear. That's why a 360cm width is convenient: each centimeter on the horizontal of our composition will equal 1 on the circumference of the 3D cylinder. The center of our layout (180cm/180) will appear directly in front of the viewer, while the left and right edges will appear behind them.\n\n<figure>\n  <img src=\"/content/images/2016/02/mockup2.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\">\n</figure>\n\nBut wait! How much of our layout will be visible to the user? Human field of view is [limited](http://xkcd.com/1080/), after all. We wouldn't want to make our users turn their heads 90 to read an important status indicator. The following diagram from Extron gives us some idea of what we have to work with.\n\n<figure>\n  <img src=\"/content/images/2016/02/human-visual-field.jpg\" alt=\"Diagram of human visual field. Source: Extron.\">\n  <figcaption>\n    Human field of vision is approximately 180 horizontal, but our ability to read text is limited to just the center 10, and our ability to perceive symbols to the center 60.\n  </figcaption>\n</figure>\n\nTo help us keep track of what our users can see, it's helpful to set up a few guides in our layout template that express these values. Most importantly, the center 60, 30, and 10 of our vision, within which we can see color, shape, and text, respectively.\n\n<figure>\n  <img src=\"/content/images/2016/02/mockup3.png\" alt=\"Mockup of a 360x90cm layout template with overlays for important field-of-view measurements.\">\n</figure>\n\nWe also need to remember that current VR headsets have a fairly limited field of view. The DK2, for example, has an effective horizontal field of view of approximately 90. This crops what we can see in the headset (without turning our heads) to the following:\n\n<figure>\n  <img src=\"/content/images/2016/02/visual-field-DK2.png\" alt=\"Diagram of Oculus Rift DK2 field of view. Source: Extron.\">\n</figure>\n\nOnce we have a layout ready, we want to export it as a bitmap. We can scale at export-time as much as we need, so long as we do not change the same layout's width/height ratio. \n\n## Viewing our layout in VR\n\nThe good news is we don't need much JS to create our WebGL VR scene. The following scene is built on the MozVR three.js WebVR boilerplate, available from our [vr-web-examples repo](https://github.com/MozVR/vr-web-examples). It uses [three.js](https://github.com/mrdoob/three.js) and two extra libraries that handle detecting, communicating, and rendering to an attached VR headset.\n\nTo preview our mockup, we simply copy the bitmap we saved into the `/images` directory and rename it `mockup.png`, overwriting the existing file. We then load `index.html` into our VR-enabled browser (e.g., [Firefox with VR](http://mozvr.com/#downloads)), and enter VR mode by pressing `F` or double-clicking. In our headset, the browser should render our scene, and we should see our layout wrapped around us on a cylinder.\n\n### The code\n\nLet's look at `index.html` to see how this works. Most of the code is standard boilerplate for a three.js scene with VR support. To add our layouts, we must do the following:\n\n1. Create a cylinder geometry with a circumference/height ratio that matches the width/height ratio of the bitmap.\n1. Create a material and load our mockup as a texture.\n1. Flip the cylinder geometry to ensure the mockup displays correctly (facing \"inwards\").\n1. Create a mesh from our geometry and material and add it to the scene so it renders.\n\nTo do this we first set up a few variables for our cylinder geometry:\n\n```javascript\n/*\nSet up the key measurements of the cylinder that will display our mockup image. It is important to match these measurements to the size of the image, or the surface area of the cylinder will be different from the image, causing it to appear squished or stretched. We start with the circumference of the cylinder. Set it to match the width of the image. Remember that the standard unit of measurement for VR scenes is meters. If our mockup canvas is 36cm wide, for example, we set the circumference value to be 3.6cm (360 / 100).\n*/\n\nvar circumference = 3.6;\n\n/*\nSet up the radius of the cylinder. We derive the radius from the circumference.\n*/\n\nvar radius = circumference / 3.14 / 2;\n\n/*\nSet up the height of the cylinder. As with the circumference, we match this value to the height of our mockup, and convert to meters (from 90cm to 0.9m).\n*/\n\nvar height = 0.9;\n\n```\n\nWe then create a cylinder geometry instance using the variables, and then invert its faces:\n\n```javascript\n/*\nCreate the geometry for the cylinder object that will display our mockups.\nThe cylinder constructor takes the following arguments: `CylinderGeometry(radiusTop, radiusBottom, height, radiusSegments, heightSegments, openEnded)`. We add 60 `radiusSegments` to make the cylinder smooth, and leave the top and bottom `openEnded`.\n*/\n\nvar geometry = new THREE.CylinderGeometry( radius, radius, height, 60, 1, true );\n\n/*\nInvert the scale of the geometry on the X axis. This flips the faces of the cylinder so they face inwards, which has the visible effect of displaying the mockups as we expect: facing inwards and in the correct orientation. Try removing this line to see what happens without flipping the scale.\n*/\n\ngeometry.applyMatrix( new THREE.Matrix4().makeScale( -1, 1, 1 ) );\n\n```\n\nWe then create a material for our mesh:\n\n```javascript\n/*\nCreate the material that we will load our mockup into and apply to our cylinder object. We set `transparent` to `true`, enabling us to optionally use mockups with alpha channels. We set `side` to `THREE.DoubleSide` so that our material renders facing both inwards and outwards (relative to the direction of the faces of the cylinder object). By default, materials and the faces of three.js meshes face outwards and are invisible from the reverse. Setting `THREE.DoubleSide` ensures the cylinder and its material will be visible no matter which direction (inside or out) we are viewing it from. This step is not strictly necessary, since we are actually going to invert the faces of the object to face inwards in a later step, but it is good to be aware of the `side` material attribute and how to define it. We then load our mockup as a texture.\n*/\n\nvar material = new THREE.MeshBasicMaterial( { \n  transparent: true, \n  side: THREE.DoubleSide,\n  map: THREE.ImageUtils.loadTexture( 'images/mockup.png' )\n});\n```\n\nNext, we create the mesh and add it to our scene:\n\n```javascript\n/*\nCreate the mesh of our cylinder object from the geometry and material.\n*/\n\nvar mesh = new THREE.Mesh( geometry, material );\n\n/*\nAdd our cylinder object to the scene. The default position of elements added to a three.js scene is `0,0,0`, which is also the default position of our scene's camera. So, our camera sits inside our cylinder.\n*/\n\nscene.add( mesh );\n```\n\nOur cylinder should now render in the scene, and we are positioned at its center.\n\n## Experimenting further\n\nWith our layout loaded, there's a lot more we can optionally do.\n\n### 1. Change the radius of our cylinder\n\nThis has the effect of bringing the mockup closer or farther from the user. By default, a cylinder with a circumference of 3.6m has a radius of 0.573m (22.5in). This is about the average distance that most of us view our desktop or laptop displays from. Using your VR headset, you can adjust the mesh scale to see what feels right for your layout. Make sure to set the same values for the X, Y and Z; otherwise, the cylinder will be stretched.\n\n```javascript\n/*\nTo adjust the distance between our mockups and the user, we can optionally scale our mesh. If we apply 0.5 to the X,Y,Z, for example, the radius shrinks by half, and the mockups become twice as close to our eyes. Because we are scaling proportionally (equal on X,Y,Z) the mockups do not _appear_ any larger, but the stereo effect of the VR headset tells us they are closer. Play with this setting to find a value that you like.\n*/\n\nmesh.scale.set( 0.5, 0.5, 0.5 );\n```\n\nAs you experiment, also consider the potential for other objects in your scene to come between your layout and the user. If I design a heads-up display (HUD)-style navigation interface with a 0.5-meter radius, for example, and my avatar in the VR world walks up to a wall, the geometry of the wall is probably going to come closer than the interface, thereby occluding it. My loading indicator suddenly disappears into brick.\n\nThe [Oculus Best Practices Guide](http://static.oculus.com/sdk-downloads/documents/Oculus_Best_Practices_Guide.pdf) (which is required reading for any creator of VR content) suggests the following:\n\n> Bringing UIs in closer (e.g., 20cm) can help prevent occlusion (where in-world objects come closer to the user than HUD objects), but require the user to \"...shift their focus between the close-up HUD and the much more distant scene whenever they check the HUD. These kinds of shifts in eye convergence and accommodation (eye lens focus) can quickly lead to fatigue and eyestrain.\"\n\n### 2. Add a background image\n\nBy default the background of our scene is black, but it's easy to add a background image.\n\n```javascript\n/*\nTo optionally add a background image to the scene, create a large sphere and apply a bitmap to it. First, create the geometry for the sphere. The `SphereGeometry` constructor takes several arguments, but we need only the basic three: `radius`, `widthSegments`, and `heightSegments`. We set `radius` to a big 5000 meters so the sphere is less likely to occlude other objects in our scene. We set the width and height segments to 64 and 32, respectively, to make its sphere surface smooth. And, we then invert the geometry on the X-axis using `THREE.Matrix4().makeScale()`, to flip the geometry faces so they face \"inwards,\" as we did with the mockup cylinder.\n*/\n\nvar geometry = new THREE.SphereGeometry( 5000, 64, 32 );\ngeometry.applyMatrix( new THREE.Matrix4().makeScale( -1, 1, 1 ) );\n\n/*\nCreate the material we will load our background image into.\n*/\n\nvar material = new THREE.MeshBasicMaterial( {\n  map: THREE.ImageUtils.loadTexture( 'images/background.png' )\n} );\n\n/*\nCreate the mesh of our background from the geometry and material, and add it to the scene.\n*/\n\nvar mesh = new THREE.Mesh( geometry, material );\nscene.add( mesh );\n\n```\n\nAnd that's it! When we load the scene and put on our headset, we should by standing inside our mockup layout, with a distant background image wrapping everything.\n\nPlay around with different background images to find one that gives you the contrast you want. I tend to use something that approximates the look of my final 3D scene, so I can judge colors, legibility, etc. For best results, use panoramic images in equirectangular format (see below). They will map perfectly (without distortion) to the WebGL sphere:\n\n<figure>\n  <img src=\"/content/images/2016/02/puydesancy.jpg\" alt=\"Equirectangular panorama photo of mountain top in France by Alexandre Duret-Lutz\">\n  <figcaption>\n    An example of an equirectangular image, taken by Alexandre Duret-Lutz. Find more of Alexandre's beautiful panos on <a href=\"https://www.flickr.com/photos/gadl/\" target=\"_blank\">Flickr</a>.\n  </figcaption>\n</figure>\n\nFlickr's [Equirectangular Pool](https://www.flickr.com/groups/equirectangular/) is a fantastic source for images (just be sure to check the licenses). You can also use 3D apps to render 3D scenes into equirectangular format. I used Cinema 4D + Vray to create the blurred pano used in this tutorial, for example. Or if you need just a simple gradient or solid color, use your favorite image-editing app to fill a canvas with 2:1 width:height proportions.\n\n### 3. Create multiple layers at different depths\n\nDepth is a fundamental element of design for virtual reality. Through the two separate eyes of a VR headset we can perceive even slight differences in z-position between elements. We can see that a glowing button hovers 0.5cm above the surface of its parent dialogue, for example, or that a UI stretches off into the horizon. Depth in VR does naturally what drop shadows do skeuomorphically in 2D layouts: create visual contrast between stacked layers.\n\nAdding additional layers to our scene is easy. We create additional meshes and load a different bitmaps into their materials.\n\n* Copy and paste the code above, not including the variables for `circumference`, `radius`, and `height` (they need to be specified only once).\n* In the new material, specify a different bitmap (e.g., `THREE.ImageUtils.loadTexture( 'images/mockup-background.png' )`).\n* Tweak the mesh scale values to push the layout closer or further, as desired. This creates separation between layers.\n\nMy tactic in creating the MozVR.com layout was to start by building my layouts in a single Illustrator layer without thinking too much about 3D composition, and then group the elements into new layers towards the end of the process, with each layer representing a different depth. I then saved each layer individually as a bitmap with transparency. Each of these I then loaded into its own cylinder mesh, which I then tweaked the scale to find the desired separations. I found quickly that depth is particularly spectacular when combined with the DK2's 3D camera, which enables us to instantly perceive the parallax effect between layers as we lean our bodies around inside the virtual world.\n\n## Have fun!\n\nThis technique enables us to bridge the workflows we know with the new world of virtual reality. It's a quick and simple way to iterate rapidly. Start hacking - and have fun!\n","slug":"quick-vr-prototypes","published":1,"_id":"citot8hz8000rik1j33q952tu","comments":1,"layout":"post","photos":[],"link":"","content":"<p class=\"intro\">Designing for the VR web is nothing like designing for the desktop and mobile web. Every process and principle must be rethought, including how we prototype our ideas. With a simple cylinder and some precise measurements, however, we can move rapidly between our favorite 2D design apps and the virtual canvas of our headsets.</p>\n\n<p>After years of bouncing between Photoshop and Keynote, Ive happily settled on Illustrator as my primary interface design tool. Im good with 3D apps such as Cinema 4D, but for all their power, theyre painful to use for typography, interface layout, etc. So when it came time to design a VR web navigation UI, I wanted a workflow that let me rapidly iterate from mockups created in Illustrator to wrap-around WebVR test scenes.</p>\n<div class=\"post-summary\"><br>  <h2>In Brief</h2><br>  <ol><br>    <li>Create your layout in a 2D design app and export as a bitmap.</li><br>    <li>Create a cylinder mesh in three.js with a circumference/height ratio that matches the width/height ratio of the bitmap.</li><br>    <li>Apply the bitmap as a texture to the cylinder and flip the cylinder faces.</li><br>    <li>View in VR!</li><br>  </ol><br>  <a href=\"http://mozvr.github.io/vr-web-examples/mockups-on-cylinders/\" class=\"assets-link\" target=\"_blank\"><br>    <div class=\"table\"><br>      <div class=\"table-cell\"><br>        View Demo<br>      </div><br>      <div class=\"table-cell\"><br>        <img src=\"/content/images/2016/02/icon-goggles-2-white.svg\" class=\"left w3\"><br>      </div><br>    </div><br>  </a><br>  <a href=\"https://drive.google.com/file/d/0BzU9Qn2t09hSemI5REw0ek54eWc/view?usp=sharing\" class=\"assets-link\" target=\"_blank\" rel=\"external\"><br>    <div class=\"table\"><br>      <div class=\"table-cell\"><br>        Get the files<br>      </div><br>      <div class=\"table-cell\"><br>        <img src=\"/content/images/2016/02/icon-download-2-white-1.svg\" class=\"left w3\"><br>      </div><br>    </div><br>  </a><br></div>\n\n<p>We start in our preferred 2D design app - in my case, Illustrator. We create a canvas that is <strong>360cm &times; 90cm</strong>. When later viewed in the Rift, this canvas will wrap around us, mapped onto a cylinder which we (or the WebGL camera, more accurately) are in the center of. Like the following:</p>\n<figure><br>  <img src=\"/content/images/2016/02/mockup1.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\"><br>  <figcaption><br>    Our 360cm &times; 90cm Illustrator layout will be mapped onto a WebGL cylinder with a 360cm circumference and 90cm height.<br>  </figcaption><br></figure>\n\n<p>Working with real-world units is important because sense of scale is integral to virtual reality, and the scale your users will perceive will be determined primarily by the size of the elements in your scene relative to the distance between the users eyes. That distance is defined in real-world measurements (meters, to be precise). Working in real-world units throughout our pipeline ensures we dont encounter any weird surprises, such as text blocks that suddenly appear 10 stories tall (unless of course you <em>want</em> that).</p>\n<p>As we create our layouts, its also important that we know where on the cylinder our elements will eventually appear. Thats why a 360cm width is convenient: each centimeter on the horizontal of our composition will equal 1 on the circumference of the 3D cylinder. The center of our layout (180cm/180) will appear directly in front of the viewer, while the left and right edges will appear behind them.</p>\n<figure><br>  <img src=\"/content/images/2016/02/mockup2.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\"><br></figure>\n\n<p>But wait! How much of our layout will be visible to the user? Human field of view is <a href=\"http://xkcd.com/1080/\" target=\"_blank\" rel=\"external\">limited</a>, after all. We wouldnt want to make our users turn their heads 90 to read an important status indicator. The following diagram from Extron gives us some idea of what we have to work with.</p>\n<figure><br>  <img src=\"/content/images/2016/02/human-visual-field.jpg\" alt=\"Diagram of human visual field. Source: Extron.\"><br>  <figcaption><br>    Human field of vision is approximately 180 horizontal, but our ability to read text is limited to just the center 10, and our ability to perceive symbols to the center 60.<br>  </figcaption><br></figure>\n\n<p>To help us keep track of what our users can see, its helpful to set up a few guides in our layout template that express these values. Most importantly, the center 60, 30, and 10 of our vision, within which we can see color, shape, and text, respectively.</p>\n<figure><br>  <img src=\"/content/images/2016/02/mockup3.png\" alt=\"Mockup of a 360x90cm layout template with overlays for important field-of-view measurements.\"><br></figure>\n\n<p>We also need to remember that current VR headsets have a fairly limited field of view. The DK2, for example, has an effective horizontal field of view of approximately 90. This crops what we can see in the headset (without turning our heads) to the following:</p>\n<figure><br>  <img src=\"/content/images/2016/02/visual-field-DK2.png\" alt=\"Diagram of Oculus Rift DK2 field of view. Source: Extron.\"><br></figure>\n\n<p>Once we have a layout ready, we want to export it as a bitmap. We can scale at export-time as much as we need, so long as we do not change the same layouts width/height ratio. </p>\n<h2 id=\"Viewing-our-layout-in-VR\"><a href=\"#Viewing-our-layout-in-VR\" class=\"headerlink\" title=\"Viewing our layout in VR\"></a>Viewing our layout in VR</h2><p>The good news is we dont need much JS to create our WebGL VR scene. The following scene is built on the MozVR three.js WebVR boilerplate, available from our <a href=\"https://github.com/MozVR/vr-web-examples\" target=\"_blank\" rel=\"external\">vr-web-examples repo</a>. It uses <a href=\"https://github.com/mrdoob/three.js\" target=\"_blank\" rel=\"external\">three.js</a> and two extra libraries that handle detecting, communicating, and rendering to an attached VR headset.</p>\n<p>To preview our mockup, we simply copy the bitmap we saved into the <code>/images</code> directory and rename it <code>mockup.png</code>, overwriting the existing file. We then load <code>index.html</code> into our VR-enabled browser (e.g., <a href=\"http://mozvr.com/#downloads\" target=\"_blank\" rel=\"external\">Firefox with VR</a>), and enter VR mode by pressing <code>F</code> or double-clicking. In our headset, the browser should render our scene, and we should see our layout wrapped around us on a cylinder.</p>\n<h3 id=\"The-code\"><a href=\"#The-code\" class=\"headerlink\" title=\"The code\"></a>The code</h3><p>Lets look at <code>index.html</code> to see how this works. Most of the code is standard boilerplate for a three.js scene with VR support. To add our layouts, we must do the following:</p>\n<ol>\n<li>Create a cylinder geometry with a circumference/height ratio that matches the width/height ratio of the bitmap.</li>\n<li>Create a material and load our mockup as a texture.</li>\n<li>Flip the cylinder geometry to ensure the mockup displays correctly (facing inwards).</li>\n<li>Create a mesh from our geometry and material and add it to the scene so it renders.</li>\n</ol>\n<p>To do this we first set up a few variables for our cylinder geometry:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Set up the key measurements of the cylinder that will display our mockup image. It is important to match these measurements to the size of the image, or the surface area of the cylinder will be different from the image, causing it to appear squished or stretched. We start with the circumference of the cylinder. Set it to match the width of the image. Remember that the standard unit of measurement for VR scenes is meters. If our mockup canvas is 36cm wide, for example, we set the circumference value to be 3.6cm (360 / 100).</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> circumference = <span class=\"number\">3.6</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Set up the radius of the cylinder. We derive the radius from the circumference.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> radius = circumference / <span class=\"number\">3.14</span> / <span class=\"number\">2</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Set up the height of the cylinder. As with the circumference, we match this value to the height of our mockup, and convert to meters (from 90cm to 0.9m).</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> height = <span class=\"number\">0.9</span>;</div></pre></td></tr></table></figure>\n<p>We then create a cylinder geometry instance using the variables, and then invert its faces:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Create the geometry for the cylinder object that will display our mockups.</div><div class=\"line\">The cylinder constructor takes the following arguments: `CylinderGeometry(radiusTop, radiusBottom, height, radiusSegments, heightSegments, openEnded)`. We add 60 `radiusSegments` to make the cylinder smooth, and leave the top and bottom `openEnded`.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> geometry = <span class=\"keyword\">new</span> THREE.CylinderGeometry( radius, radius, height, <span class=\"number\">60</span>, <span class=\"number\">1</span>, <span class=\"literal\">true</span> );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Invert the scale of the geometry on the X axis. This flips the faces of the cylinder so they face inwards, which has the visible effect of displaying the mockups as we expect: facing inwards and in the correct orientation. Try removing this line to see what happens without flipping the scale.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\">geometry.applyMatrix( <span class=\"keyword\">new</span> THREE.Matrix4().makeScale( <span class=\"number\">-1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span> ) );</div></pre></td></tr></table></figure>\n<p>We then create a material for our mesh:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Create the material that we will load our mockup into and apply to our cylinder object. We set `transparent` to `true`, enabling us to optionally use mockups with alpha channels. We set `side` to `THREE.DoubleSide` so that our material renders facing both inwards and outwards (relative to the direction of the faces of the cylinder object). By default, materials and the faces of three.js meshes face outwards and are invisible from the reverse. Setting `THREE.DoubleSide` ensures the cylinder and its material will be visible no matter which direction (inside or out) we are viewing it from. This step is not strictly necessary, since we are actually going to invert the faces of the object to face inwards in a later step, but it is good to be aware of the `side` material attribute and how to define it. We then load our mockup as a texture.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> material = <span class=\"keyword\">new</span> THREE.MeshBasicMaterial( &#123; </div><div class=\"line\">  <span class=\"attr\">transparent</span>: <span class=\"literal\">true</span>, </div><div class=\"line\">  <span class=\"attr\">side</span>: THREE.DoubleSide,</div><div class=\"line\">  <span class=\"attr\">map</span>: THREE.ImageUtils.loadTexture( <span class=\"string\">'images/mockup.png'</span> )</div><div class=\"line\">&#125;);</div></pre></td></tr></table></figure>\n<p>Next, we create the mesh and add it to our scene:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Create the mesh of our cylinder object from the geometry and material.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> mesh = <span class=\"keyword\">new</span> THREE.Mesh( geometry, material );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Add our cylinder object to the scene. The default position of elements added to a three.js scene is `0,0,0`, which is also the default position of our scene's camera. So, our camera sits inside our cylinder.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\">scene.add( mesh );</div></pre></td></tr></table></figure>\n<p>Our cylinder should now render in the scene, and we are positioned at its center.</p>\n<h2 id=\"Experimenting-further\"><a href=\"#Experimenting-further\" class=\"headerlink\" title=\"Experimenting further\"></a>Experimenting further</h2><p>With our layout loaded, theres a lot more we can optionally do.</p>\n<h3 id=\"1-Change-the-radius-of-our-cylinder\"><a href=\"#1-Change-the-radius-of-our-cylinder\" class=\"headerlink\" title=\"1. Change the radius of our cylinder\"></a>1. Change the radius of our cylinder</h3><p>This has the effect of bringing the mockup closer or farther from the user. By default, a cylinder with a circumference of 3.6m has a radius of 0.573m (22.5in). This is about the average distance that most of us view our desktop or laptop displays from. Using your VR headset, you can adjust the mesh scale to see what feels right for your layout. Make sure to set the same values for the X, Y and Z; otherwise, the cylinder will be stretched.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">To adjust the distance between our mockups and the user, we can optionally scale our mesh. If we apply 0.5 to the X,Y,Z, for example, the radius shrinks by half, and the mockups become twice as close to our eyes. Because we are scaling proportionally (equal on X,Y,Z) the mockups do not _appear_ any larger, but the stereo effect of the VR headset tells us they are closer. Play with this setting to find a value that you like.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\">mesh.scale.set( <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span> );</div></pre></td></tr></table></figure>\n<p>As you experiment, also consider the potential for other objects in your scene to come between your layout and the user. If I design a heads-up display (HUD)-style navigation interface with a 0.5-meter radius, for example, and my avatar in the VR world walks up to a wall, the geometry of the wall is probably going to come closer than the interface, thereby occluding it. My loading indicator suddenly disappears into brick.</p>\n<p>The <a href=\"http://static.oculus.com/sdk-downloads/documents/Oculus_Best_Practices_Guide.pdf\" target=\"_blank\" rel=\"external\">Oculus Best Practices Guide</a> (which is required reading for any creator of VR content) suggests the following:</p>\n<blockquote>\n<p>Bringing UIs in closer (e.g., 20cm) can help prevent occlusion (where in-world objects come closer to the user than HUD objects), but require the user to shift their focus between the close-up HUD and the much more distant scene whenever they check the HUD. These kinds of shifts in eye convergence and accommodation (eye lens focus) can quickly lead to fatigue and eyestrain.</p>\n</blockquote>\n<h3 id=\"2-Add-a-background-image\"><a href=\"#2-Add-a-background-image\" class=\"headerlink\" title=\"2. Add a background image\"></a>2. Add a background image</h3><p>By default the background of our scene is black, but its easy to add a background image.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">To optionally add a background image to the scene, create a large sphere and apply a bitmap to it. First, create the geometry for the sphere. The `SphereGeometry` constructor takes several arguments, but we need only the basic three: `radius`, `widthSegments`, and `heightSegments`. We set `radius` to a big 5000 meters so the sphere is less likely to occlude other objects in our scene. We set the width and height segments to 64 and 32, respectively, to make its sphere surface smooth. And, we then invert the geometry on the X-axis using `THREE.Matrix4().makeScale()`, to flip the geometry faces so they face \"inwards,\" as we did with the mockup cylinder.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> geometry = <span class=\"keyword\">new</span> THREE.SphereGeometry( <span class=\"number\">5000</span>, <span class=\"number\">64</span>, <span class=\"number\">32</span> );</div><div class=\"line\">geometry.applyMatrix( <span class=\"keyword\">new</span> THREE.Matrix4().makeScale( <span class=\"number\">-1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span> ) );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Create the material we will load our background image into.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> material = <span class=\"keyword\">new</span> THREE.MeshBasicMaterial( &#123;</div><div class=\"line\">  <span class=\"attr\">map</span>: THREE.ImageUtils.loadTexture( <span class=\"string\">'images/background.png'</span> )</div><div class=\"line\">&#125; );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</span></div><div class=\"line\">Create the mesh of our background from the geometry and material, and add it to the scene.</div><div class=\"line\">*/</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> mesh = <span class=\"keyword\">new</span> THREE.Mesh( geometry, material );</div><div class=\"line\">scene.add( mesh );</div></pre></td></tr></table></figure>\n<p>And thats it! When we load the scene and put on our headset, we should by standing inside our mockup layout, with a distant background image wrapping everything.</p>\n<p>Play around with different background images to find one that gives you the contrast you want. I tend to use something that approximates the look of my final 3D scene, so I can judge colors, legibility, etc. For best results, use panoramic images in equirectangular format (see below). They will map perfectly (without distortion) to the WebGL sphere:</p>\n<figure><br>  <img src=\"/content/images/2016/02/puydesancy.jpg\" alt=\"Equirectangular panorama photo of mountain top in France by Alexandre Duret-Lutz\"><br>  <figcaption><br>    An example of an equirectangular image, taken by Alexandre Duret-Lutz. Find more of Alexandres beautiful panos on <a href=\"https://www.flickr.com/photos/gadl/\" target=\"_blank\">Flickr</a>.<br>  </figcaption><br></figure>\n\n<p>Flickrs <a href=\"https://www.flickr.com/groups/equirectangular/\" target=\"_blank\" rel=\"external\">Equirectangular Pool</a> is a fantastic source for images (just be sure to check the licenses). You can also use 3D apps to render 3D scenes into equirectangular format. I used Cinema 4D + Vray to create the blurred pano used in this tutorial, for example. Or if you need just a simple gradient or solid color, use your favorite image-editing app to fill a canvas with 2:1 width:height proportions.</p>\n<h3 id=\"3-Create-multiple-layers-at-different-depths\"><a href=\"#3-Create-multiple-layers-at-different-depths\" class=\"headerlink\" title=\"3. Create multiple layers at different depths\"></a>3. Create multiple layers at different depths</h3><p>Depth is a fundamental element of design for virtual reality. Through the two separate eyes of a VR headset we can perceive even slight differences in z-position between elements. We can see that a glowing button hovers 0.5cm above the surface of its parent dialogue, for example, or that a UI stretches off into the horizon. Depth in VR does naturally what drop shadows do skeuomorphically in 2D layouts: create visual contrast between stacked layers.</p>\n<p>Adding additional layers to our scene is easy. We create additional meshes and load a different bitmaps into their materials.</p>\n<ul>\n<li>Copy and paste the code above, not including the variables for <code>circumference</code>, <code>radius</code>, and <code>height</code> (they need to be specified only once).</li>\n<li>In the new material, specify a different bitmap (e.g., <code>THREE.ImageUtils.loadTexture( &#39;images/mockup-background.png&#39; )</code>).</li>\n<li>Tweak the mesh scale values to push the layout closer or further, as desired. This creates separation between layers.</li>\n</ul>\n<p>My tactic in creating the MozVR.com layout was to start by building my layouts in a single Illustrator layer without thinking too much about 3D composition, and then group the elements into new layers towards the end of the process, with each layer representing a different depth. I then saved each layer individually as a bitmap with transparency. Each of these I then loaded into its own cylinder mesh, which I then tweaked the scale to find the desired separations. I found quickly that depth is particularly spectacular when combined with the DK2s 3D camera, which enables us to instantly perceive the parallax effect between layers as we lean our bodies around inside the virtual world.</p>\n<h2 id=\"Have-fun\"><a href=\"#Have-fun\" class=\"headerlink\" title=\"Have fun!\"></a>Have fun!</h2><p>This technique enables us to bridge the workflows we know with the new world of virtual reality. Its a quick and simple way to iterate rapidly. Start hacking - and have fun!</p>\n","excerpt":"","more":"<p class=\"intro\">Designing for the VR web is nothing like designing for the desktop and mobile web. Every process and principle must be rethought, including how we prototype our ideas. With a simple cylinder and some precise measurements, however, we can move rapidly between our favorite 2D design apps and the virtual canvas of our headsets.</p>\n\n<p>After years of bouncing between Photoshop and Keynote, Ive happily settled on Illustrator as my primary interface design tool. Im good with 3D apps such as Cinema 4D, but for all their power, theyre painful to use for typography, interface layout, etc. So when it came time to design a VR web navigation UI, I wanted a workflow that let me rapidly iterate from mockups created in Illustrator to wrap-around WebVR test scenes.</p>\n<div class=\"post-summary\"><br>  <h2>In Brief</h2><br>  <ol><br>    <li>Create your layout in a 2D design app and export as a bitmap.</li><br>    <li>Create a cylinder mesh in three.js with a circumference/height ratio that matches the width/height ratio of the bitmap.</li><br>    <li>Apply the bitmap as a texture to the cylinder and flip the cylinder faces.</li><br>    <li>View in VR!</li><br>  </ol><br>  <a href=\"http://mozvr.github.io/vr-web-examples/mockups-on-cylinders/\" class=\"assets-link\" target=\"_blank\"><br>    <div class=\"table\"><br>      <div class=\"table-cell\"><br>        View Demo<br>      </div><br>      <div class=\"table-cell\"><br>        <img src=\"/content/images/2016/02/icon-goggles-2-white.svg\" class=\"left w3\"><br>      </div><br>    </div><br>  </a><br>  <a href=\"https://drive.google.com/file/d/0BzU9Qn2t09hSemI5REw0ek54eWc/view?usp=sharing\" class=\"assets-link\"><br>    <div class=\"table\"><br>      <div class=\"table-cell\"><br>        Get the files<br>      </div><br>      <div class=\"table-cell\"><br>        <img src=\"/content/images/2016/02/icon-download-2-white-1.svg\" class=\"left w3\"><br>      </div><br>    </div><br>  </a><br></div>\n\n<p>We start in our preferred 2D design app - in my case, Illustrator. We create a canvas that is <strong>360cm &times; 90cm</strong>. When later viewed in the Rift, this canvas will wrap around us, mapped onto a cylinder which we (or the WebGL camera, more accurately) are in the center of. Like the following:</p>\n<figure><br>  <img src=\"/content/images/2016/02/mockup1.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\"><br>  <figcaption><br>    Our 360cm &times; 90cm Illustrator layout will be mapped onto a WebGL cylinder with a 360cm circumference and 90cm height.<br>  </figcaption><br></figure>\n\n<p>Working with real-world units is important because sense of scale is integral to virtual reality, and the scale your users will perceive will be determined primarily by the size of the elements in your scene relative to the distance between the users eyes. That distance is defined in real-world measurements (meters, to be precise). Working in real-world units throughout our pipeline ensures we dont encounter any weird surprises, such as text blocks that suddenly appear 10 stories tall (unless of course you <em>want</em> that).</p>\n<p>As we create our layouts, its also important that we know where on the cylinder our elements will eventually appear. Thats why a 360cm width is convenient: each centimeter on the horizontal of our composition will equal 1 on the circumference of the 3D cylinder. The center of our layout (180cm/180) will appear directly in front of the viewer, while the left and right edges will appear behind them.</p>\n<figure><br>  <img src=\"/content/images/2016/02/mockup2.png\" alt=\"Top: our Illustrator layout. Bottom: our layout mapped onto a WebGL cylinder.\"><br></figure>\n\n<p>But wait! How much of our layout will be visible to the user? Human field of view is <a href=\"http://xkcd.com/1080/\">limited</a>, after all. We wouldnt want to make our users turn their heads 90 to read an important status indicator. The following diagram from Extron gives us some idea of what we have to work with.</p>\n<figure><br>  <img src=\"/content/images/2016/02/human-visual-field.jpg\" alt=\"Diagram of human visual field. Source: Extron.\"><br>  <figcaption><br>    Human field of vision is approximately 180 horizontal, but our ability to read text is limited to just the center 10, and our ability to perceive symbols to the center 60.<br>  </figcaption><br></figure>\n\n<p>To help us keep track of what our users can see, its helpful to set up a few guides in our layout template that express these values. Most importantly, the center 60, 30, and 10 of our vision, within which we can see color, shape, and text, respectively.</p>\n<figure><br>  <img src=\"/content/images/2016/02/mockup3.png\" alt=\"Mockup of a 360x90cm layout template with overlays for important field-of-view measurements.\"><br></figure>\n\n<p>We also need to remember that current VR headsets have a fairly limited field of view. The DK2, for example, has an effective horizontal field of view of approximately 90. This crops what we can see in the headset (without turning our heads) to the following:</p>\n<figure><br>  <img src=\"/content/images/2016/02/visual-field-DK2.png\" alt=\"Diagram of Oculus Rift DK2 field of view. Source: Extron.\"><br></figure>\n\n<p>Once we have a layout ready, we want to export it as a bitmap. We can scale at export-time as much as we need, so long as we do not change the same layouts width/height ratio. </p>\n<h2 id=\"Viewing-our-layout-in-VR\"><a href=\"#Viewing-our-layout-in-VR\" class=\"headerlink\" title=\"Viewing our layout in VR\"></a>Viewing our layout in VR</h2><p>The good news is we dont need much JS to create our WebGL VR scene. The following scene is built on the MozVR three.js WebVR boilerplate, available from our <a href=\"https://github.com/MozVR/vr-web-examples\">vr-web-examples repo</a>. It uses <a href=\"https://github.com/mrdoob/three.js\">three.js</a> and two extra libraries that handle detecting, communicating, and rendering to an attached VR headset.</p>\n<p>To preview our mockup, we simply copy the bitmap we saved into the <code>/images</code> directory and rename it <code>mockup.png</code>, overwriting the existing file. We then load <code>index.html</code> into our VR-enabled browser (e.g., <a href=\"http://mozvr.com/#downloads\">Firefox with VR</a>), and enter VR mode by pressing <code>F</code> or double-clicking. In our headset, the browser should render our scene, and we should see our layout wrapped around us on a cylinder.</p>\n<h3 id=\"The-code\"><a href=\"#The-code\" class=\"headerlink\" title=\"The code\"></a>The code</h3><p>Lets look at <code>index.html</code> to see how this works. Most of the code is standard boilerplate for a three.js scene with VR support. To add our layouts, we must do the following:</p>\n<ol>\n<li>Create a cylinder geometry with a circumference/height ratio that matches the width/height ratio of the bitmap.</li>\n<li>Create a material and load our mockup as a texture.</li>\n<li>Flip the cylinder geometry to ensure the mockup displays correctly (facing inwards).</li>\n<li>Create a mesh from our geometry and material and add it to the scene so it renders.</li>\n</ol>\n<p>To do this we first set up a few variables for our cylinder geometry:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Set up the key measurements of the cylinder that will display our mockup image. It is important to match these measurements to the size of the image, or the surface area of the cylinder will be different from the image, causing it to appear squished or stretched. We start with the circumference of the cylinder. Set it to match the width of the image. Remember that the standard unit of measurement for VR scenes is meters. If our mockup canvas is 36cm wide, for example, we set the circumference value to be 3.6cm (360 / 100).</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> circumference = <span class=\"number\">3.6</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Set up the radius of the cylinder. We derive the radius from the circumference.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> radius = circumference / <span class=\"number\">3.14</span> / <span class=\"number\">2</span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Set up the height of the cylinder. As with the circumference, we match this value to the height of our mockup, and convert to meters (from 90cm to 0.9m).</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> height = <span class=\"number\">0.9</span>;</div></pre></td></tr></table></figure>\n<p>We then create a cylinder geometry instance using the variables, and then invert its faces:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Create the geometry for the cylinder object that will display our mockups.</div><div class=\"line\">The cylinder constructor takes the following arguments: `CylinderGeometry(radiusTop, radiusBottom, height, radiusSegments, heightSegments, openEnded)`. We add 60 `radiusSegments` to make the cylinder smooth, and leave the top and bottom `openEnded`.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> geometry = <span class=\"keyword\">new</span> THREE.CylinderGeometry( radius, radius, height, <span class=\"number\">60</span>, <span class=\"number\">1</span>, <span class=\"literal\">true</span> );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Invert the scale of the geometry on the X axis. This flips the faces of the cylinder so they face inwards, which has the visible effect of displaying the mockups as we expect: facing inwards and in the correct orientation. Try removing this line to see what happens without flipping the scale.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\">geometry.applyMatrix( <span class=\"keyword\">new</span> THREE.Matrix4().makeScale( <span class=\"number\">-1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span> ) );</div></pre></td></tr></table></figure>\n<p>We then create a material for our mesh:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Create the material that we will load our mockup into and apply to our cylinder object. We set `transparent` to `true`, enabling us to optionally use mockups with alpha channels. We set `side` to `THREE.DoubleSide` so that our material renders facing both inwards and outwards (relative to the direction of the faces of the cylinder object). By default, materials and the faces of three.js meshes face outwards and are invisible from the reverse. Setting `THREE.DoubleSide` ensures the cylinder and its material will be visible no matter which direction (inside or out) we are viewing it from. This step is not strictly necessary, since we are actually going to invert the faces of the object to face inwards in a later step, but it is good to be aware of the `side` material attribute and how to define it. We then load our mockup as a texture.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> material = <span class=\"keyword\">new</span> THREE.MeshBasicMaterial( &#123; </div><div class=\"line\">  <span class=\"attr\">transparent</span>: <span class=\"literal\">true</span>, </div><div class=\"line\">  <span class=\"attr\">side</span>: THREE.DoubleSide,</div><div class=\"line\">  <span class=\"attr\">map</span>: THREE.ImageUtils.loadTexture( <span class=\"string\">'images/mockup.png'</span> )</div><div class=\"line\">&#125;);</div></pre></td></tr></table></figure>\n<p>Next, we create the mesh and add it to our scene:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Create the mesh of our cylinder object from the geometry and material.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> mesh = <span class=\"keyword\">new</span> THREE.Mesh( geometry, material );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Add our cylinder object to the scene. The default position of elements added to a three.js scene is `0,0,0`, which is also the default position of our scene's camera. So, our camera sits inside our cylinder.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\">scene.add( mesh );</div></pre></td></tr></table></figure>\n<p>Our cylinder should now render in the scene, and we are positioned at its center.</p>\n<h2 id=\"Experimenting-further\"><a href=\"#Experimenting-further\" class=\"headerlink\" title=\"Experimenting further\"></a>Experimenting further</h2><p>With our layout loaded, theres a lot more we can optionally do.</p>\n<h3 id=\"1-Change-the-radius-of-our-cylinder\"><a href=\"#1-Change-the-radius-of-our-cylinder\" class=\"headerlink\" title=\"1. Change the radius of our cylinder\"></a>1. Change the radius of our cylinder</h3><p>This has the effect of bringing the mockup closer or farther from the user. By default, a cylinder with a circumference of 3.6m has a radius of 0.573m (22.5in). This is about the average distance that most of us view our desktop or laptop displays from. Using your VR headset, you can adjust the mesh scale to see what feels right for your layout. Make sure to set the same values for the X, Y and Z; otherwise, the cylinder will be stretched.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">To adjust the distance between our mockups and the user, we can optionally scale our mesh. If we apply 0.5 to the X,Y,Z, for example, the radius shrinks by half, and the mockups become twice as close to our eyes. Because we are scaling proportionally (equal on X,Y,Z) the mockups do not _appear_ any larger, but the stereo effect of the VR headset tells us they are closer. Play with this setting to find a value that you like.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\">mesh.scale.set( <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span> );</div></pre></td></tr></table></figure>\n<p>As you experiment, also consider the potential for other objects in your scene to come between your layout and the user. If I design a heads-up display (HUD)-style navigation interface with a 0.5-meter radius, for example, and my avatar in the VR world walks up to a wall, the geometry of the wall is probably going to come closer than the interface, thereby occluding it. My loading indicator suddenly disappears into brick.</p>\n<p>The <a href=\"http://static.oculus.com/sdk-downloads/documents/Oculus_Best_Practices_Guide.pdf\">Oculus Best Practices Guide</a> (which is required reading for any creator of VR content) suggests the following:</p>\n<blockquote>\n<p>Bringing UIs in closer (e.g., 20cm) can help prevent occlusion (where in-world objects come closer to the user than HUD objects), but require the user to shift their focus between the close-up HUD and the much more distant scene whenever they check the HUD. These kinds of shifts in eye convergence and accommodation (eye lens focus) can quickly lead to fatigue and eyestrain.</p>\n</blockquote>\n<h3 id=\"2-Add-a-background-image\"><a href=\"#2-Add-a-background-image\" class=\"headerlink\" title=\"2. Add a background image\"></a>2. Add a background image</h3><p>By default the background of our scene is black, but its easy to add a background image.</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">To optionally add a background image to the scene, create a large sphere and apply a bitmap to it. First, create the geometry for the sphere. The `SphereGeometry` constructor takes several arguments, but we need only the basic three: `radius`, `widthSegments`, and `heightSegments`. We set `radius` to a big 5000 meters so the sphere is less likely to occlude other objects in our scene. We set the width and height segments to 64 and 32, respectively, to make its sphere surface smooth. And, we then invert the geometry on the X-axis using `THREE.Matrix4().makeScale()`, to flip the geometry faces so they face \"inwards,\" as we did with the mockup cylinder.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> geometry = <span class=\"keyword\">new</span> THREE.SphereGeometry( <span class=\"number\">5000</span>, <span class=\"number\">64</span>, <span class=\"number\">32</span> );</div><div class=\"line\">geometry.applyMatrix( <span class=\"keyword\">new</span> THREE.Matrix4().makeScale( <span class=\"number\">-1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span> ) );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Create the material we will load our background image into.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> material = <span class=\"keyword\">new</span> THREE.MeshBasicMaterial( &#123;</div><div class=\"line\">  <span class=\"attr\">map</span>: THREE.ImageUtils.loadTexture( <span class=\"string\">'images/background.png'</span> )</div><div class=\"line\">&#125; );</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*</div><div class=\"line\">Create the mesh of our background from the geometry and material, and add it to the scene.</div><div class=\"line\">*/</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">var</span> mesh = <span class=\"keyword\">new</span> THREE.Mesh( geometry, material );</div><div class=\"line\">scene.add( mesh );</div></pre></td></tr></table></figure>\n<p>And thats it! When we load the scene and put on our headset, we should by standing inside our mockup layout, with a distant background image wrapping everything.</p>\n<p>Play around with different background images to find one that gives you the contrast you want. I tend to use something that approximates the look of my final 3D scene, so I can judge colors, legibility, etc. For best results, use panoramic images in equirectangular format (see below). They will map perfectly (without distortion) to the WebGL sphere:</p>\n<figure><br>  <img src=\"/content/images/2016/02/puydesancy.jpg\" alt=\"Equirectangular panorama photo of mountain top in France by Alexandre Duret-Lutz\"><br>  <figcaption><br>    An example of an equirectangular image, taken by Alexandre Duret-Lutz. Find more of Alexandres beautiful panos on <a href=\"https://www.flickr.com/photos/gadl/\" target=\"_blank\">Flickr</a>.<br>  </figcaption><br></figure>\n\n<p>Flickrs <a href=\"https://www.flickr.com/groups/equirectangular/\">Equirectangular Pool</a> is a fantastic source for images (just be sure to check the licenses). You can also use 3D apps to render 3D scenes into equirectangular format. I used Cinema 4D + Vray to create the blurred pano used in this tutorial, for example. Or if you need just a simple gradient or solid color, use your favorite image-editing app to fill a canvas with 2:1 width:height proportions.</p>\n<h3 id=\"3-Create-multiple-layers-at-different-depths\"><a href=\"#3-Create-multiple-layers-at-different-depths\" class=\"headerlink\" title=\"3. Create multiple layers at different depths\"></a>3. Create multiple layers at different depths</h3><p>Depth is a fundamental element of design for virtual reality. Through the two separate eyes of a VR headset we can perceive even slight differences in z-position between elements. We can see that a glowing button hovers 0.5cm above the surface of its parent dialogue, for example, or that a UI stretches off into the horizon. Depth in VR does naturally what drop shadows do skeuomorphically in 2D layouts: create visual contrast between stacked layers.</p>\n<p>Adding additional layers to our scene is easy. We create additional meshes and load a different bitmaps into their materials.</p>\n<ul>\n<li>Copy and paste the code above, not including the variables for <code>circumference</code>, <code>radius</code>, and <code>height</code> (they need to be specified only once).</li>\n<li>In the new material, specify a different bitmap (e.g., <code>THREE.ImageUtils.loadTexture( &#39;images/mockup-background.png&#39; )</code>).</li>\n<li>Tweak the mesh scale values to push the layout closer or further, as desired. This creates separation between layers.</li>\n</ul>\n<p>My tactic in creating the MozVR.com layout was to start by building my layouts in a single Illustrator layer without thinking too much about 3D composition, and then group the elements into new layers towards the end of the process, with each layer representing a different depth. I then saved each layer individually as a bitmap with transparency. Each of these I then loaded into its own cylinder mesh, which I then tweaked the scale to find the desired separations. I found quickly that depth is particularly spectacular when combined with the DK2s 3D camera, which enables us to instantly perceive the parallax effect between layers as we lean our bodies around inside the virtual world.</p>\n<h2 id=\"Have-fun\"><a href=\"#Have-fun\" class=\"headerlink\" title=\"Have fun!\"></a>Have fun!</h2><p>This technique enables us to bridge the workflows we know with the new world of virtual reality. Its a quick and simple way to iterate rapidly. Start hacking - and have fun!</p>\n"},{"title":"WebVR Oculus Pose Prediction and HW Latency Testing","id":"7","updated":"2016-02-25T00:05:24.000Z","date":"2016-02-24T23:58:30.000Z","_content":"\n<p class=\"intro\">Oculus Pose prediction and hardware latency testing support has <strong>landed in the 2016-02-24 <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a></strong>. The effect will only be seen by Windows users with Oculus 0.8 runtime or newer. Existing WebVR content will take advantage of this automatically, without any modifications.</p>\n\nThe HMD pose and frame numbers submitted with each frame were not consistently associated with the frame that the sensors were sampled on. This update corrects this, enabling the Oculus HUD to show accurate latency information. Providing the accurate pose information to the Oculus runtime also results in a perceived lower latency and smoother HMD tracking.\n\nPose prediction has also been implemented behind a preference, which is disabled by default for now. Pose prediction offsets the effects of latency by returning a predicted future HMD pose instead of the instantaneous HMD pose. The prediction is dependent on the accurate measurement of latency, through the hardware latency tester. Through use of the latency tester, we have identified a reduction of frame latency uniformity when using e10s (multi-process). I recommend that you disable `Enable multi-process Nightly` in `about:preferences` / General before enabling pose prediction until we have improved the latency uniformity.\n\nIf you wish to try pose prediction early, from `about:config` set the `dom.vr.poseprediction.enabled` preference to `true`.\n\nAdditionally, it is recommended to set the `layout.frame_rate` preference to match the frame rate of your hardware. This should be set to `75` for Oculus DK2 and `90` for Oculus CV1.\n\nMore exciting updates for WebVR are coming soon. Stay tuned!\n","source":"_posts/WebVR-Oculus-Pose-Prediction-and-HW-Latency-Testing.md","raw":"---\ntitle: WebVR Oculus Pose Prediction and HW Latency Testing\ntags:\n  - Platform\n  - Oculus\npermalink: webvr-oculus-pose-prediction-and-hw-latency-testing\nid: 7\nupdated: '2016-02-24 16:05:24'\ndate: 2016-02-24 15:58:30\n---\n\n<p class=\"intro\">Oculus Pose prediction and hardware latency testing support has <strong>landed in the 2016-02-24 <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a></strong>. The effect will only be seen by Windows users with Oculus 0.8 runtime or newer. Existing WebVR content will take advantage of this automatically, without any modifications.</p>\n\nThe HMD pose and frame numbers submitted with each frame were not consistently associated with the frame that the sensors were sampled on. This update corrects this, enabling the Oculus HUD to show accurate latency information. Providing the accurate pose information to the Oculus runtime also results in a perceived lower latency and smoother HMD tracking.\n\nPose prediction has also been implemented behind a preference, which is disabled by default for now. Pose prediction offsets the effects of latency by returning a predicted future HMD pose instead of the instantaneous HMD pose. The prediction is dependent on the accurate measurement of latency, through the hardware latency tester. Through use of the latency tester, we have identified a reduction of frame latency uniformity when using e10s (multi-process). I recommend that you disable `Enable multi-process Nightly` in `about:preferences` / General before enabling pose prediction until we have improved the latency uniformity.\n\nIf you wish to try pose prediction early, from `about:config` set the `dom.vr.poseprediction.enabled` preference to `true`.\n\nAdditionally, it is recommended to set the `layout.frame_rate` preference to match the frame rate of your hardware. This should be set to `75` for Oculus DK2 and `90` for Oculus CV1.\n\nMore exciting updates for WebVR are coming soon. Stay tuned!\n","slug":"webvr-oculus-pose-prediction-and-hw-latency-testing","published":1,"_id":"citot8hz8000sik1jgy7f0m50","comments":1,"layout":"post","photos":[],"link":"","content":"<p class=\"intro\">Oculus Pose prediction and hardware latency testing support has <strong>landed in the 2016-02-24 <a href=\"https://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a></strong>. The effect will only be seen by Windows users with Oculus 0.8 runtime or newer. Existing WebVR content will take advantage of this automatically, without any modifications.</p>\n\n<p>The HMD pose and frame numbers submitted with each frame were not consistently associated with the frame that the sensors were sampled on. This update corrects this, enabling the Oculus HUD to show accurate latency information. Providing the accurate pose information to the Oculus runtime also results in a perceived lower latency and smoother HMD tracking.</p>\n<p>Pose prediction has also been implemented behind a preference, which is disabled by default for now. Pose prediction offsets the effects of latency by returning a predicted future HMD pose instead of the instantaneous HMD pose. The prediction is dependent on the accurate measurement of latency, through the hardware latency tester. Through use of the latency tester, we have identified a reduction of frame latency uniformity when using e10s (multi-process). I recommend that you disable <code>Enable multi-process Nightly</code> in <code>about:preferences</code> / General before enabling pose prediction until we have improved the latency uniformity.</p>\n<p>If you wish to try pose prediction early, from <code>about:config</code> set the <code>dom.vr.poseprediction.enabled</code> preference to <code>true</code>.</p>\n<p>Additionally, it is recommended to set the <code>layout.frame_rate</code> preference to match the frame rate of your hardware. This should be set to <code>75</code> for Oculus DK2 and <code>90</code> for Oculus CV1.</p>\n<p>More exciting updates for WebVR are coming soon. Stay tuned!</p>\n","excerpt":"","more":"<p class=\"intro\">Oculus Pose prediction and hardware latency testing support has <strong>landed in the 2016-02-24 <a href=\"https://nightly.mozilla.org/\">Firefox Nightly</a></strong>. The effect will only be seen by Windows users with Oculus 0.8 runtime or newer. Existing WebVR content will take advantage of this automatically, without any modifications.</p>\n\n<p>The HMD pose and frame numbers submitted with each frame were not consistently associated with the frame that the sensors were sampled on. This update corrects this, enabling the Oculus HUD to show accurate latency information. Providing the accurate pose information to the Oculus runtime also results in a perceived lower latency and smoother HMD tracking.</p>\n<p>Pose prediction has also been implemented behind a preference, which is disabled by default for now. Pose prediction offsets the effects of latency by returning a predicted future HMD pose instead of the instantaneous HMD pose. The prediction is dependent on the accurate measurement of latency, through the hardware latency tester. Through use of the latency tester, we have identified a reduction of frame latency uniformity when using e10s (multi-process). I recommend that you disable <code>Enable multi-process Nightly</code> in <code>about:preferences</code> / General before enabling pose prediction until we have improved the latency uniformity.</p>\n<p>If you wish to try pose prediction early, from <code>about:config</code> set the <code>dom.vr.poseprediction.enabled</code> preference to <code>true</code>.</p>\n<p>Additionally, it is recommended to set the <code>layout.frame_rate</code> preference to match the frame rate of your hardware. This should be set to <code>75</code> for Oculus DK2 and <code>90</code> for Oculus CV1.</p>\n<p>More exciting updates for WebVR are coming soon. Stay tuned!</p>\n"},{"title":"WebVR Lands in Firefox Nightly","id":"3","updated":"2016-02-18T23:45:32.000Z","date":"2016-02-18T23:22:40.000Z","_content":"\n<p class=\"intro\">Weve been working on adding VR capabilities to the Web for some months now, with the goal of making VR a first class citizen on the Web. Today, were taking another step towards this by adding core VR support directly to our Firefox Nightly builds.</p>\n\nPreviously, users and content creators had to download a separate build of Firefox. This one-off build usually lagged behind ongoing development. From now on, VR capabilities will be developed alongside other continuous Firefox improvements. While Firefox Nightly builds include core WebVR functionality, an additional add-on is needed to integrate with the Oculus Rift headset.\n\nTo experience WebVR content with an Oculus Rift Firefox Nightly builds, youll need to:\n\n* Install most recent [Firefox Nightly](http://nightly.mozilla.org/).\n* Install [WebVR Oculus Rift Enabler](/downloads/webvr-oculus-addon-0.4.4.xpi) add-on.\n* Open a non-e10s browser window.\n\nThe add-on simply provides the Oculus Rift SDK library so that Firefox can access it. In the future, this functionality may be bundled directly with Firefox, or provided by Oculus Runtime itself. The source for the add-on, as well as build instructions, [can be found on GitHub](https://github.com/MozVR/webvr-oculus-addon).\n\nWhile VR support will be enabled in our Nightly and Developer Edition (Alpha) builds, it will currently be automatically disabled in Beta and Release builds. We're still making rapid improvements and changes to both the VR interfaces and the necessary platform support pieces. Once WebVR is more complete, we'll discuss shipping plans to our Beta and Release builds.\n\nBecause there is ongoing development on Firefox in many directions, there is one issue to be aware of. Currently, WebVR in Firefox does not work with multiprocess browsing (e10s), which is being tested simultaneously on our Nightly builds. In order to view WebVR content, a non-e10s window must be used.\n\n## Creating non-e10s browser windows\n\n##### Mac\n![New Non-e10s (Mac)](/content/images/2016/02/e10s.png \"New Non-e10s (Mac)\")\n\n##### Windows\n![New Non-e10s (Windows) ](/content/images/2016/02/e10s-windows.png \"New Non-e10s (Windows)\")\n\nYou can create a new non-e10s window by going to the File menu and selecting New Non-e10s Window. (If instead that menu option says New e10s Window, then multiprocess browsing is disabled by default for you and youre good to go.) It's also possible to disable e10s entirely via the General tab in Preferences. Were working on resolving this issue in the near future.\n\nNow that we're able to work directly in our Nightly builds, we hope to have Direct-to-Rift support soon, as well as support for Linux, Firefox for Android, and the Cardboard device for mobile VR experiences. We'll also be starting to revisit VR support using CSS and the DOM, to maximize compatibility with existing Web content and Web development knowledge. You'll also soon be able to report bugs to us via [bugzilla.mozilla.org](https://bugzilla.mozilla.org/) in a new WebVR component. And, as always, please join the discussion on the [web-vr-discuss mailing list](https://mail.mozilla.org/listinfo/web-vr-discuss)!\n\nFinally, today we are launching a new and improved version of [mozvr.com](http://mozvr.com) with more resources for web developers and faster access to demos. Our first tutorial is from Josh Carpenter, on how to create [Quick VR Mockups with Illustrator](/quick-vr-prototypes/). We'll have more to come soon, with the goal of helping make it easier for everyone to create new VR web experiences.\n","source":"_posts/WebVR-Lands-in-Firefox-Nightly.md","raw":"---\ntitle: WebVR Lands in Firefox Nightly\ntags: Platform\npermalink: webvr-lands-in-firefox-nightly\nid: 3\nupdated: '2016-02-18 15:45:32'\ndate: 2016-02-18 15:22:40\n---\n\n<p class=\"intro\">Weve been working on adding VR capabilities to the Web for some months now, with the goal of making VR a first class citizen on the Web. Today, were taking another step towards this by adding core VR support directly to our Firefox Nightly builds.</p>\n\nPreviously, users and content creators had to download a separate build of Firefox. This one-off build usually lagged behind ongoing development. From now on, VR capabilities will be developed alongside other continuous Firefox improvements. While Firefox Nightly builds include core WebVR functionality, an additional add-on is needed to integrate with the Oculus Rift headset.\n\nTo experience WebVR content with an Oculus Rift Firefox Nightly builds, youll need to:\n\n* Install most recent [Firefox Nightly](http://nightly.mozilla.org/).\n* Install [WebVR Oculus Rift Enabler](/downloads/webvr-oculus-addon-0.4.4.xpi) add-on.\n* Open a non-e10s browser window.\n\nThe add-on simply provides the Oculus Rift SDK library so that Firefox can access it. In the future, this functionality may be bundled directly with Firefox, or provided by Oculus Runtime itself. The source for the add-on, as well as build instructions, [can be found on GitHub](https://github.com/MozVR/webvr-oculus-addon).\n\nWhile VR support will be enabled in our Nightly and Developer Edition (Alpha) builds, it will currently be automatically disabled in Beta and Release builds. We're still making rapid improvements and changes to both the VR interfaces and the necessary platform support pieces. Once WebVR is more complete, we'll discuss shipping plans to our Beta and Release builds.\n\nBecause there is ongoing development on Firefox in many directions, there is one issue to be aware of. Currently, WebVR in Firefox does not work with multiprocess browsing (e10s), which is being tested simultaneously on our Nightly builds. In order to view WebVR content, a non-e10s window must be used.\n\n## Creating non-e10s browser windows\n\n##### Mac\n![New Non-e10s (Mac)](/content/images/2016/02/e10s.png \"New Non-e10s (Mac)\")\n\n##### Windows\n![New Non-e10s (Windows) ](/content/images/2016/02/e10s-windows.png \"New Non-e10s (Windows)\")\n\nYou can create a new non-e10s window by going to the File menu and selecting New Non-e10s Window. (If instead that menu option says New e10s Window, then multiprocess browsing is disabled by default for you and youre good to go.) It's also possible to disable e10s entirely via the General tab in Preferences. Were working on resolving this issue in the near future.\n\nNow that we're able to work directly in our Nightly builds, we hope to have Direct-to-Rift support soon, as well as support for Linux, Firefox for Android, and the Cardboard device for mobile VR experiences. We'll also be starting to revisit VR support using CSS and the DOM, to maximize compatibility with existing Web content and Web development knowledge. You'll also soon be able to report bugs to us via [bugzilla.mozilla.org](https://bugzilla.mozilla.org/) in a new WebVR component. And, as always, please join the discussion on the [web-vr-discuss mailing list](https://mail.mozilla.org/listinfo/web-vr-discuss)!\n\nFinally, today we are launching a new and improved version of [mozvr.com](http://mozvr.com) with more resources for web developers and faster access to demos. Our first tutorial is from Josh Carpenter, on how to create [Quick VR Mockups with Illustrator](/quick-vr-prototypes/). We'll have more to come soon, with the goal of helping make it easier for everyone to create new VR web experiences.\n","slug":"webvr-lands-in-firefox-nightly","published":1,"_id":"citot8hza000vik1j66tty2fw","comments":1,"layout":"post","photos":[],"link":"","content":"<p class=\"intro\">Weve been working on adding VR capabilities to the Web for some months now, with the goal of making VR a first class citizen on the Web. Today, were taking another step towards this by adding core VR support directly to our Firefox Nightly builds.</p>\n\n<p>Previously, users and content creators had to download a separate build of Firefox. This one-off build usually lagged behind ongoing development. From now on, VR capabilities will be developed alongside other continuous Firefox improvements.  While Firefox Nightly builds include core WebVR functionality, an additional add-on is needed to integrate with the Oculus Rift headset.</p>\n<p>To experience WebVR content with an Oculus Rift Firefox Nightly builds, youll need to:</p>\n<ul>\n<li>Install most recent <a href=\"http://nightly.mozilla.org/\" target=\"_blank\" rel=\"external\">Firefox Nightly</a>.</li>\n<li>Install <a href=\"/downloads/webvr-oculus-addon-0.4.4.xpi\">WebVR Oculus Rift Enabler</a> add-on.</li>\n<li>Open a non-e10s browser window.</li>\n</ul>\n<p>The add-on simply provides the Oculus Rift SDK library so that Firefox can access it. In the future, this functionality may be bundled directly with Firefox, or provided by Oculus Runtime itself. The source for the add-on, as well as build instructions, <a href=\"https://github.com/MozVR/webvr-oculus-addon\" target=\"_blank\" rel=\"external\">can be found on GitHub</a>.</p>\n<p>While VR support will be enabled in our Nightly and Developer Edition (Alpha) builds, it will currently be automatically disabled in Beta and Release builds. Were still making rapid improvements and changes to both the VR interfaces and the necessary platform support pieces.  Once WebVR is more complete, well discuss shipping plans to our Beta and Release builds.</p>\n<p>Because there is ongoing development on Firefox in many directions, there is one issue to be aware of. Currently, WebVR in Firefox does not work with multiprocess browsing (e10s), which is being tested simultaneously on our Nightly builds. In order to view WebVR content, a non-e10s window must be used.</p>\n<h2 id=\"Creating-non-e10s-browser-windows\"><a href=\"#Creating-non-e10s-browser-windows\" class=\"headerlink\" title=\"Creating non-e10s browser windows\"></a>Creating non-e10s browser windows</h2><h5 id=\"Mac\"><a href=\"#Mac\" class=\"headerlink\" title=\"Mac\"></a>Mac</h5><p><img src=\"/content/images/2016/02/e10s.png\" alt=\"New Non-e10s (Mac)\" title=\"New Non-e10s (Mac)\"></p>\n<h5 id=\"Windows\"><a href=\"#Windows\" class=\"headerlink\" title=\"Windows\"></a>Windows</h5><p><img src=\"/content/images/2016/02/e10s-windows.png\" alt=\"New Non-e10s (Windows) \" title=\"New Non-e10s (Windows)\"></p>\n<p>You can create a new non-e10s window by going to the File menu and selecting New Non-e10s Window. (If instead that menu option says New e10s Window, then multiprocess browsing is disabled by default for you and youre good to go.) Its also possible to disable e10s entirely via the General tab in Preferences. Were working on resolving this issue in the near future.</p>\n<p>Now that were able to work directly in our Nightly builds, we hope to have Direct-to-Rift support soon, as well as support for Linux, Firefox for Android, and the Cardboard device for mobile VR experiences. Well also be starting to revisit VR support using CSS and the DOM, to maximize compatibility with existing Web content and Web development knowledge. Youll also soon be able to report bugs to us via <a href=\"https://bugzilla.mozilla.org/\" target=\"_blank\" rel=\"external\">bugzilla.mozilla.org</a> in a new WebVR component.  And, as always, please join the discussion on the <a href=\"https://mail.mozilla.org/listinfo/web-vr-discuss\" target=\"_blank\" rel=\"external\">web-vr-discuss mailing list</a>!</p>\n<p>Finally, today we are launching a new and improved version of <a href=\"http://mozvr.com\" target=\"_blank\" rel=\"external\">mozvr.com</a> with more resources for web developers and faster access to demos. Our first tutorial is from Josh Carpenter, on how to create <a href=\"/quick-vr-prototypes/\">Quick VR Mockups with Illustrator</a>. Well have more to come soon, with the goal of helping make it easier for everyone to create new VR web experiences.</p>\n","excerpt":"","more":"<p class=\"intro\">Weve been working on adding VR capabilities to the Web for some months now, with the goal of making VR a first class citizen on the Web. Today, were taking another step towards this by adding core VR support directly to our Firefox Nightly builds.</p>\n\n<p>Previously, users and content creators had to download a separate build of Firefox. This one-off build usually lagged behind ongoing development. From now on, VR capabilities will be developed alongside other continuous Firefox improvements.  While Firefox Nightly builds include core WebVR functionality, an additional add-on is needed to integrate with the Oculus Rift headset.</p>\n<p>To experience WebVR content with an Oculus Rift Firefox Nightly builds, youll need to:</p>\n<ul>\n<li>Install most recent <a href=\"http://nightly.mozilla.org/\">Firefox Nightly</a>.</li>\n<li>Install <a href=\"/downloads/webvr-oculus-addon-0.4.4.xpi\">WebVR Oculus Rift Enabler</a> add-on.</li>\n<li>Open a non-e10s browser window.</li>\n</ul>\n<p>The add-on simply provides the Oculus Rift SDK library so that Firefox can access it. In the future, this functionality may be bundled directly with Firefox, or provided by Oculus Runtime itself. The source for the add-on, as well as build instructions, <a href=\"https://github.com/MozVR/webvr-oculus-addon\">can be found on GitHub</a>.</p>\n<p>While VR support will be enabled in our Nightly and Developer Edition (Alpha) builds, it will currently be automatically disabled in Beta and Release builds. Were still making rapid improvements and changes to both the VR interfaces and the necessary platform support pieces.  Once WebVR is more complete, well discuss shipping plans to our Beta and Release builds.</p>\n<p>Because there is ongoing development on Firefox in many directions, there is one issue to be aware of. Currently, WebVR in Firefox does not work with multiprocess browsing (e10s), which is being tested simultaneously on our Nightly builds. In order to view WebVR content, a non-e10s window must be used.</p>\n<h2 id=\"Creating-non-e10s-browser-windows\"><a href=\"#Creating-non-e10s-browser-windows\" class=\"headerlink\" title=\"Creating non-e10s browser windows\"></a>Creating non-e10s browser windows</h2><h5 id=\"Mac\"><a href=\"#Mac\" class=\"headerlink\" title=\"Mac\"></a>Mac</h5><p><img src=\"/content/images/2016/02/e10s.png\" alt=\"New Non-e10s (Mac)\" title=\"New Non-e10s (Mac)\"></p>\n<h5 id=\"Windows\"><a href=\"#Windows\" class=\"headerlink\" title=\"Windows\"></a>Windows</h5><p><img src=\"/content/images/2016/02/e10s-windows.png\" alt=\"New Non-e10s (Windows) \" title=\"New Non-e10s (Windows)\"></p>\n<p>You can create a new non-e10s window by going to the File menu and selecting New Non-e10s Window. (If instead that menu option says New e10s Window, then multiprocess browsing is disabled by default for you and youre good to go.) Its also possible to disable e10s entirely via the General tab in Preferences. Were working on resolving this issue in the near future.</p>\n<p>Now that were able to work directly in our Nightly builds, we hope to have Direct-to-Rift support soon, as well as support for Linux, Firefox for Android, and the Cardboard device for mobile VR experiences. Well also be starting to revisit VR support using CSS and the DOM, to maximize compatibility with existing Web content and Web development knowledge. Youll also soon be able to report bugs to us via <a href=\"https://bugzilla.mozilla.org/\">bugzilla.mozilla.org</a> in a new WebVR component.  And, as always, please join the discussion on the <a href=\"https://mail.mozilla.org/listinfo/web-vr-discuss\">web-vr-discuss mailing list</a>!</p>\n<p>Finally, today we are launching a new and improved version of <a href=\"http://mozvr.com\">mozvr.com</a> with more resources for web developers and faster access to demos. Our first tutorial is from Josh Carpenter, on how to create <a href=\"/quick-vr-prototypes/\">Quick VR Mockups with Illustrator</a>. Well have more to come soon, with the goal of helping make it easier for everyone to create new VR web experiences.</p>\n"},{"title":"New site!","_content":"\nWe are doing some really cool work with WebVR here at Mozilla, and with the new site, we wanted to focus on showcasing our ideas, thoughts and projects with the community as much as possible.  So the best thing to do was to blow away the old site and really re-focus the content around the blog posts and content that we create here with WebVR.    In addition to this, we feel that we can provide a lot of help through your first WebVR project and to serve as a hub to the latest news in WebVR.\n\n## Your contributions matter\n\nIt's all about you.  The ideas, experiments and thoughts.   We value your work and would like you to be part of the larger discussion.    We invite you to post.\n\n\n### It's not just about Mozilla\n\nWe want to in one place, provide you all the necessary bits you need to get started in VR.\n\n\n### participate\n\nSlack, github, twitter, mailing list.\n\n","source":"_posts/hello-world.md","raw":"---\ntitle: New site!\n---\n\nWe are doing some really cool work with WebVR here at Mozilla, and with the new site, we wanted to focus on showcasing our ideas, thoughts and projects with the community as much as possible.  So the best thing to do was to blow away the old site and really re-focus the content around the blog posts and content that we create here with WebVR.    In addition to this, we feel that we can provide a lot of help through your first WebVR project and to serve as a hub to the latest news in WebVR.\n\n## Your contributions matter\n\nIt's all about you.  The ideas, experiments and thoughts.   We value your work and would like you to be part of the larger discussion.    We invite you to post.\n\n\n### It's not just about Mozilla\n\nWe want to in one place, provide you all the necessary bits you need to get started in VR.\n\n\n### participate\n\nSlack, github, twitter, mailing list.\n\n","slug":"hello-world","published":1,"date":"2016-09-27T23:01:38.000Z","updated":"2016-09-28T00:20:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"citot8hzc000xik1je8oyjww2","content":"<p>We are doing some really cool work with WebVR here at Mozilla, and with the new site, we wanted to focus on showcasing our ideas, thoughts and projects with the community as much as possible.  So the best thing to do was to blow away the old site and really re-focus the content around the blog posts and content that we create here with WebVR.    In addition to this, we feel that we can provide a lot of help through your first WebVR project and to serve as a hub to the latest news in WebVR.</p>\n<h2 id=\"Your-contributions-matter\"><a href=\"#Your-contributions-matter\" class=\"headerlink\" title=\"Your contributions matter\"></a>Your contributions matter</h2><p>Its all about you.  The ideas, experiments and thoughts.   We value your work and would like you to be part of the larger discussion.    We invite you to post.</p>\n<h3 id=\"Its-not-just-about-Mozilla\"><a href=\"#Its-not-just-about-Mozilla\" class=\"headerlink\" title=\"Its not just about Mozilla\"></a>Its not just about Mozilla</h3><p>We want to in one place, provide you all the necessary bits you need to get started in VR.</p>\n<h3 id=\"participate\"><a href=\"#participate\" class=\"headerlink\" title=\"participate\"></a>participate</h3><p>Slack, github, twitter, mailing list.</p>\n","excerpt":"","more":"<p>We are doing some really cool work with WebVR here at Mozilla, and with the new site, we wanted to focus on showcasing our ideas, thoughts and projects with the community as much as possible.  So the best thing to do was to blow away the old site and really re-focus the content around the blog posts and content that we create here with WebVR.    In addition to this, we feel that we can provide a lot of help through your first WebVR project and to serve as a hub to the latest news in WebVR.</p>\n<h2 id=\"Your-contributions-matter\"><a href=\"#Your-contributions-matter\" class=\"headerlink\" title=\"Your contributions matter\"></a>Your contributions matter</h2><p>Its all about you.  The ideas, experiments and thoughts.   We value your work and would like you to be part of the larger discussion.    We invite you to post.</p>\n<h3 id=\"Its-not-just-about-Mozilla\"><a href=\"#Its-not-just-about-Mozilla\" class=\"headerlink\" title=\"Its not just about Mozilla\"></a>Its not just about Mozilla</h3><p>We want to in one place, provide you all the necessary bits you need to get started in VR.</p>\n<h3 id=\"participate\"><a href=\"#participate\" class=\"headerlink\" title=\"participate\"></a>participate</h3><p>Slack, github, twitter, mailing list.</p>\n"},{"title":"WebVR API Transitions to W3C Incubation","id":"11","updated":"2016-06-07T19:45:17.000Z","date":"2016-06-02T00:35:42.000Z","_content":"\nThe **[WebVR API][webvr-spec]** has officially begun its transition to the [W3C WebVR Community Group][webvr-cg]!\n\nIn finalizing the recent [WebVR v1.0 API spec][webvr1-intro], we formed the **[WebVR Community Group within the W3C][webvr-cg]**. Our goal: to help bring high-performance virtual reality to the open Web through JavaScript-based APIs to access VR devices, sensors, and head-mounted displays.\n\nIn 2014, [Vlad Vukievi prototyped builds of Firefox with Oculus Rift DK1 support](http://web.archive.org/web/20151016091437/http://blog.bitops.com/blog/2014/06/26/first-steps-for-vr-on-the-web), and [Brandon Jones followed with experimental WebVR builds of Chromium](http://blog.tojicode.com/2014/07/bringing-vr-to-chrome.html). Together, they drafted an [informal WebVR API spec](http://web.archive.org/web/20160219163240/https://mozvr.github.io/webvr-spec/webvr.html) that served folks well until earlier this year in March 2016 when we announced the new-and-improved [WebVR v1.0 API proposal](https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/).\n\n## Is WebVR a standard yet?\n\nThe WebVR API spec is not yet a bonafide standard. We're hosting all development and discussion of the [WebVR spec][webvr-spec] in the [W3C Community Group][webvr-cg]. (All issues and commits from our old [`MozVR/webvr-spec` GitHub repo](https://github.com/mozvr/webvr-spec/) have been migrated to our new home, the [`W3C/webvr` repo](https://github.com/w3c/webvr/).)\n\nThese are significant milestones in getting WebVR one day on the standards track, and we couldn't be more excited! **_But, at the current time, we have not yet started making it a W3C standard._** As a community group, we are beginning to have discussions before committing to a particular standards body.\n\n## How to participate\n\nFeel free to [join](https://www.w3.org/community/webvr/join) the [W3C WebVR Community Group][webvr-cg] (only a [W3C account](https://www.w3.org/accounts/request), not W3C membership, is necessary).\n\nIf you'd like to participate in shaping the spec, feel free to [file new issues](https://github.com/w3c/webvr/issues/new) or jump into conversations in [existing issues](https://github.com/w3c/webvr/issues).\n\nTo learn more about how the [latest version of the WebVR API works, read this article][webvr1-intro] - and, of course, [the spec][webvr-spec].\n\nFor general WebVR information, go to [WebVR.info][webvr-info]. You can also check up-to-date platform status of the WebVR APIs at [IsWebVRReady.org][iwr]. Lastly, you can hop in the [WebVR Slack](https://webvr-slack.herokuapp.com/) to ask questions, give feedback, and hang out with the rest of the WebVR community.\n\n## Acknowledgements\n\nThanks to the following people who supported the creation of the **[W3C WebVR Community Group][webvr-cg]**: [Chris Van Wiemeersch][@cvanw], [Anssi Kostiainen][@anssik], [Brandon Jones][@tojiro], [Diego Marcos][@dmarcos], [Malik Butler](https://twitter.com/roninb_), [Daniel Appelquist](https://twitter.com/torgo), [Laszlo Gombos](https://twitter.com/laszlogombos), [Tee Jia Hen](https://twitter.com/wizztjh), [Arturo Paracuellos](https://twitter.com/arturitu), and [Donovan Kraeker](https://twitter.com/drawvr).\n\nWe'd like to give special thanks to those who contributed to the creation of and continue to shape the **[WebVR API specification][webvr-spec]**: [Vlad Vukievi][@vvuk] (Mozilla), [Brandon Jones][@tojiro] (Google), [Kearwood Kip Gilbert][@kearwoodgilbert] (Mozilla), [Chris Van Wiemeersch][@cvanw] (Mozilla), [Justin Rogers][@JustRogDigiTec] (Microsoft), [Michael Blix][@mkeblx] (Samsung), and [Brian Chirls](@bchirls) ([Datavized](http://datavized.com/)).\n\nLastly, we have to thank the always helpful and patient W3C standards gurus who continue to help us with WebVR's transition to the **[W3C Community Group](https://github.com/w3c/webvr)**: [Anssi Kostiainen][@anssik] (Intel, W3C Spec Editor & Chair), [Dominique Hazael-Massieux][@dontcallmedom] (W3C Staff), and Wayne Carr (Intel, W3C Advisory Committee).\n\nP.S. For a trip down memory lane, check out [this passage from Tony Parisi's _Learning Virtual Reality_ book][learningvr].\n\n[@JustRogDigiTec]: https://twitter.com/JustRogDigiTec\n[@anssik]: https://twitter.com/anssik\n[@bchirls]: https://twitter.com/bchirls\n[@cvanw]: https://twitter.com/cvanw\n[@dmarcos]: https://twitter.com/dmarcos\n[@dontcallmedom]: https://twitter.com/dontcallmedom\n[@kearwoodgilbert]: https://twitter.com/kearwoodgilbert\n[@mkeblx]: https://twitter.com/mkeblx\n[@tojiro]: https://twitter.com/tojiro\n[@vvuk]: https://twitter.com/vvuk\n[iwr]: https://iswebvrready.org/\n[learningvr]: https://books.google.com/books?id=bXvPCgAAQBAJ&lpg=PP1&pg=PA65#v=onepage&q&f=false\n[webvr-cg]: https://www.w3.org/community/webvr/\n[webvr-info]: https://webvr.info/\n[webvr-spec]: https://w3c.github.io/webvr/\n[webvr1-intro]: https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\n","source":"_posts/WebVR-API-Transitions-to-W3C-Incubation.md","raw":"---\ntitle: WebVR API Transitions to W3C Incubation\ntags: Standards\npermalink: webvr-api-transitions-to-w3c-standard\nid: 11\nupdated: '2016-06-07 12:45:17'\ndate: 2016-06-01 17:35:42\n---\n\nThe **[WebVR API][webvr-spec]** has officially begun its transition to the [W3C WebVR Community Group][webvr-cg]!\n\nIn finalizing the recent [WebVR v1.0 API spec][webvr1-intro], we formed the **[WebVR Community Group within the W3C][webvr-cg]**. Our goal: to help bring high-performance virtual reality to the open Web through JavaScript-based APIs to access VR devices, sensors, and head-mounted displays.\n\nIn 2014, [Vlad Vukievi prototyped builds of Firefox with Oculus Rift DK1 support](http://web.archive.org/web/20151016091437/http://blog.bitops.com/blog/2014/06/26/first-steps-for-vr-on-the-web), and [Brandon Jones followed with experimental WebVR builds of Chromium](http://blog.tojicode.com/2014/07/bringing-vr-to-chrome.html). Together, they drafted an [informal WebVR API spec](http://web.archive.org/web/20160219163240/https://mozvr.github.io/webvr-spec/webvr.html) that served folks well until earlier this year in March 2016 when we announced the new-and-improved [WebVR v1.0 API proposal](https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/).\n\n## Is WebVR a standard yet?\n\nThe WebVR API spec is not yet a bonafide standard. We're hosting all development and discussion of the [WebVR spec][webvr-spec] in the [W3C Community Group][webvr-cg]. (All issues and commits from our old [`MozVR/webvr-spec` GitHub repo](https://github.com/mozvr/webvr-spec/) have been migrated to our new home, the [`W3C/webvr` repo](https://github.com/w3c/webvr/).)\n\nThese are significant milestones in getting WebVR one day on the standards track, and we couldn't be more excited! **_But, at the current time, we have not yet started making it a W3C standard._** As a community group, we are beginning to have discussions before committing to a particular standards body.\n\n## How to participate\n\nFeel free to [join](https://www.w3.org/community/webvr/join) the [W3C WebVR Community Group][webvr-cg] (only a [W3C account](https://www.w3.org/accounts/request), not W3C membership, is necessary).\n\nIf you'd like to participate in shaping the spec, feel free to [file new issues](https://github.com/w3c/webvr/issues/new) or jump into conversations in [existing issues](https://github.com/w3c/webvr/issues).\n\nTo learn more about how the [latest version of the WebVR API works, read this article][webvr1-intro] - and, of course, [the spec][webvr-spec].\n\nFor general WebVR information, go to [WebVR.info][webvr-info]. You can also check up-to-date platform status of the WebVR APIs at [IsWebVRReady.org][iwr]. Lastly, you can hop in the [WebVR Slack](https://webvr-slack.herokuapp.com/) to ask questions, give feedback, and hang out with the rest of the WebVR community.\n\n## Acknowledgements\n\nThanks to the following people who supported the creation of the **[W3C WebVR Community Group][webvr-cg]**: [Chris Van Wiemeersch][@cvanw], [Anssi Kostiainen][@anssik], [Brandon Jones][@tojiro], [Diego Marcos][@dmarcos], [Malik Butler](https://twitter.com/roninb_), [Daniel Appelquist](https://twitter.com/torgo), [Laszlo Gombos](https://twitter.com/laszlogombos), [Tee Jia Hen](https://twitter.com/wizztjh), [Arturo Paracuellos](https://twitter.com/arturitu), and [Donovan Kraeker](https://twitter.com/drawvr).\n\nWe'd like to give special thanks to those who contributed to the creation of and continue to shape the **[WebVR API specification][webvr-spec]**: [Vlad Vukievi][@vvuk] (Mozilla), [Brandon Jones][@tojiro] (Google), [Kearwood Kip Gilbert][@kearwoodgilbert] (Mozilla), [Chris Van Wiemeersch][@cvanw] (Mozilla), [Justin Rogers][@JustRogDigiTec] (Microsoft), [Michael Blix][@mkeblx] (Samsung), and [Brian Chirls](@bchirls) ([Datavized](http://datavized.com/)).\n\nLastly, we have to thank the always helpful and patient W3C standards gurus who continue to help us with WebVR's transition to the **[W3C Community Group](https://github.com/w3c/webvr)**: [Anssi Kostiainen][@anssik] (Intel, W3C Spec Editor & Chair), [Dominique Hazael-Massieux][@dontcallmedom] (W3C Staff), and Wayne Carr (Intel, W3C Advisory Committee).\n\nP.S. For a trip down memory lane, check out [this passage from Tony Parisi's _Learning Virtual Reality_ book][learningvr].\n\n[@JustRogDigiTec]: https://twitter.com/JustRogDigiTec\n[@anssik]: https://twitter.com/anssik\n[@bchirls]: https://twitter.com/bchirls\n[@cvanw]: https://twitter.com/cvanw\n[@dmarcos]: https://twitter.com/dmarcos\n[@dontcallmedom]: https://twitter.com/dontcallmedom\n[@kearwoodgilbert]: https://twitter.com/kearwoodgilbert\n[@mkeblx]: https://twitter.com/mkeblx\n[@tojiro]: https://twitter.com/tojiro\n[@vvuk]: https://twitter.com/vvuk\n[iwr]: https://iswebvrready.org/\n[learningvr]: https://books.google.com/books?id=bXvPCgAAQBAJ&lpg=PP1&pg=PA65#v=onepage&q&f=false\n[webvr-cg]: https://www.w3.org/community/webvr/\n[webvr-info]: https://webvr.info/\n[webvr-spec]: https://w3c.github.io/webvr/\n[webvr1-intro]: https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\n","slug":"webvr-api-transitions-to-w3c-standard","published":1,"_id":"citot8hzc000zik1jw4augn1h","comments":1,"layout":"post","photos":[],"link":"","content":"<p>The <strong><a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">WebVR API</a></strong> has officially begun its transition to the <a href=\"https://www.w3.org/community/webvr/\" target=\"_blank\" rel=\"external\">W3C WebVR Community Group</a>!</p>\n<p>In finalizing the recent <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\" target=\"_blank\" rel=\"external\">WebVR v1.0 API spec</a>, we formed the <strong><a href=\"https://www.w3.org/community/webvr/\" target=\"_blank\" rel=\"external\">WebVR Community Group within the W3C</a></strong>. Our goal: to help bring high-performance virtual reality to the open Web through JavaScript-based APIs to access VR devices, sensors, and head-mounted displays.</p>\n<p>In 2014, <a href=\"http://web.archive.org/web/20151016091437/http://blog.bitops.com/blog/2014/06/26/first-steps-for-vr-on-the-web\" target=\"_blank\" rel=\"external\">Vlad Vukievi prototyped builds of Firefox with Oculus Rift DK1 support</a>, and <a href=\"http://blog.tojicode.com/2014/07/bringing-vr-to-chrome.html\" target=\"_blank\" rel=\"external\">Brandon Jones followed with experimental WebVR builds of Chromium</a>. Together, they drafted an <a href=\"http://web.archive.org/web/20160219163240/https://mozvr.github.io/webvr-spec/webvr.html\" target=\"_blank\" rel=\"external\">informal WebVR API spec</a> that served folks well until earlier this year in March 2016 when we announced the new-and-improved <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\" target=\"_blank\" rel=\"external\">WebVR v1.0 API proposal</a>.</p>\n<h2 id=\"Is-WebVR-a-standard-yet\"><a href=\"#Is-WebVR-a-standard-yet\" class=\"headerlink\" title=\"Is WebVR a standard yet?\"></a>Is WebVR a standard yet?</h2><p>The WebVR API spec is not yet a bonafide standard. Were hosting all development and discussion of the <a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">WebVR spec</a> in the <a href=\"https://www.w3.org/community/webvr/\" target=\"_blank\" rel=\"external\">W3C Community Group</a>. (All issues and commits from our old <a href=\"https://github.com/mozvr/webvr-spec/\" target=\"_blank\" rel=\"external\"><code>MozVR/webvr-spec</code> GitHub repo</a> have been migrated to our new home, the <a href=\"https://github.com/w3c/webvr/\" target=\"_blank\" rel=\"external\"><code>W3C/webvr</code> repo</a>.)</p>\n<p>These are significant milestones in getting WebVR one day on the standards track, and we couldnt be more excited! <strong><em>But, at the current time, we have not yet started making it a W3C standard.</em></strong> As a community group, we are beginning to have discussions before committing to a particular standards body.</p>\n<h2 id=\"How-to-participate\"><a href=\"#How-to-participate\" class=\"headerlink\" title=\"How to participate\"></a>How to participate</h2><p>Feel free to <a href=\"https://www.w3.org/community/webvr/join\" target=\"_blank\" rel=\"external\">join</a> the <a href=\"https://www.w3.org/community/webvr/\" target=\"_blank\" rel=\"external\">W3C WebVR Community Group</a> (only a <a href=\"https://www.w3.org/accounts/request\" target=\"_blank\" rel=\"external\">W3C account</a>, not W3C membership, is necessary).</p>\n<p>If youd like to participate in shaping the spec, feel free to <a href=\"https://github.com/w3c/webvr/issues/new\" target=\"_blank\" rel=\"external\">file new issues</a> or jump into conversations in <a href=\"https://github.com/w3c/webvr/issues\" target=\"_blank\" rel=\"external\">existing issues</a>.</p>\n<p>To learn more about how the <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\" target=\"_blank\" rel=\"external\">latest version of the WebVR API works, read this article</a> - and, of course, <a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">the spec</a>.</p>\n<p>For general WebVR information, go to <a href=\"https://webvr.info/\" target=\"_blank\" rel=\"external\">WebVR.info</a>. You can also check up-to-date platform status of the WebVR APIs at <a href=\"https://iswebvrready.org/\" target=\"_blank\" rel=\"external\">IsWebVRReady.org</a>. Lastly, you can hop in the <a href=\"https://webvr-slack.herokuapp.com/\" target=\"_blank\" rel=\"external\">WebVR Slack</a> to ask questions, give feedback, and hang out with the rest of the WebVR community.</p>\n<h2 id=\"Acknowledgements\"><a href=\"#Acknowledgements\" class=\"headerlink\" title=\"Acknowledgements\"></a>Acknowledgements</h2><p>Thanks to the following people who supported the creation of the <strong><a href=\"https://www.w3.org/community/webvr/\" target=\"_blank\" rel=\"external\">W3C WebVR Community Group</a></strong>: <a href=\"https://twitter.com/cvanw\" target=\"_blank\" rel=\"external\">Chris Van Wiemeersch</a>, <a href=\"https://twitter.com/anssik\" target=\"_blank\" rel=\"external\">Anssi Kostiainen</a>, <a href=\"https://twitter.com/tojiro\" target=\"_blank\" rel=\"external\">Brandon Jones</a>, <a href=\"https://twitter.com/dmarcos\" target=\"_blank\" rel=\"external\">Diego Marcos</a>, <a href=\"https://twitter.com/roninb_\" target=\"_blank\" rel=\"external\">Malik Butler</a>, <a href=\"https://twitter.com/torgo\" target=\"_blank\" rel=\"external\">Daniel Appelquist</a>, <a href=\"https://twitter.com/laszlogombos\" target=\"_blank\" rel=\"external\">Laszlo Gombos</a>, <a href=\"https://twitter.com/wizztjh\" target=\"_blank\" rel=\"external\">Tee Jia Hen</a>, <a href=\"https://twitter.com/arturitu\" target=\"_blank\" rel=\"external\">Arturo Paracuellos</a>, and <a href=\"https://twitter.com/drawvr\" target=\"_blank\" rel=\"external\">Donovan Kraeker</a>.</p>\n<p>Wed like to give special thanks to those who contributed to the creation of and continue to shape the <strong><a href=\"https://w3c.github.io/webvr/\" target=\"_blank\" rel=\"external\">WebVR API specification</a></strong>: <a href=\"https://twitter.com/vvuk\" target=\"_blank\" rel=\"external\">Vlad Vukievi</a> (Mozilla), <a href=\"https://twitter.com/tojiro\" target=\"_blank\" rel=\"external\">Brandon Jones</a> (Google), <a href=\"https://twitter.com/kearwoodgilbert\" target=\"_blank\" rel=\"external\">Kearwood Kip Gilbert</a> (Mozilla), <a href=\"https://twitter.com/cvanw\" target=\"_blank\" rel=\"external\">Chris Van Wiemeersch</a> (Mozilla), <a href=\"https://twitter.com/JustRogDigiTec\" target=\"_blank\" rel=\"external\">Justin Rogers</a> (Microsoft), <a href=\"https://twitter.com/mkeblx\" target=\"_blank\" rel=\"external\">Michael Blix</a> (Samsung), and <a href=\"@bchirls\">Brian Chirls</a> (<a href=\"http://datavized.com/\" target=\"_blank\" rel=\"external\">Datavized</a>).</p>\n<p>Lastly, we have to thank the always helpful and patient W3C standards gurus who continue to help us with WebVRs transition to the <strong><a href=\"https://github.com/w3c/webvr\" target=\"_blank\" rel=\"external\">W3C Community Group</a></strong>: <a href=\"https://twitter.com/anssik\" target=\"_blank\" rel=\"external\">Anssi Kostiainen</a> (Intel, W3C Spec Editor &amp; Chair), <a href=\"https://twitter.com/dontcallmedom\" target=\"_blank\" rel=\"external\">Dominique Hazael-Massieux</a> (W3C Staff), and Wayne Carr (Intel, W3C Advisory Committee).</p>\n<p>P.S. For a trip down memory lane, check out <a href=\"https://books.google.com/books?id=bXvPCgAAQBAJ&amp;lpg=PP1&amp;pg=PA65#v=onepage&amp;q&amp;f=false\" target=\"_blank\" rel=\"external\">this passage from Tony Parisis <em>Learning Virtual Reality</em> book</a>.</p>\n","excerpt":"","more":"<p>The <strong><a href=\"https://w3c.github.io/webvr/\">WebVR API</a></strong> has officially begun its transition to the <a href=\"https://www.w3.org/community/webvr/\">W3C WebVR Community Group</a>!</p>\n<p>In finalizing the recent <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\">WebVR v1.0 API spec</a>, we formed the <strong><a href=\"https://www.w3.org/community/webvr/\">WebVR Community Group within the W3C</a></strong>. Our goal: to help bring high-performance virtual reality to the open Web through JavaScript-based APIs to access VR devices, sensors, and head-mounted displays.</p>\n<p>In 2014, <a href=\"http://web.archive.org/web/20151016091437/http://blog.bitops.com/blog/2014/06/26/first-steps-for-vr-on-the-web\">Vlad Vukievi prototyped builds of Firefox with Oculus Rift DK1 support</a>, and <a href=\"http://blog.tojicode.com/2014/07/bringing-vr-to-chrome.html\">Brandon Jones followed with experimental WebVR builds of Chromium</a>. Together, they drafted an <a href=\"http://web.archive.org/web/20160219163240/https://mozvr.github.io/webvr-spec/webvr.html\">informal WebVR API spec</a> that served folks well until earlier this year in March 2016 when we announced the new-and-improved <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\">WebVR v1.0 API proposal</a>.</p>\n<h2 id=\"Is-WebVR-a-standard-yet\"><a href=\"#Is-WebVR-a-standard-yet\" class=\"headerlink\" title=\"Is WebVR a standard yet?\"></a>Is WebVR a standard yet?</h2><p>The WebVR API spec is not yet a bonafide standard. Were hosting all development and discussion of the <a href=\"https://w3c.github.io/webvr/\">WebVR spec</a> in the <a href=\"https://www.w3.org/community/webvr/\">W3C Community Group</a>. (All issues and commits from our old <a href=\"https://github.com/mozvr/webvr-spec/\"><code>MozVR/webvr-spec</code> GitHub repo</a> have been migrated to our new home, the <a href=\"https://github.com/w3c/webvr/\"><code>W3C/webvr</code> repo</a>.)</p>\n<p>These are significant milestones in getting WebVR one day on the standards track, and we couldnt be more excited! <strong><em>But, at the current time, we have not yet started making it a W3C standard.</em></strong> As a community group, we are beginning to have discussions before committing to a particular standards body.</p>\n<h2 id=\"How-to-participate\"><a href=\"#How-to-participate\" class=\"headerlink\" title=\"How to participate\"></a>How to participate</h2><p>Feel free to <a href=\"https://www.w3.org/community/webvr/join\">join</a> the <a href=\"https://www.w3.org/community/webvr/\">W3C WebVR Community Group</a> (only a <a href=\"https://www.w3.org/accounts/request\">W3C account</a>, not W3C membership, is necessary).</p>\n<p>If youd like to participate in shaping the spec, feel free to <a href=\"https://github.com/w3c/webvr/issues/new\">file new issues</a> or jump into conversations in <a href=\"https://github.com/w3c/webvr/issues\">existing issues</a>.</p>\n<p>To learn more about how the <a href=\"https://hacks.mozilla.org/2016/03/introducing-the-webvr-1-0-api-proposal/\">latest version of the WebVR API works, read this article</a> - and, of course, <a href=\"https://w3c.github.io/webvr/\">the spec</a>.</p>\n<p>For general WebVR information, go to <a href=\"https://webvr.info/\">WebVR.info</a>. You can also check up-to-date platform status of the WebVR APIs at <a href=\"https://iswebvrready.org/\">IsWebVRReady.org</a>. Lastly, you can hop in the <a href=\"https://webvr-slack.herokuapp.com/\">WebVR Slack</a> to ask questions, give feedback, and hang out with the rest of the WebVR community.</p>\n<h2 id=\"Acknowledgements\"><a href=\"#Acknowledgements\" class=\"headerlink\" title=\"Acknowledgements\"></a>Acknowledgements</h2><p>Thanks to the following people who supported the creation of the <strong><a href=\"https://www.w3.org/community/webvr/\">W3C WebVR Community Group</a></strong>: <a href=\"https://twitter.com/cvanw\">Chris Van Wiemeersch</a>, <a href=\"https://twitter.com/anssik\">Anssi Kostiainen</a>, <a href=\"https://twitter.com/tojiro\">Brandon Jones</a>, <a href=\"https://twitter.com/dmarcos\">Diego Marcos</a>, <a href=\"https://twitter.com/roninb_\">Malik Butler</a>, <a href=\"https://twitter.com/torgo\">Daniel Appelquist</a>, <a href=\"https://twitter.com/laszlogombos\">Laszlo Gombos</a>, <a href=\"https://twitter.com/wizztjh\">Tee Jia Hen</a>, <a href=\"https://twitter.com/arturitu\">Arturo Paracuellos</a>, and <a href=\"https://twitter.com/drawvr\">Donovan Kraeker</a>.</p>\n<p>Wed like to give special thanks to those who contributed to the creation of and continue to shape the <strong><a href=\"https://w3c.github.io/webvr/\">WebVR API specification</a></strong>: <a href=\"https://twitter.com/vvuk\">Vlad Vukievi</a> (Mozilla), <a href=\"https://twitter.com/tojiro\">Brandon Jones</a> (Google), <a href=\"https://twitter.com/kearwoodgilbert\">Kearwood Kip Gilbert</a> (Mozilla), <a href=\"https://twitter.com/cvanw\">Chris Van Wiemeersch</a> (Mozilla), <a href=\"https://twitter.com/JustRogDigiTec\">Justin Rogers</a> (Microsoft), <a href=\"https://twitter.com/mkeblx\">Michael Blix</a> (Samsung), and <a href=\"@bchirls\">Brian Chirls</a> (<a href=\"http://datavized.com/\">Datavized</a>).</p>\n<p>Lastly, we have to thank the always helpful and patient W3C standards gurus who continue to help us with WebVRs transition to the <strong><a href=\"https://github.com/w3c/webvr\">W3C Community Group</a></strong>: <a href=\"https://twitter.com/anssik\">Anssi Kostiainen</a> (Intel, W3C Spec Editor &amp; Chair), <a href=\"https://twitter.com/dontcallmedom\">Dominique Hazael-Massieux</a> (W3C Staff), and Wayne Carr (Intel, W3C Advisory Committee).</p>\n<p>P.S. For a trip down memory lane, check out <a href=\"https://books.google.com/books?id=bXvPCgAAQBAJ&amp;lpg=PP1&amp;pg=PA65#v=onepage&amp;q&amp;f=false\">this passage from Tony Parisis <em>Learning Virtual Reality</em> book</a>.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"citot8hyk0006ik1jso6rs350","tag_id":"citot8hyo0008ik1jb79y803h","_id":"citot8hyt000dik1j4qjkpd6u"},{"post_id":"citot8hza000vik1j66tty2fw","tag_id":"citoteqs50000kh1jnkh0x828","_id":"citotf1980002kh1jfz4vbgco"},{"post_id":"citot8hz5000nik1jlp8ikoct","tag_id":"citoteqs50000kh1jnkh0x828","_id":"citotfewh0004kh1j9wl0rq83"},{"post_id":"citot8hzc000zik1jw4augn1h","tag_id":"citotfr930005kh1jh1nw57ay","_id":"citotfr930006kh1jr4nx6wuf"},{"post_id":"citot8hz7000qik1jr8nw1foh","tag_id":"citoteqs50000kh1jnkh0x828","_id":"citotfvgp0007kh1j3709ykxy"},{"post_id":"citot8hz4000mik1jifoxfg9d","tag_id":"citotfr930005kh1jh1nw57ay","_id":"citotgoze000bkh1j2e4h8xuk"},{"post_id":"citot8hyy000iik1jtq3j4pqy","tag_id":"citothq7r000hkh1j3yg3rv83","_id":"citothq7s000ikh1jnvjd4mhi"},{"post_id":"citot8hyv000fik1j01g9csdw","tag_id":"citoti0ef000jkh1jw6zhszzl","_id":"citoti0eg000kkh1j61wmq2we"},{"post_id":"citot8hyr000bik1j7i34gioj","tag_id":"citotiiee000pkh1jlykecbce","_id":"citotiiee000qkh1jptywp41c"},{"post_id":"citot8hyq000aik1jaldlq6l5","tag_id":"citothq7r000hkh1j3yg3rv83","_id":"citotisgq000tkh1jdlsmvr5n"},{"post_id":"citot8hyw000gik1jp788bfw9","tag_id":"citothq7r000hkh1j3yg3rv83","_id":"citotjq9w000ukh1jqn0lreig"},{"post_id":"citot8hyt000eik1jcacfzk6x","tag_id":"citoteqs50000kh1jnkh0x828","_id":"citotm77n0010kh1jzrpxu5m9"},{"post_id":"citot8hyt000eik1jcacfzk6x","tag_id":"citotm77n000zkh1j5vkmek5q","_id":"citotm77n0011kh1jbbpf0rik"},{"post_id":"citot8hz0000lik1j2b87ybdb","tag_id":"citoteqs50000kh1jnkh0x828","_id":"citotn34v0012kh1jlglskncd"},{"post_id":"citot8hz0000lik1j2b87ybdb","tag_id":"citotiiee000pkh1jlykecbce","_id":"citotn34v0013kh1jhxiohr61"},{"post_id":"citot8hz8000rik1j33q952tu","tag_id":"citotn9zm0014kh1j2q6o347x","_id":"citotn9zn0016kh1jq9oyldlo"},{"post_id":"citot8hz8000rik1j33q952tu","tag_id":"citotn9zn0015kh1j11dqzqxe","_id":"citotn9zn0017kh1jvzx0o2aq"},{"post_id":"citot8hz8000sik1jgy7f0m50","tag_id":"citoteqs50000kh1jnkh0x828","_id":"citotnzgk0018kh1jithqb23v"},{"post_id":"citot8hz8000sik1jgy7f0m50","tag_id":"citotiiee000pkh1jlykecbce","_id":"citotnzgk0019kh1ji4c4c218"}],"Tag":[{"name":"\n- Community","_id":"citot8hyo0008ik1jb79y803h"},{"name":"\n- A-Frame","_id":"citot8hyt000cik1j2i5pdoe1"},{"name":"\n- Tools","_id":"citot8hyz000jik1jjpkwgzrr"},{"name":"\n- Platform","_id":"citot8hz6000oik1jj3ycw4da"},{"name":"\n- Tutorials","_id":"citot8hza000uik1jypz1s3hy"},{"name":"Platform","_id":"citoteqs50000kh1jnkh0x828"},{"name":"Standards","_id":"citotfr930005kh1jh1nw57ay"},{"name":"Standards, Workshops","_id":"citotgj2j0009kh1j4bt5hdc0"},{"name":"Tutorials, Design","_id":"citotgvgc000ckh1jqzgpxbbc"},{"name":"Platform, Oculus","_id":"citoth1hr000ekh1jflv8os8z"},{"name":"A-Frame","_id":"citothq7r000hkh1j3yg3rv83"},{"name":"Community","_id":"citoti0ef000jkh1jw6zhszzl"},{"name":"Platform, VIVE","_id":"citoti6oa000lkh1jfjtqhv0g"},{"name":"Platform, HTC VIVE","_id":"citoti9h0000nkh1jgqxr29sw"},{"name":"Oculus","_id":"citotiiee000pkh1jlykecbce"},{"name":"Tools","_id":"citotioa8000rkh1j5870709o"},{"name":"Platform VIVE","_id":"citotk1n7000vkh1jx5j9jdlk"},{"name":"Platform; VIVE","_id":"citotk6gx000xkh1jysaw4oq5"},{"name":"HTC VIVE","_id":"citotm77n000zkh1j5vkmek5q"},{"name":"Tutorials","_id":"citotn9zm0014kh1j2q6o347x"},{"name":"Design","_id":"citotn9zn0015kh1j11dqzqxe"}]}}